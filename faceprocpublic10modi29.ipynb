{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25667513",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\Administrator\\anaconda3\\envs\\tensorflow113\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Administrator\\anaconda3\\envs\\tensorflow113\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Administrator\\anaconda3\\envs\\tensorflow113\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Administrator\\anaconda3\\envs\\tensorflow113\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Administrator\\anaconda3\\envs\\tensorflow113\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Administrator\\anaconda3\\envs\\tensorflow113\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Administrator\\anaconda3\\envs\\tensorflow113\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 80, 80, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, 40, 40, 3)    0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePoo (None, 20, 20, 3)    0           average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "vgggen5_12_Next0 (Model)        (None, 80, 80, 1)    47262438    average_pooling2d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "vgggen5_12_Next1 (Model)        (None, 80, 80, 1)    47262438    average_pooling2d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "vgggen5_12_Next2 (Model)        (None, 80, 80, 1)    47262438    average_pooling2d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_22 (Concatenate)    (None, 80, 80, 3)    0           vgggen5_12_Next0[1][0]           \n",
      "                                                                 vgggen5_12_Next1[1][0]           \n",
      "                                                                 vgggen5_12_Next2[1][0]           \n",
      "==================================================================================================\n",
      "Total params: 141,787,314\n",
      "Trainable params: 141,780,972\n",
      "Non-trainable params: 6,342\n",
      "__________________________________________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 80, 80, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 40, 40, 3)    0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "vgggen5_16_Next0 (Model)        (None, 80, 80, 1)    22902375    max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "vgggen5_16_Next1 (Model)        (None, 80, 80, 1)    22902375    max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "vgggen5_16_Next2 (Model)        (None, 80, 80, 1)    22902375    max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_23 (Concatenate)    (None, 80, 80, 3)    0           vgggen5_16_Next0[1][0]           \n",
      "                                                                 vgggen5_16_Next1[1][0]           \n",
      "                                                                 vgggen5_16_Next2[1][0]           \n",
      "==================================================================================================\n",
      "Total params: 68,707,125\n",
      "Trainable params: 68,700,591\n",
      "Non-trainable params: 6,534\n",
      "__________________________________________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 80, 80, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vgggen5_15_MNext0 (Model)       (None, 80, 80, 1)    530946      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "vgggen5_15_MNext1 (Model)       (None, 80, 80, 1)    530946      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "vgggen5_15_MNext2 (Model)       (None, 80, 80, 1)    530946      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_24 (Concatenate)    (None, 80, 80, 3)    0           vgggen5_15_MNext0[1][0]          \n",
      "                                                                 vgggen5_15_MNext1[1][0]          \n",
      "                                                                 vgggen5_15_MNext2[1][0]          \n",
      "==================================================================================================\n",
      "Total params: 1,592,838\n",
      "Trainable params: 1,587,462\n",
      "Non-trainable params: 5,376\n",
      "__________________________________________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 80, 80, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePoo (None, 40, 40, 3)    0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_9 (AveragePoo (None, 20, 20, 3)    0           average_pooling2d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "vgggen5_12_Next0 (Model)        (None, 80, 80, 1)    47262438    average_pooling2d_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "vgggen5_12_Next1 (Model)        (None, 80, 80, 1)    47262438    average_pooling2d_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "vgggen5_12_Next2 (Model)        (None, 80, 80, 1)    47262438    average_pooling2d_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_25 (Concatenate)    (None, 80, 80, 3)    0           vgggen5_12_Next0[2][0]           \n",
      "                                                                 vgggen5_12_Next1[2][0]           \n",
      "                                                                 vgggen5_12_Next2[2][0]           \n",
      "==================================================================================================\n",
      "Total params: 141,787,314\n",
      "Trainable params: 141,780,972\n",
      "Non-trainable params: 6,342\n",
      "__________________________________________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 80, 80, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_10 (AveragePo (None, 40, 40, 3)    0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "vgggen5_12_Next40_80_50 (Model) (None, 80, 80, 1)    20820481    average_pooling2d_10[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "vgggen5_12_Next40_80_51 (Model) (None, 80, 80, 1)    20820481    average_pooling2d_10[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "vgggen5_12_Next40_80_52 (Model) (None, 80, 80, 1)    20820481    average_pooling2d_10[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "vgggen5_12_Next40_80_5prev (Mod (None, 80, 80, 3)    24143181    average_pooling2d_10[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_26 (Concatenate)    (None, 80, 80, 3)    0           vgggen5_12_Next40_80_50[1][0]    \n",
      "                                                                 vgggen5_12_Next40_80_51[1][0]    \n",
      "                                                                 vgggen5_12_Next40_80_52[1][0]    \n",
      "__________________________________________________________________________________________________\n",
      "add_75 (Add)                    (None, 80, 80, 3)    0           vgggen5_12_Next40_80_5prev[1][0] \n",
      "                                                                 concatenate_26[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 86,604,624\n",
      "Trainable params: 86,599,086\n",
      "Non-trainable params: 5,538\n",
      "__________________________________________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, 120, 120, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_11 (AveragePo (None, 60, 60, 3)    0           input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "vgggen5_12_Next40_80_60 (Model) (None, 120, 120, 1)  36711281    average_pooling2d_11[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "vgggen5_12_Next40_80_61 (Model) (None, 120, 120, 1)  36711281    average_pooling2d_11[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "vgggen5_12_Next40_80_62 (Model) (None, 120, 120, 1)  36711281    average_pooling2d_11[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "vgggen5_12_Next40_80_5prev2 (Mo (None, 120, 120, 3)  24698011    average_pooling2d_11[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_27 (Concatenate)    (None, 120, 120, 3)  0           vgggen5_12_Next40_80_60[1][0]    \n",
      "                                                                 vgggen5_12_Next40_80_61[1][0]    \n",
      "                                                                 vgggen5_12_Next40_80_62[1][0]    \n",
      "__________________________________________________________________________________________________\n",
      "add_76 (Add)                    (None, 120, 120, 3)  0           vgggen5_12_Next40_80_5prev2[1][0]\n",
      "                                                                 concatenate_27[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 134,831,854\n",
      "Trainable params: 134,826,736\n",
      "Non-trainable params: 5,118\n",
      "__________________________________________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            (None, 160, 160, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_12 (AveragePo (None, 80, 80, 3)    0           input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "vgggen5_12_Next40_80_70 (Model) (None, 160, 160, 1)  32678481    average_pooling2d_12[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "vgggen5_12_Next40_80_71 (Model) (None, 160, 160, 1)  32678481    average_pooling2d_12[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "vgggen5_12_Next40_80_72 (Model) (None, 160, 160, 1)  32678481    average_pooling2d_12[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "vgggen5_12_Next40_80_5prev3 (Mo (None, 160, 160, 3)  22934539    average_pooling2d_12[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_28 (Concatenate)    (None, 160, 160, 3)  0           vgggen5_12_Next40_80_70[1][0]    \n",
      "                                                                 vgggen5_12_Next40_80_71[1][0]    \n",
      "                                                                 vgggen5_12_Next40_80_72[1][0]    \n",
      "__________________________________________________________________________________________________\n",
      "add_77 (Add)                    (None, 160, 160, 3)  0           vgggen5_12_Next40_80_5prev3[1][0]\n",
      "                                                                 concatenate_28[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 120,969,982\n",
      "Trainable params: 120,963,008\n",
      "Non-trainable params: 6,974\n",
      "__________________________________________________________________________________________________\n",
      "begin proc image\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now proc 99\n",
      "now proc 199\n",
      "now proc 299\n",
      "now proc 399\n",
      "now proc 499\n",
      "now proc 599\n",
      "now proc 699\n",
      "now proc 799\n",
      "now proc 899\n",
      "now proc 999\n",
      "now proc 1099\n",
      "now proc 1199\n",
      "now proc 1299\n",
      "now proc 1399\n",
      "now proc 1499\n",
      "now proc 1599\n",
      "now proc 1699\n",
      "now proc 1799\n",
      "now proc 1899\n",
      "now proc 1999\n",
      "now proc 2099\n",
      "now proc 2199\n",
      "now proc 2299\n",
      "now proc 2399\n",
      "now proc 2499\n",
      "now proc 2599\n",
      "now proc 2699\n",
      "now proc 2799\n",
      "now proc 2899\n",
      "now proc 2999\n",
      "now proc 3099\n",
      "now proc 3199\n",
      "now proc 3299\n",
      "now proc 3399\n",
      "now proc 3499\n",
      "now proc 3599\n",
      "now proc 3699\n",
      "now proc 3799\n",
      "now proc 3899\n",
      "now proc 3999\n",
      "now proc 4099\n",
      "now proc 4199\n",
      "now proc 4299\n",
      "now proc 4399\n",
      "now proc 4499\n",
      "now proc 4599\n",
      "now proc 4699\n",
      "now proc 4799\n",
      "now proc 4899\n",
      "now proc 4999\n",
      "now proc 5099\n",
      "now proc 5199\n",
      "now proc 5299\n",
      "now proc 5399\n",
      "now proc 5499\n",
      "now proc 5599\n",
      "now proc 5699\n",
      "now proc 5799\n",
      "now proc 5899\n",
      "now proc 5999\n",
      "now proc 6099\n",
      "now proc 6199\n",
      "now proc 6299\n",
      "now proc 6399\n",
      "now proc 6499\n",
      "now proc 6599\n",
      "now proc 6699\n",
      "now proc 6799\n",
      "now proc 6899\n",
      "now proc 6999\n",
      "now proc 7099\n",
      "now proc 7199\n",
      "now proc 7299\n",
      "now proc 7399\n",
      "now proc 7499\n",
      "now proc 7599\n",
      "now proc 7699\n",
      "now proc 7799\n",
      "now proc 7899\n",
      "now proc 7999\n",
      "now proc 8099\n",
      "now proc 8199\n",
      "now proc 8299\n",
      "now proc 8399\n",
      "now proc 8499\n",
      "now proc 8599\n",
      "now proc 8699\n",
      "now proc 8799\n",
      "now proc 8899\n",
      "now proc 8999\n",
      "now proc 9099\n",
      "now proc 9199\n",
      "now proc 9299\n",
      "now proc 9399\n",
      "now proc 9499\n",
      "now proc 9599\n",
      "now proc 9699\n",
      "now proc 9799\n",
      "now proc 9899\n",
      "now proc 9999\n",
      "now proc 10099\n",
      "now proc 10199\n",
      "now proc 10299\n",
      "now proc 10399\n",
      "now proc 10499\n",
      "now proc 10599\n",
      "now proc 10699\n",
      "now proc 10799\n",
      "now proc 10899\n",
      "now proc 10999\n",
      "now proc 11099\n",
      "now proc 11199\n",
      "now proc 11299\n",
      "now proc 11399\n",
      "now proc 11499\n",
      "now proc 11599\n",
      "now proc 11699\n",
      "now proc 11799\n",
      "now proc 11899\n",
      "now proc 11999\n",
      "now proc 12099\n",
      "now proc 12199\n",
      "now proc 12299\n",
      "now proc 12399\n",
      "now proc 12499\n",
      "now proc 12599\n",
      "now proc 12699\n",
      "now proc 12799\n",
      "now proc 12899\n",
      "now proc 12999\n",
      "now proc 13099\n",
      "now proc 13199\n",
      "now proc 13299\n",
      "now proc 13399\n",
      "now proc 13499\n",
      "now proc 13599\n",
      "now proc 13699\n",
      "now proc 13799\n",
      "now proc 13899\n",
      "now proc 13999\n",
      "now proc 14099\n",
      "now proc 14199\n",
      "now proc 14299\n",
      "now proc 14399\n",
      "now proc 14499\n",
      "now proc 14599\n",
      "now proc 14699\n",
      "now proc 14799\n",
      "now proc 14899\n",
      "now proc 14999\n",
      "now proc 15099\n",
      "now proc 15199\n",
      "now proc 15299\n",
      "now proc 15399\n",
      "now proc 15499\n",
      "now proc 15599\n",
      "now proc 15699\n",
      "now proc 15799\n",
      "now proc 15899\n",
      "now proc 15999\n",
      "now proc 16099\n",
      "now proc 16199\n",
      "now proc 16299\n",
      "now proc 16399\n",
      "now proc 16499\n",
      "now proc 16599\n",
      "now proc 16699\n",
      "now proc 16799\n",
      "now proc 16899\n",
      "now proc 16999\n",
      "now proc 17099\n",
      "now proc 17199\n",
      "now proc 17299\n",
      "now proc 17399\n",
      "now proc 17499\n",
      "now proc 17599\n",
      "now proc 17699\n",
      "now proc 17799\n",
      "now proc 17899\n",
      "now proc 17999\n",
      "now proc 18099\n",
      "now proc 18199\n",
      "now proc 18299\n",
      "now proc 18399\n",
      "now proc 18499\n",
      "now proc 18599\n",
      "now proc 18699\n",
      "now proc 18799\n",
      "now proc 18899\n",
      "now proc 18999\n",
      "now proc 19099\n",
      "now proc 19199\n",
      "now proc 19299\n",
      "now proc 19399\n",
      "now proc 19499\n",
      "now proc 19599\n",
      "now proc 19699\n",
      "now proc 19799\n",
      "now proc 19899\n",
      "now proc 19999\n",
      "now proc 20099\n",
      "now proc 20199\n",
      "now proc 20299\n",
      "now proc 20399\n",
      "now proc 20499\n",
      "now proc 20599\n",
      "now proc 20699\n",
      "now proc 20799\n",
      "now proc 20899\n",
      "now proc 20999\n",
      "now proc 21099\n",
      "now proc 21199\n",
      "now proc 21299\n",
      "now proc 21399\n",
      "now proc 21499\n",
      "now proc 21599\n",
      "now proc 21699\n",
      "now proc 21799\n",
      "now proc 21899\n",
      "now proc 21999\n",
      "now proc 22099\n",
      "now proc 22199\n",
      "now proc 22299\n",
      "now proc 22399\n",
      "now proc 22499\n",
      "now proc 22599\n",
      "now proc 22699\n",
      "now proc 22799\n",
      "now proc 22899\n",
      "now proc 22999\n",
      "now proc 23099\n",
      "now proc 23199\n",
      "now proc 23299\n",
      "now proc 23399\n",
      "now proc 23499\n",
      "now proc 23599\n",
      "now proc 23699\n",
      "now proc 23799\n",
      "now proc 23899\n",
      "now proc 23999\n",
      "now proc 24099\n",
      "now proc 24199\n",
      "now proc 24299\n",
      "now proc 24399\n",
      "now proc 24499\n",
      "now proc 24599\n",
      "now proc 24699\n",
      "now proc 24799\n",
      "now proc 24899\n",
      "now proc 24999\n",
      "now proc 25099\n",
      "now proc 25199\n",
      "now proc 25299\n",
      "now proc 25399\n",
      "now proc 25499\n",
      "now proc 25599\n",
      "now proc 25699\n",
      "now proc 25799\n",
      "now proc 25899\n",
      "now proc 25999\n",
      "now proc 26099\n",
      "now proc 26199\n",
      "now proc 26299\n",
      "now proc 26399\n",
      "now proc 26499\n",
      "now proc 26599\n",
      "now proc 26699\n",
      "now proc 26799\n",
      "now proc 26899\n",
      "now proc 26999\n",
      "now proc 27099\n",
      "now proc 27199\n",
      "now proc 27299\n",
      "now proc 27399\n",
      "now proc 27499\n",
      "now proc 27599\n",
      "now proc 27699\n",
      "now proc 27799\n",
      "now proc 27899\n",
      "now proc 27999\n",
      "now proc 28099\n",
      "now proc 28199\n",
      "now proc 28299\n",
      "now proc 28399\n",
      "now proc 28499\n",
      "now proc 28599\n",
      "now proc 28699\n",
      "now proc 28799\n",
      "now proc 28899\n",
      "now proc 28999\n",
      "now proc 29099\n",
      "now proc 29199\n",
      "now proc 29299\n",
      "now proc 29399\n",
      "now proc 29499\n",
      "now proc 29599\n",
      "now proc 29699\n",
      "now proc 29799\n",
      "now proc 29899\n",
      "now proc 29999\n",
      "train images complete\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "#from keras.datasets import mnist\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Input, Dense, Dropout,Reshape, Flatten\n",
    "from keras.layers.pooling import MaxPooling2D,AveragePooling2D\n",
    "from keras.layers import Conv2D, BatchNormalization,UpSampling2D\n",
    "from keras.layers import Add,GlobalAveragePooling2D, Lambda, Conv2D,  Dropout, Dense, Flatten, Activation\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.preprocessing.image import load_img,img_to_array\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.layers import concatenate\n",
    "from keras import backend as K\n",
    "from keras import regularizers\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import *\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import load_model\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "\n",
    "#,Merge\n",
    "\n",
    "FILE_PATH = 'C:\\\\Users\\\\ncuser\\\\facedata\\\\face_CNN_model_final.h5'\n",
    "trainpath = 'C:\\\\Users\\\\ncuser\\\\facedata\\\\new_data_50000\\\\50000train\\\\'\n",
    "testpath = 'C:\\\\Users\\\\ncuser\\\\facedata\\\\new_data_50000\\\\50000test\\\\'\n",
    "\n",
    "trainpath2 = 'C:\\\\Users\\\\ncuser\\\\facedata\\\\convdata\\\\50000train\\\\'\n",
    "testpath2 = 'C:\\\\Users\\\\ncuser\\\\facedata\\\\convdata\\\\50000test\\\\'\n",
    "\n",
    "FILE_PATH = 'h:\\\\facedata\\\\face_CNN_model_final.h5'\n",
    "trainpath = 'h:\\\\facedata\\\\new_data_50000\\\\50000train\\\\'\n",
    "testpath = 'h:\\\\facedata\\\\new_data_50000\\\\50000test\\\\'\n",
    "\n",
    "trainpath2 = 'h:\\\\facedata\\\\convdata\\\\50000train\\\\'\n",
    "testpath2 = 'h:\\\\facedata\\\\convdata\\\\50000test\\\\'\n",
    "\n",
    "trainpath2 = 'O:\\\\CelebA-HQ-img80\\\\CelebA-HQ-img80\\\\'\n",
    "\n",
    "trainpath3 = 'O:\\\\CelebA-HQ-img40\\\\CelebA-HQ-img40\\\\'\n",
    "\n",
    "trainpath5 = 'O:\\\\CelebA-HQ-img120\\\\CelebA-HQ-img120\\\\'\n",
    "\n",
    "trainpath6 = 'O:\\\\CelebA-HQ-img160\\\\CelebA-HQ-img160\\\\'\n",
    "\n",
    "K.set_floatx('float32')\n",
    "\n",
    "imgsize = 178\n",
    "train_samples = 40000\n",
    "test_samples = 200\n",
    "batch_size = 8\n",
    "\n",
    "chanDim = -1\n",
    "\n",
    "model_input6 = Input(shape=(178,178,3))\n",
    "input_shape = (178, 178, 3)\n",
    "\n",
    "\n",
    "model_inputconv = Input(shape=(80,80,3))\n",
    "input_shapeconv = (80, 80, 3)\n",
    "\n",
    "\n",
    "model_inputconv2 = Input(shape=(40,40,3))\n",
    "\n",
    "\n",
    "model_inputconv9 = Input(shape=(120,120,3))\n",
    "\n",
    "model_inputconv10 = Input(shape=(160,160,3))\n",
    "\n",
    "traindata =[]\n",
    "traindata2 =[]\n",
    "traindataok=[]\n",
    "traincount = 0\n",
    "testdata = []\n",
    "testdata2 = []\n",
    "testdataok=[]\n",
    "testcount = 0\n",
    "\n",
    "\n",
    "def sliceuse(x,index):\n",
    "    return x[:,:,:,index]\n",
    "\n",
    "def get_lr_metric(optimizer):  # printing the value of the learning rate\n",
    "    def lr(y_true, y_pred):\n",
    "        return optimizer.lr\n",
    "    return lr\n",
    "\n",
    "def splitdata(x,inum,index):\n",
    "    da = K.int_shape(x)[1]\n",
    "    #print('data num:',da)\n",
    "    splitd = (int)(da/inum*2)\n",
    "    #test = x[:,0:splitd,0:splitd,:]\n",
    "    #print('test',test)\n",
    "    \n",
    "    if index ==0:\n",
    "        return x[:,0:splitd,0:splitd,:]\n",
    "    if index ==1:\n",
    "        return x[:,0:splitd,splitd:,:]\n",
    "    if index ==2:\n",
    "        return x[:,splitd:,0:splitd,:]\n",
    "    return x[:,splitd:,splitd:,:]\n",
    "    \n",
    "    #resu = []\n",
    "    #return  np.array(x[:,0:splitd,0:splitd,:]),  np.array(x[:,0:splitd,splitd:,:]), np.array(x[:,splitd:,0:splitd,:]), np.array(x[:,splitd:,splitd:,:])\n",
    "#K.int_shape(x)[0]\n",
    "\n",
    "def point(img,x,y):\n",
    "    cv2.circle(img,(x,y),1,(0,0,255),10)\n",
    "\n",
    "def msesum(y_true, y_pred):\n",
    "    return K.sum(K.abs(y_pred - y_true), axis=-1)*100\n",
    "\n",
    "def printResu27(modelpr,testcheck,testok):\n",
    "    img = testcheck[0:60]\n",
    "    imgok =testok[0:60]\n",
    "    predict = modelpr.predict(img)\n",
    "    predict = np.clip(predict, 0., 1.)\n",
    "    n1 = 0\n",
    "    n2 = 0\n",
    "    n3 = 0\n",
    "    nl = np.random.uniform(low = 21,high = 39,size =[1])\n",
    "    n1 = (int)(n1)-20\n",
    "    n2 = np.random.uniform(low = 21,high = 39,size =[1])\n",
    "    n2 = (int)(n2)\n",
    "    noise = np.random.uniform(low = 11,high = 19,size =[1])\n",
    "    noise =(int)((noise-11)/3)\n",
    "    n1 = (int)(n2)-20+noise\n",
    "    n3 = np.random.uniform(low = 40,high = 59,size =[1])\n",
    "    n3 = (int)(n3)\n",
    "    p1 = img[n1]\n",
    "    p2 = predict[n1]\n",
    "    p21 =imgok[n1]\n",
    "    p5 = img[n2]\n",
    "    p6 = predict[n2]\n",
    "    p61 =imgok[n2]\n",
    "        \n",
    "    p7= img[n3]\n",
    "    p8 = predict[n3]\n",
    "    p81=imgok[n3]\n",
    "    \n",
    "    \n",
    "    p1.shape = [80,80,3]\n",
    "    p2.shape = [80,80,3]\n",
    "    p21.shape = [80,80,3]\n",
    "            \n",
    "    p5.shape = [80,80,3]\n",
    "    p6.shape = [80,80,3]\n",
    "    p61.shape = [80,80,3]\n",
    "    \n",
    "    p7.shape = [80,80,3]\n",
    "    p8.shape = [80,80,3]\n",
    "    p81.shape = [80,80,3]\n",
    "    \n",
    "    p1 = p1.astype('float32')\n",
    "    p2 = p2.astype('float32')\n",
    "    p21 = p21.astype('float32')\n",
    "            \n",
    "    p5 = p5.astype('float32')\n",
    "    p6 = p6.astype('float32')\n",
    "    p61 = p61.astype('float32')\n",
    "    \n",
    "    p7 = p7.astype('float32')\n",
    "    p8 = p8.astype('float32')\n",
    "    p81 = p81.astype('float32')\n",
    "    \n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(p1)\n",
    "    plt.subplot(1, 3, 2)    \n",
    "    plt.imshow(p2)\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(p21)   \n",
    "    plt.show()\n",
    "            \n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(p5)\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(p6)\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(p61)\n",
    "    plt.show()\n",
    "    \n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(p7)\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(p8)\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(p81)\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "def printResu28(modelpr,testcheck,testok):\n",
    "    img = testcheck[0:60]\n",
    "    imgok =testok[0:60]\n",
    "    predict = modelpr.predict(img)\n",
    "    predict = np.clip(predict, 0., 1.)\n",
    "    n1 = 0\n",
    "    n2 = 0\n",
    "    n3 = 0\n",
    "    nl = np.random.uniform(low = 21,high = 39,size =[1])\n",
    "    n1 = (int)(n1)-20\n",
    "    n2 = np.random.uniform(low = 21,high = 39,size =[1])\n",
    "    n2 = (int)(n2)\n",
    "    noise = np.random.uniform(low = 11,high = 19,size =[1])\n",
    "    noise =(int)((noise-11)/3)\n",
    "    n1 = (int)(n2)-20+noise\n",
    "    n3 = np.random.uniform(low = 40,high = 59,size =[1])\n",
    "    n3 = (int)(n3)\n",
    "    p1 = img[n1]\n",
    "    p2 = predict[n1]\n",
    "    p21 =imgok[n1]\n",
    "    p5 = img[n2]\n",
    "    p6 = predict[n2]\n",
    "    p61 =imgok[n2]\n",
    "        \n",
    "    p7= img[n3]\n",
    "    p8 = predict[n3]\n",
    "    p81=imgok[n3]\n",
    "    \n",
    "    \n",
    "    p1.shape = [80,80,3]\n",
    "    p2.shape = [40,40,3]\n",
    "    p21.shape = [80,80,3]\n",
    "            \n",
    "    p5.shape = [80,80,3]\n",
    "    p6.shape = [40,40,3]\n",
    "    p61.shape = [80,80,3]\n",
    "    \n",
    "    p7.shape = [80,80,3]\n",
    "    p8.shape = [40,40,3]\n",
    "    p81.shape = [80,80,3]\n",
    "    \n",
    "    p1 = p1.astype('float32')\n",
    "    p2 = p2.astype('float32')\n",
    "    p21 = p21.astype('float32')\n",
    "            \n",
    "    p5 = p5.astype('float32')\n",
    "    p6 = p6.astype('float32')\n",
    "    p61 = p61.astype('float32')\n",
    "    \n",
    "    p7 = p7.astype('float32')\n",
    "    p8 = p8.astype('float32')\n",
    "    p81 = p81.astype('float32')\n",
    "    \n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(p1)\n",
    "    plt.subplot(1, 3, 2)    \n",
    "    plt.imshow(p2)\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(p21)   \n",
    "    plt.show()\n",
    "            \n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(p5)\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(p6)\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(p61)\n",
    "    plt.show()\n",
    "    \n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(p7)\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(p8)\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(p81)\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "\n",
    "def printResu2(modelpr):\n",
    "    printResu27(modelpr,testdataok,testdataok)\n",
    "    return\n",
    "\n",
    "def average2(inputs):      \n",
    "    \n",
    "    x =  inputs\n",
    "    x = AveragePooling2D((2, 2))(x)\n",
    "    x = AveragePooling2D((2, 2))(x)\n",
    "    layer_model = Model(inputs=inputs,outputs=x)\n",
    "    return layer_model\n",
    "\n",
    "average2 = average2(model_inputconv)\n",
    "\n",
    "\n",
    "\n",
    "def average3(inputs):      \n",
    "    \n",
    "    x =  inputs\n",
    "    x = AveragePooling2D((2, 2))(x)    \n",
    "    layer_model = Model(inputs=inputs,outputs=x)\n",
    "    return layer_model\n",
    "\n",
    "\n",
    "def average5(inputs):      \n",
    "    \n",
    "    x =  inputs\n",
    "    x = AveragePooling2D((2, 2))(x)    \n",
    "    layer_model = Model(inputs=inputs,outputs=x)\n",
    "    return layer_model\n",
    "\n",
    "\n",
    "def average6(inputs):      \n",
    "    \n",
    "    x =  inputs\n",
    "    x = AveragePooling2D((2, 2))(x)    \n",
    "    layer_model = Model(inputs=inputs,outputs=x)\n",
    "    return layer_model\n",
    "\n",
    "\n",
    "def average8(inputs):      \n",
    "    \n",
    "    x =  inputs\n",
    "    x = AveragePooling2D((2, 2))(x)    \n",
    "    layer_model = Model(inputs=inputs,outputs=x)\n",
    "    return layer_model\n",
    "\n",
    "average3 = average3(model_inputconv)\n",
    "\n",
    "average5 = average5(model_inputconv2)\n",
    "\n",
    "average6 = average6(model_inputconv9)\n",
    "\n",
    "average9 = average6(model_inputconv10)\n",
    "\n",
    "def printGen22Resu(modelpr,num,runmode,resusize):\n",
    "    if runmode==0:\n",
    "        img = testdataok[0:890]   \n",
    "    else:\n",
    "        img = testdata[0:890]   \n",
    "    imgok =testdataok[0:890]\n",
    "    predict = modelpr.predict(img)    \n",
    "    predict = np.clip(predict, 0., 1.)\n",
    "    \n",
    "    \"\"\"\n",
    "    img = np.array(img)\n",
    "    img = tf.convert_to_tensor(img)\n",
    "    img = AveragePooling2D((2, 2))(img)\n",
    "    img = AveragePooling2D((2, 2))(img)\n",
    "    img = np.array(img)\n",
    "    \"\"\"\n",
    "    if num==80:        \n",
    "        img = average9.predict(img)\n",
    "        img = np.array(img)\n",
    "        img = np.clip(img, 0., 1.)\n",
    "    if num==60:        \n",
    "        img = average6.predict(img)\n",
    "        img = np.array(img)\n",
    "        img = np.clip(img, 0., 1.)\n",
    "    if num==40:        \n",
    "        img = average3.predict(img)\n",
    "        img = np.array(img)\n",
    "        img = np.clip(img, 0., 1.)\n",
    "    if num==20:\n",
    "        if (resusize==40):\n",
    "            img = average5.predict(img)    \n",
    "        else:\n",
    "            img = average2.predict(img)    \n",
    "        img = np.array(img)\n",
    "        img = np.clip(img, 0., 1.)\n",
    "    n1 = 0\n",
    "    n2 = 0\n",
    "    n3 = 0\n",
    "    nl = np.random.uniform(low = 21,high = 399,size =[1])\n",
    "    n1 = (int)(n1)-20\n",
    "    n2 = np.random.uniform(low = 31,high = 399,size =[1])\n",
    "    n2 = (int)(n2)\n",
    "    noise = np.random.uniform(low = 111,high = 589,size =[1])\n",
    "    noise =(int)((noise-11)/3)\n",
    "    n1 = (int)(n2)-30+noise\n",
    "    n3 = np.random.uniform(low = 589,high = 789,size =[1])\n",
    "    n3 = (int)(n3)\n",
    "    p1 = img[n1]\n",
    "    p2 = predict[n1]\n",
    "    p21 =imgok[n1]\n",
    "    p5 = img[n2]\n",
    "    p6 = predict[n2]\n",
    "    p61 =imgok[n2]\n",
    "        \n",
    "    p7= img[n3]\n",
    "    p8 = predict[n3]\n",
    "    p81=imgok[n3]\n",
    "    \n",
    "    \n",
    "    p1.shape = [num,num,3]\n",
    "    p2.shape = [resusize,resusize,3]\n",
    "    p21.shape = [resusize,resusize,3]\n",
    "            \n",
    "    p5.shape = [num,num,3]\n",
    "    p6.shape = [resusize,resusize,3]\n",
    "    p61.shape = [resusize,resusize,3]\n",
    "    \n",
    "    p7.shape = [num,num,3]\n",
    "    p8.shape = [resusize,resusize,3]\n",
    "    p81.shape = [resusize,resusize,3]\n",
    "    \n",
    "    p1 = p1.astype('float32')\n",
    "    p2 = p2.astype('float32')\n",
    "    p21 = p21.astype('float32')\n",
    "            \n",
    "    p5 = p5.astype('float32')\n",
    "    p6 = p6.astype('float32')\n",
    "    p61 = p61.astype('float32')\n",
    "    \n",
    "    p7 = p7.astype('float32')\n",
    "    p8 = p8.astype('float32')\n",
    "    p81 = p81.astype('float32')\n",
    "    \n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(p1)\n",
    "    plt.subplot(1, 3, 2)    \n",
    "    plt.imshow(p2)\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(p21)   \n",
    "    plt.show()\n",
    "            \n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(p5)\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(p6)\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(p61)\n",
    "    plt.show()\n",
    "    \n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(p7)\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(p8)\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(p81)\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "def printGen23Resu(modelpr):\n",
    "    img = testdata[0:60]   \n",
    "    imgok =testdataok[0:60]\n",
    "    predict = modelpr.predict(img)    \n",
    "    predict = np.clip(predict, 0., 1.)\n",
    "    img = average3.predict(img)    \n",
    "    img = np.clip(img, 0., 1.)\n",
    "    \"\"\"\n",
    "    img = np.array(img)\n",
    "    img = tf.convert_to_tensor(img)\n",
    "    img = AveragePooling2D((2, 2))(img)\n",
    "    img = AveragePooling2D((2, 2))(img)\n",
    "    img = np.array(img)\n",
    "    \"\"\"\n",
    "    n1 = 0\n",
    "    n2 = 0\n",
    "    n3 = 0\n",
    "    nl = np.random.uniform(low = 21,high = 39,size =[1])\n",
    "    n1 = (int)(n1)-20\n",
    "    n2 = np.random.uniform(low = 21,high = 39,size =[1])\n",
    "    n2 = (int)(n2)\n",
    "    noise = np.random.uniform(low = 11,high = 19,size =[1])\n",
    "    noise =(int)((noise-11)/3)\n",
    "    n1 = (int)(n2)-20+noise\n",
    "    n3 = np.random.uniform(low = 40,high = 59,size =[1])\n",
    "    n3 = (int)(n3)\n",
    "    p1 = img[n1]\n",
    "    p2 = predict[n1]\n",
    "    p21 =imgok[n1]\n",
    "    p5 = img[n2]\n",
    "    p6 = predict[n2]\n",
    "    p61 =imgok[n2]\n",
    "        \n",
    "    p7= img[n3]\n",
    "    p8 = predict[n3]\n",
    "    p81=imgok[n3]\n",
    "    \n",
    "    \n",
    "    p1.shape = [40,40,3]\n",
    "    p2.shape = [80,80,3]\n",
    "    p21.shape = [80,80,3]\n",
    "            \n",
    "    p5.shape = [40,40,3]\n",
    "    p6.shape = [80,80,3]\n",
    "    p61.shape = [80,80,3]\n",
    "    \n",
    "    p7.shape = [40,40,3]\n",
    "    p8.shape = [80,80,3]\n",
    "    p81.shape = [80,80,3]\n",
    "    \n",
    "    p1 = p1.astype('float32')\n",
    "    p2 = p2.astype('float32')\n",
    "    p21 = p21.astype('float32')\n",
    "            \n",
    "    p5 = p5.astype('float32')\n",
    "    p6 = p6.astype('float32')\n",
    "    p61 = p61.astype('float32')\n",
    "    \n",
    "    p7 = p7.astype('float32')\n",
    "    p8 = p8.astype('float32')\n",
    "    p81 = p81.astype('float32')\n",
    "    \n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(p1)\n",
    "    plt.subplot(1, 3, 2)    \n",
    "    plt.imshow(p2)\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(p21)   \n",
    "    plt.show()\n",
    "            \n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(p5)\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(p6)\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(p61)\n",
    "    plt.show()\n",
    "    \n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(p7)\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(p8)\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(p81)\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "\n",
    "def data_label(path):\n",
    "    f = open(path+\"lable-40.txt\",\"r\")\n",
    "    j = 0\n",
    "    i = -1\n",
    "    datalist = []\n",
    "    labellist = []\n",
    "    while True:\n",
    "        for line in f.readlines():\n",
    "            i+=1\n",
    "            j +=1\n",
    "            a = line.replace(\"\\n\",\"\")\n",
    "            b = a.split(\",\")\n",
    "            lable = b[1:]\n",
    "            imgname = path+b[0]\n",
    "            images = load_img(imgname)\n",
    "            images = img_to_array(images).astype('float32')\n",
    "            image = np.expand_dims(images,axis= 0)\n",
    "            lables = np.array(lable)\n",
    "            \n",
    "            lable= lables.reshape(1,10)\n",
    "            yield(image,lable)\n",
    "\n",
    "            \n",
    "def img_conv(path):\n",
    "    f = open(path+\"lable-40.txt\",\"r\")\n",
    "    j = 0\n",
    "    i = -1\n",
    "    datalist = []\n",
    "    labellist = []\n",
    "    \n",
    "    for line in f.readlines():        \n",
    "        \n",
    "        i+=1\n",
    "        j +=1\n",
    "        a = line.replace(\"\\n\",\"\")\n",
    "        b = a.split(\" \")\n",
    "        lable = b[1:]\n",
    "        imgname = path+b[0]\n",
    "            #images = load_img(imgname)\n",
    "            #images = img_to_array(images).astype('float32')\n",
    "            #image = np.expand_dims(images,axis= 0)\n",
    "        imgs = cv2.imread(imgname)\n",
    "        image2 = cv2.resize(imgs,(80,80))\n",
    "        cv2.imwrite(imgname,image2)\n",
    "        if (j%100==99):\n",
    "            print('now proc',j)\n",
    "\n",
    "def img_custconv(path,picsize):\n",
    "    f = open(path+\"lable-40.txt\",\"r\")\n",
    "    j = 0\n",
    "    i = -1\n",
    "    datalist = []\n",
    "    labellist = []\n",
    "    \n",
    "    for line in f.readlines():        \n",
    "        \n",
    "        i+=1\n",
    "        j +=1\n",
    "        a = line.replace(\"\\n\",\"\")\n",
    "        b = a.split(\" \")\n",
    "        lable = b[1:]\n",
    "        imgname = path+b[0]\n",
    "            #images = load_img(imgname)\n",
    "            #images = img_to_array(images).astype('float32')\n",
    "            #image = np.expand_dims(images,axis= 0)\n",
    "        imgs = cv2.imread(imgname)\n",
    "        image2 = cv2.resize(imgs,(picsize,picsize))\n",
    "        cv2.imwrite(imgname,image2)\n",
    "        if (j%100==99):\n",
    "            print('now proc',j)\n",
    "            \n",
    "def img_conv2(path,inum):\n",
    "    f = open(path+\"lable-40.txt\",\"r\")\n",
    "    j = 0\n",
    "    i = -1\n",
    "    datalist = []\n",
    "    labellist = []\n",
    "    \n",
    "    for line in f.readlines():        \n",
    "        \n",
    "        i+=1\n",
    "        j +=1\n",
    "        a = line.replace(\"\\n\",\"\")\n",
    "        b = a.split(\" \")\n",
    "        lable = b[1:]\n",
    "        imgname = path+b[0]\n",
    "            #images = load_img(imgname)\n",
    "            #images = img_to_array(images).astype('float32')\n",
    "            #image = np.expand_dims(images,axis= 0)\n",
    "        imgs = cv2.imread(imgname)\n",
    "        image2 = cv2.resize(imgs,(inum,inum))\n",
    "        cv2.imwrite(imgname,image2)\n",
    "        if (j%100==99):\n",
    "            print('now proc',j)\n",
    "\n",
    "def procData():\n",
    "    print('begin proc image')\n",
    "    img_conv(trainpath2)\n",
    "    print('train images complete')\n",
    "    img_conv(testpath2)\n",
    "    print('test images complete')\n",
    "\n",
    "\n",
    "def data_labelnoisy(path,size):\n",
    "    f = open(path+\"lable-40.txt\",\"r\")\n",
    "    j = 0\n",
    "    i = -1\n",
    "    n1 = 0\n",
    "    n2 = 0\n",
    "    dataresu = []\n",
    "    datalist = []\n",
    "    bPrintpic = False\n",
    "    for line in f.readlines():        \n",
    "        i+=1\n",
    "        j +=1\n",
    "        a = line.replace(\"\\n\",\"\")\n",
    "        b = a.split(\" \")\n",
    "        lable = b[1:]\n",
    "        imgname = path+b[0]\n",
    "        \n",
    "        #images = load_img(imgname)\n",
    "        #images = img_to_array(images).astype('float32')\n",
    "        #image = np.expand_dims(images,axis= 0)\n",
    "        \n",
    "        images = load_img(imgname)\n",
    "        images = img_to_array(images).astype('float32')\n",
    "        image = np.expand_dims(images,axis= 0)\n",
    "           \n",
    "        noise_factor = 2\n",
    "        #x_train_noisy = image + (noise_factor * np.random.normal(loc=0.0, scale=2.0, size=image.shape))\n",
    "\n",
    "        w = np.random.uniform(low = -50,high = 50,size =image.shape)\n",
    "        wmul = np.random.uniform(low = 0.7,high = 1.2,size =[1])\n",
    "        #print('wmul',wmul)\n",
    "        x_train_noisy = image + w*wmul\n",
    "        image = image/255\n",
    "        x_train_noisy = x_train_noisy/255\n",
    "        x_train_noisy = np.clip(x_train_noisy, 0., 1.)            \n",
    "        \n",
    "        image = image.astype('float32')\n",
    "        x_train_noisy = x_train_noisy.astype('float32')\n",
    "        #,dtype=float32\n",
    "        #image = tf.convert_to_tensor(image)\n",
    "        #x_train_noisy = tf.convert_to_tensor(x_train_noisy)\n",
    "        image.shape = [size,size,3]\n",
    "        x_train_noisy.shape = [size,size,3]\n",
    "        datalist.append(image)\n",
    "        dataresu.append(x_train_noisy)\n",
    "        \n",
    "        if (j%3000==2999):\n",
    "            print('now proc',j)\n",
    "            if (j>30000):                \n",
    "                return dataresu,datalist,j\n",
    "        if (j==1000):\n",
    "            bPrintpic = True\n",
    "            print('w',w)\n",
    "            print('source:')\n",
    "            print(image)\n",
    "            print('conv source:')\n",
    "            print(x_train_noisy)            \n",
    "            nl = np.random.uniform(low = 100,high = 500,size =[1])\n",
    "            nl = np.random.uniform(low = 500,high = 999,size =[1])\n",
    "            n1 = (int)(n1)-500\n",
    "            n2 = np.random.uniform(low = 500,high = 999,size =[1])\n",
    "            n2 = (int)(n2)\n",
    "            n1 = (int)(n2)-500\n",
    "            p1 = dataresu[n1]\n",
    "            p2 = dataresu[n2]\n",
    "            p5 = datalist[n1]\n",
    "            p6 = datalist[n2]\n",
    "            \n",
    "            \"\"\"\n",
    "            p1 = dataresu[1]\n",
    "            p2 = dataresu[2]\n",
    "            p5 = datalist[1]\n",
    "            p6 = datalist[2]\n",
    "            \"\"\"\n",
    "            \n",
    "            p1.shape = [size,size,3]\n",
    "            p2.shape = [size,size,3]\n",
    "            \n",
    "            p5.shape = [size,size,3]\n",
    "            p6.shape = [size,size,3]\n",
    "            p1 = p1.astype('float32')\n",
    "            p2 = p2.astype('float32')\n",
    "            \n",
    "            p5 = p5.astype('float32')\n",
    "            p6 = p6.astype('float32')\n",
    "            #p1 = p1/255\n",
    "            #p2 = p2/255\n",
    "            \n",
    "            #p5 = p5/255\n",
    "            #p6 = p6/255\n",
    "            #p1 = Reshape((120,120,3))(p1)\n",
    "            #p2 = Reshape((120,120,3))(p2)\n",
    "            plt.subplot(2, 2, 1)\n",
    "            plt.imshow(p1)\n",
    "            plt.subplot(2, 2, 2)\n",
    "            plt.imshow(p2)\n",
    "            \n",
    "            plt.subplot(2, 2, 3)\n",
    "            plt.imshow(p5)\n",
    "            plt.subplot(2, 2, 4)\n",
    "            plt.imshow(p6)\n",
    "            #image.shape = [120, 120,3]\n",
    "            #plt.subplot(1, 2, 2)\n",
    "            #plt.imshow(image)\n",
    "            plt.show()\n",
    "            \n",
    "            \"\"\"\n",
    "            image = cv2.resize(x_train_noisy,(120,120))\n",
    "            image2 = cv2.resize(image,(120,120))\n",
    "            cv2.imshow('img',image)\n",
    "            cv2.imshow('img2',image2)\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows()\n",
    "           \n",
    "            \"\"\"\n",
    "    #ataresu = tf.convert_to_tensor(dataresu)\n",
    "    #datalist = tf.convert_to_tensor(datalist)\n",
    "    #traindata = np.array(traindata)\n",
    "    #traindataok= np.array(traindataok)\n",
    "    #testdata = np.array(testdata)\n",
    "    #testdataok = np.array(testdataok)\n",
    "    #dataresu = np.array(dataresu)\n",
    "    #datalist = np.array(datalist)\n",
    "    resui =(int)(i/2)\n",
    "    if (bPrintpic==False):\n",
    "        print(\"test image:\")\n",
    "        nl = np.random.uniform(low = resui+1,high = resui*2,size =[1])\n",
    "        n1 = (int)(n1)-resui\n",
    "        n2 = np.random.uniform(low = resui+1,high = resui*2,size =[1])\n",
    "        n2 = (int)(n2)\n",
    "        n1 = (int)(n2)-resui\n",
    "        p1 = dataresu[n1]\n",
    "        p2 = dataresu[n2]\n",
    "        p5 = datalist[n1]\n",
    "        p6 = datalist[n2]\n",
    "            \n",
    "            \n",
    "        p1.shape = [size,size,3]\n",
    "        p2.shape = [size,size,3]\n",
    "            \n",
    "        p5.shape = [size,size,3]\n",
    "        p6.shape = [size,size,3]\n",
    "        p1 = p1.astype('float32')\n",
    "        p2 = p2.astype('float32')\n",
    "            \n",
    "        p5 = p5.astype('float32')\n",
    "        p6 = p6.astype('float32')\n",
    "        \n",
    "        plt.subplot(2, 2, 1)\n",
    "        plt.imshow(p1)\n",
    "        plt.subplot(2, 2, 2)\n",
    "        plt.imshow(p2)\n",
    "            \n",
    "        plt.subplot(2, 2, 3)\n",
    "        plt.imshow(p5)\n",
    "        plt.subplot(2, 2, 4)\n",
    "        plt.imshow(p6)\n",
    "        plt.show()\n",
    "            \n",
    "    return dataresu,datalist,j\n",
    "\n",
    "\n",
    "def data_chnagenoisy(datalist,icount):\n",
    "   \n",
    "    j = 0\n",
    "    i = -1\n",
    "    dataresu = []\n",
    "    \n",
    "    n1 =0\n",
    "    n2 =0\n",
    "    for i in range(icount):        \n",
    "        image = datalist[i]\n",
    "       \n",
    "        tm =np.random.uniform(low = 5,high = 12,size =[1])\n",
    "        tm= (int)(tm)\n",
    "        tm2 =np.random.uniform(low = -5,high = 5,size =[1])\n",
    "        tm2= (int)(tm)\n",
    "        if tm>9:\n",
    "            w = np.random.uniform(low = -50+tm2,high = 50+tm2,size =image.shape)\n",
    "        else:\n",
    "            if tm>7:\n",
    "                w = np.random.uniform(low = -60+tm2,high = 60+tm2,size =image.shape)\n",
    "            else:\n",
    "                w = np.random.uniform(low = -30+tm2,high = 70+tm2,size =image.shape)\n",
    "        \n",
    "        if tm>9:\n",
    "            w = w*1.2\n",
    "        else:\n",
    "            if tm>7:\n",
    "                w=w*0.9\n",
    "            else:\n",
    "                w=w*0.7\n",
    "        x_train_noisy = image*255 + w\n",
    "        x_train_noisy = x_train_noisy/255\n",
    "        x_train_noisy = np.clip(x_train_noisy, 0., 1.)            \n",
    "        \n",
    "        dataresu.append(x_train_noisy)\n",
    "        \n",
    "        if (j%1000==999):\n",
    "            print('now proc',j)            \n",
    "                \n",
    "        if (i==100):\n",
    "            #print('w',w)\n",
    "            #print('source:')\n",
    "            #print(image)\n",
    "            #print('conv source:')\n",
    "            #print(x_train_noisy)            \n",
    "            nl = np.random.uniform(low = 51,high = 100,size =[1])\n",
    "            \n",
    "            n2 = np.random.uniform(low = 51,high = 100,size =[1])\n",
    "            n2 = (int)(n2)\n",
    "            n1 = n2-50\n",
    "            p1 = dataresu[n1]\n",
    "            p2 = dataresu[n2]\n",
    "            p5 = datalist[n1]\n",
    "            p6 = datalist[n2]\n",
    "            p1.shape = [80,80,3]\n",
    "            p2.shape = [80,80,3]\n",
    "            \n",
    "            p5.shape = [80,80,3]\n",
    "            p6.shape = [80,80,3]\n",
    "            p1 = p1.astype('float32')\n",
    "            p2 = p2.astype('float32')\n",
    "            \n",
    "            p5 = p5.astype('float32')\n",
    "            p6 = p6.astype('float32')\n",
    "            #p1 = p1/255\n",
    "            #p2 = p2/255\n",
    "            \n",
    "            #p5 = p5/255\n",
    "            #p6 = p6/255\n",
    "            #p1 = Reshape((120,120,3))(p1)\n",
    "            #p2 = Reshape((120,120,3))(p2)\n",
    "            plt.subplot(2, 2, 1)\n",
    "            plt.imshow(p1)\n",
    "            plt.subplot(2, 2, 2)\n",
    "            plt.imshow(p2)\n",
    "            \n",
    "            plt.subplot(2, 2, 3)\n",
    "            plt.imshow(p5)\n",
    "            plt.subplot(2, 2, 4)\n",
    "            plt.imshow(p6)\n",
    "            #image.shape = [120, 120,3]\n",
    "            #plt.subplot(1, 2, 2)\n",
    "            #plt.imshow(image)\n",
    "            plt.show()           \n",
    "    return dataresu\n",
    "\n",
    "\n",
    "def data_chnagenoisy2(datalist,icount,nproc):\n",
    "   \n",
    "    j = 0\n",
    "    i = -1\n",
    "    dataresu = []\n",
    "    \n",
    "    n1 =0\n",
    "    n2 =0\n",
    "    for i in range(icount):        \n",
    "        image = datalist[i]        \n",
    "        tm =np.random.uniform(low = 5,high = 12,size =[1])\n",
    "        tm= (int)(tm)\n",
    "        tm2 =np.random.uniform(low = -5,high = 5,size =[1])\n",
    "        tm2= (int)(tm)\n",
    "        tm5 =np.random.uniform(low = -2,high = 7,size =[1])\n",
    "        tm5= (int)(tm)\n",
    "        tm3 =np.random.uniform(low = -3,high = tm5+1,size =[1])\n",
    "        tm3= (int)(tm)\n",
    "        if tm>9:\n",
    "            w = np.random.uniform(low = -50+tm2+tm3,high = 50+tm2+tm3,size =image.shape)\n",
    "        else:\n",
    "            if tm>7:\n",
    "                w = np.random.uniform(low = -60+tm2+tm3,high = 60+tm2+tm3,size =image.shape)\n",
    "            else:\n",
    "                w = np.random.uniform(low = -30+tm2+tm3,high = 70+tm2+tm3,size =image.shape)\n",
    "        if tm>9:\n",
    "            w = w*1.2\n",
    "        else:\n",
    "            if tm>7:\n",
    "                w=w*0.9\n",
    "            else:\n",
    "                w=w*0.7\n",
    "        tm2 =np.random.uniform(low = 6,high = 66,size =[1])\n",
    "        tm2= (int)(tm2)\n",
    "        if tm2>12:\n",
    "            if nproc==0:\n",
    "                x_train_noisy = image*255 + w* ((tm2-12)/50+0.1)\n",
    "            if nproc==1:\n",
    "                x_train_noisy = image*255 + w* ((tm2-12)/80+0.1)\n",
    "            if nproc==2:\n",
    "                x_train_noisy = image*255 + w* ((tm2-12)/120+0.1)\n",
    "            x_train_noisy = x_train_noisy/255\n",
    "        else:\n",
    "            x_train_noisy = image\n",
    "        x_train_noisy = np.clip(x_train_noisy, 0., 1.)            \n",
    "        \n",
    "        dataresu.append(x_train_noisy)\n",
    "        \n",
    "        if (j%1000==999):\n",
    "            print('now proc',j)            \n",
    "                \n",
    "        if (i==100):\n",
    "            #print('w',w)\n",
    "            #print('source:')\n",
    "            #print(image)\n",
    "            #print('conv source:')\n",
    "            #print(x_train_noisy)            \n",
    "            nl = np.random.uniform(low = 51,high = 100,size =[1])\n",
    "            \n",
    "            n2 = np.random.uniform(low = 51,high = 100,size =[1])\n",
    "            n2 = (int)(n2)\n",
    "            n1 = n2-50\n",
    "            p1 = dataresu[n1]\n",
    "            p2 = dataresu[n2]\n",
    "            p5 = datalist[n1]\n",
    "            p6 = datalist[n2]\n",
    "            p1.shape = [80,80,3]\n",
    "            p2.shape = [80,80,3]\n",
    "            \n",
    "            p5.shape = [80,80,3]\n",
    "            p6.shape = [80,80,3]\n",
    "            p1 = p1.astype('float32')\n",
    "            p2 = p2.astype('float32')\n",
    "            \n",
    "            p5 = p5.astype('float32')\n",
    "            p6 = p6.astype('float32')\n",
    "            #p1 = p1/255\n",
    "            #p2 = p2/255\n",
    "            \n",
    "            #p5 = p5/255\n",
    "            #p6 = p6/255\n",
    "            #p1 = Reshape((120,120,3))(p1)\n",
    "            #p2 = Reshape((120,120,3))(p2)\n",
    "            plt.subplot(2, 2, 1)\n",
    "            plt.imshow(p1)\n",
    "            plt.subplot(2, 2, 2)\n",
    "            plt.imshow(p2)\n",
    "            \n",
    "            plt.subplot(2, 2, 3)\n",
    "            plt.imshow(p5)\n",
    "            plt.subplot(2, 2, 4)\n",
    "            plt.imshow(p6)\n",
    "            #image.shape = [120, 120,3]\n",
    "            #plt.subplot(1, 2, 2)\n",
    "            #plt.imshow(image)\n",
    "            plt.show()           \n",
    "    return dataresu\n",
    "\n",
    "\n",
    "\n",
    "def printResu3(modeprev,modelpr,chang,num):\n",
    "    if  chang:\n",
    "        img = testdata[0:60]\n",
    "    else:\n",
    "        img = testdataok[0:60]\n",
    "    imgok =testdataok[0:60]\n",
    "    predictPrev = modeprev.predict(img)\n",
    "    predictPrev = np.clip(predictPrev, 0., 1.)\n",
    "    if chang:\n",
    "        predictPrev = data_chnagenoisy2(predictPrev,60,0)\n",
    "        predictPrev = np.clip(predictPrev, 0., 1.)\n",
    "        predictPrev = np.array(predictPrev)\n",
    "    \n",
    "    predict = modelpr.predict(predictPrev)\n",
    "    predict = np.clip(predict, 0., 1.)\n",
    "    if num==40:        \n",
    "        img = average3.predict(img)\n",
    "        img = np.array(img)\n",
    "        img = np.clip(img, 0., 1.)\n",
    "    if num==20:\n",
    "        img = average2.predict(img)    \n",
    "        img = np.array(img)\n",
    "        img = np.clip(img, 0., 1.)\n",
    "    n1 = 0\n",
    "    n2 = 0\n",
    "    n3 = 0\n",
    "    noise = np.random.uniform(low = 11,high = 19,size =[1])\n",
    "    noise =(int)((noise-11)/3)\n",
    "    nl = np.random.uniform(low = 21,high = 39,size =[1])\n",
    "    n1 = (int)(n1)-20\n",
    "    n2 = np.random.uniform(low = 21,high = 39,size =[1])\n",
    "    n2 = (int)(n2)   \n",
    "    n1 = (int)(n2)-20+noise\n",
    "    n3 = np.random.uniform(low = 40,high = 59,size =[1])\n",
    "    n3 = (int)(n3)\n",
    "    p1 = img[n1]\n",
    "    p11 = predictPrev[n1]\n",
    "    p2 = predict[n1]\n",
    "    p21 =imgok[n1]\n",
    "    \n",
    "    p5 = img[n2]\n",
    "    p51 = predictPrev[n2]\n",
    "    p6 = predict[n2]\n",
    "    p61 =imgok[n2]\n",
    "        \n",
    "    p7= img[n3]\n",
    "    p71 = predictPrev[n3]\n",
    "    p8 = predict[n3]\n",
    "    p81=imgok[n3]\n",
    "    \n",
    "    \n",
    "    p1.shape = [num,num,3]\n",
    "    p11.shape = [80,80,3]\n",
    "    p2.shape = [80,80,3]\n",
    "    p21.shape = [80,80,3]\n",
    "            \n",
    "    p5.shape = [num,num,3]\n",
    "    p51.shape = [80,80,3]\n",
    "    p6.shape = [80,80,3]\n",
    "    p61.shape = [80,80,3]\n",
    "    \n",
    "    p7.shape = [num,num,3]\n",
    "    p71.shape = [80,80,3]\n",
    "    p8.shape = [80,80,3]\n",
    "    p81.shape = [80,80,3]\n",
    "    \n",
    "    p1 = p1.astype('float32')\n",
    "    p11 = p11.astype('float32')\n",
    "    p2 = p2.astype('float32')\n",
    "    p21 = p21.astype('float32')\n",
    "            \n",
    "    p5 = p5.astype('float32')\n",
    "    p51 = p51.astype('float32')\n",
    "    p6 = p6.astype('float32')\n",
    "    p61 = p61.astype('float32')\n",
    "    \n",
    "    p7 = p7.astype('float32')\n",
    "    p71 = p71.astype('float32')\n",
    "    p8 = p8.astype('float32')\n",
    "    p81 = p81.astype('float32')\n",
    "    \n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.imshow(p1)\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.imshow(p11)\n",
    "    plt.subplot(2, 2, 3)    \n",
    "    plt.imshow(p2)\n",
    "    plt.subplot(2, 2, 4)\n",
    "    plt.imshow(p21)   \n",
    "    plt.show()\n",
    "            \n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.imshow(p5)\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.imshow(p51)\n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.imshow(p6)\n",
    "    plt.subplot(2, 2, 4)\n",
    "    plt.imshow(p61)\n",
    "    plt.show()\n",
    "    \n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.imshow(p7)\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.imshow(p71)\n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.imshow(p8)\n",
    "    plt.subplot(2, 2, 4)\n",
    "    plt.imshow(p81)\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "\n",
    "\n",
    "def vgggen5_12_Nextbak(inputs,num):\n",
    "    weight_decay = 0.0005    \n",
    "       \n",
    "   \n",
    "    x6 = Lambda(sliceuse,output_shape=(20,20,1),arguments={'index':num})(inputs)\n",
    "    x6 = Reshape((20,20,1))(x6)\n",
    "    \n",
    "    x=Conv2D(filters=32,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x6)\n",
    "    x= BatchNormalization(axis=chanDim)(x)\n",
    "    x= LeakyReLU(alpha=0.05)(x)       \n",
    "  \n",
    "    \n",
    "    x=Conv2D(filters=32,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x)\n",
    "    x= BatchNormalization(axis=chanDim)(x)\n",
    "    x1= LeakyReLU(alpha=0.05)(x) \n",
    "    \n",
    "    x5=Conv2D(filters=64,kernel_size=(3,3),strides=2,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x1)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)\n",
    "    \n",
    "    x5=Conv2D(filters=64,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)\n",
    "    \n",
    "    x5=Conv2D(filters=64,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)\n",
    "    \n",
    "           \n",
    "    x5= UpSampling2D()(x5)\n",
    "        \n",
    "    \n",
    "    x5=Conv2D(filters=32,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)\n",
    "    \n",
    "    x5=Conv2D(filters=32,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)\n",
    "    \n",
    "\n",
    "    x5=Conv2D(filters=1,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)     \n",
    "    #20*20\n",
    "  \n",
    "    x7= UpSampling2D()(x5)  #40*40 \n",
    "    \n",
    "    x7=Conv2D(filters=32,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x7)\n",
    "    x7= BatchNormalization(axis=chanDim)(x7)\n",
    "    x7= LeakyReLU(alpha=0.05)(x7)\n",
    "    \n",
    "    x7=Conv2D(filters=32,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x7)\n",
    "    x7= BatchNormalization(axis=chanDim)(x7)\n",
    "    x7= LeakyReLU(alpha=0.05)(x7)\n",
    "    \n",
    "    x7= UpSampling2D()(x7)  #80*80\n",
    "    \n",
    "    x7=Conv2D(filters=32,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x7)\n",
    "    x7= BatchNormalization(axis=chanDim)(x7)\n",
    "    x7= LeakyReLU(alpha=0.05)(x7)\n",
    "    \n",
    "    x7=Conv2D(filters=32,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x7)\n",
    "    x7= BatchNormalization(axis=chanDim)(x7)\n",
    "    x7= LeakyReLU(alpha=0.05)(x7)\n",
    "    \n",
    "    x7=Conv2D(filters=1,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x7)\n",
    "    x7= BatchNormalization(axis=chanDim)(x7)\n",
    "    x7= LeakyReLU(alpha=0.05)(x7)\n",
    "    \n",
    "    #x3 = Lambda(lambda t: t[:,:,:,0])(input)\n",
    "    #xu = MaxPooling2D(pool_size=(2,2))(inputs)\n",
    "    #xc = Lambda(sliceuse,output_shape=(40,40,1),arguments={'index':0})(xu)    \n",
    "     \n",
    "    #xu = MaxPooling2D(pool_size=(2,2))(inputs)\n",
    "    xc = Lambda(sliceuse,output_shape=(20,20,1),arguments={'index':num})(inputs)\n",
    "    xc = Reshape((20,20,1))(xc)  \n",
    "    \n",
    "    xr1 = Lambda(splitdata,output_shape=(10,10,1),arguments={'index':0,'inum':4})(xc)    \n",
    "    xr2 = Lambda(splitdata,output_shape=(10,10,1),arguments={'index':1,'inum':4})(xc)    \n",
    "    xr3 = Lambda(splitdata,output_shape=(10,10,1),arguments={'index':2,'inum':4})(xc)    \n",
    "    xr4 = Lambda(splitdata,output_shape=(10,10,1),arguments={'index':3,'inum':4})(xc)    \n",
    "    \n",
    "    #xr1,xr2,xr3,xr4 = Lambda(splitdata,arguments={'index':0,'inum':4})(xc)    \n",
    "    #xr = np.array(Lambda(splitdata,output_shape=(20,20,1),arguments={'index':0,'inum':4})(xc)) \n",
    "    #xr1,xr2,xr3,xr4 = Lambda(splitdata,output_shape=(20,20,1),arguments={'index':3,'inum':4})(xc)\n",
    "    xr = [xr1,xr2,xr3,xr4]\n",
    "    # ,output_shape=(20,20,1)\n",
    "    \n",
    "    x3 = xr\n",
    "    \n",
    "    for m in range(4):        \n",
    "        x3[m] = Reshape((10,10,1))(xr[m])\n",
    "        x3[m] = Flatten()(x3[m])   \n",
    "        x3[m] = Dense(500 ,kernel_regularizer=regularizers.l2(weight_decay))(x3[m]) \n",
    "    #activation=\"relu\",\n",
    "        x3[m]= LeakyReLU(alpha=0.05)(x3[m])\n",
    "        x3[m] = Dense(800 ,kernel_regularizer=regularizers.l2(weight_decay))(x3[m])\n",
    "        x3[m]= LeakyReLU(alpha=0.05)(x3[m])\n",
    "        x3[m] = Dense(1000 ,kernel_regularizer=regularizers.l2(weight_decay))(x3[m])\n",
    "        x3[m]= LeakyReLU(alpha=0.05)(x3[m])\n",
    "        x3[m] = Dense(40*40 ,kernel_regularizer=regularizers.l2(weight_decay))(x3[m])\n",
    "        x3[m]= LeakyReLU(alpha=0.05)(x3[m])\n",
    "        x3[m] = Reshape((40,40,1))(x3[m])\n",
    "         \n",
    "    x3resu =concatenate([x3[0],x3[1],x3[2],x3[3]])\n",
    "    x3resu =Reshape((80,80,1))(x3resu)\n",
    "    \n",
    "    x10 = [xr1,xr2,xr3,xr4]\n",
    "    for m in range(4):\n",
    "        x10[m] = Reshape((10,10,1))(x10[m])\n",
    "        x10[m] = Flatten()(x10[m])   \n",
    "        x10[m] = Dense(400 ,kernel_regularizer=regularizers.l2(weight_decay))(x10[m]) \n",
    "        #activation=\"relu\",\n",
    "        x10[m]= LeakyReLU(alpha=0.05)(x10[m])\n",
    "        x10[m] = Dense(900 ,kernel_regularizer=regularizers.l2(weight_decay))(x10[m])\n",
    "        x10[m]= LeakyReLU(alpha=0.05)(x10[m])\n",
    "        x10[m] = Dense(40*40 ,kernel_regularizer=regularizers.l2(weight_decay))(x10[m])\n",
    "        x10[m]= LeakyReLU(alpha=0.05)(x10[m])\n",
    "        x10[m] = Reshape((40,40,1))(x10[m]) \n",
    "          \n",
    "    x10resu =concatenate([x10[0],x10[1],x10[2],x10[3]])\n",
    "    x10resu =Reshape((80,80,1))(x10resu)\n",
    "    \n",
    "    \n",
    "    x11 = x6\n",
    "    x11=Conv2D(filters=32,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x11)\n",
    "    x11= BatchNormalization(axis=chanDim)(x11)\n",
    "    x11= LeakyReLU(alpha=0.05)(x11)   \n",
    "    \n",
    "    x11= UpSampling2D()(x11)\n",
    "    \n",
    "    x11=Conv2D(filters=32,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x11)\n",
    "    x11= BatchNormalization(axis=chanDim)(x11)\n",
    "    x11= LeakyReLU(alpha=0.05)(x11)   \n",
    "    \n",
    "    x11= UpSampling2D()(x11)\n",
    "    \n",
    "    x11=Conv2D(filters=32,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x11)\n",
    "    x11= BatchNormalization(axis=chanDim)(x11)\n",
    "    x11= LeakyReLU(alpha=0.05)(x11)      \n",
    "    \n",
    "    x11=Conv2D(filters=1,kernel_size=(3,3),strides=1,padding=\"same\",activation=\"relu\",kernel_regularizer=regularizers.l2(weight_decay))(x11)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    x=  Add()([x3resu,x7,x10resu,x11])\n",
    "    #xrsu = Merge([ x,x2,x3],mode='concat')\n",
    "    model = Model(inputs=[inputs],outputs=x,name='vgggen5_12_Nextbak'+str(num))\n",
    "    return model\n",
    "\n",
    "def vgggen5_12_Next2(inputs,num):\n",
    "    weight_decay = 0.0005    \n",
    "       \n",
    "   \n",
    "    x6 = Lambda(sliceuse,output_shape=(20,20,1),arguments={'index':num})(inputs)\n",
    "    x6 = Reshape((20,20,1))(x6)\n",
    "    \n",
    "    x=Conv2D(filters=32,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x6)\n",
    "    x= BatchNormalization(axis=chanDim)(x)\n",
    "    x= LeakyReLU(alpha=0.05)(x)       \n",
    "  \n",
    "    \n",
    "    x=Conv2D(filters=32,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x)\n",
    "    x= BatchNormalization(axis=chanDim)(x)\n",
    "    x1= LeakyReLU(alpha=0.05)(x) \n",
    "    \n",
    "    x5=Conv2D(filters=64,kernel_size=(3,3),strides=2,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x1)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)\n",
    "    \n",
    "    x5=Conv2D(filters=64,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)\n",
    "    \n",
    "    x5=Conv2D(filters=64,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)\n",
    "    \n",
    "           \n",
    "    x5= UpSampling2D()(x5)\n",
    "        \n",
    "    \n",
    "    x5=Conv2D(filters=32,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)\n",
    "    \n",
    "    x5=Conv2D(filters=32,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)\n",
    "    \n",
    "\n",
    "    x5=Conv2D(filters=1,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)     \n",
    "    #20*20\n",
    "  \n",
    "    x7= UpSampling2D()(x5)  #40*40 \n",
    "    \n",
    "    x7=Conv2D(filters=32,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x7)\n",
    "    x7= BatchNormalization(axis=chanDim)(x7)\n",
    "    x7= LeakyReLU(alpha=0.05)(x7)\n",
    "    \n",
    "    x7=Conv2D(filters=32,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x7)\n",
    "    x7= BatchNormalization(axis=chanDim)(x7)\n",
    "    x7= LeakyReLU(alpha=0.05)(x7)\n",
    "    \n",
    "    x7= UpSampling2D()(x7)  #80*80\n",
    "    \n",
    "    x7=Conv2D(filters=32,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x7)\n",
    "    x7= BatchNormalization(axis=chanDim)(x7)\n",
    "    x7= LeakyReLU(alpha=0.05)(x7)\n",
    "    \n",
    "    x7=Conv2D(filters=32,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x7)\n",
    "    x7= BatchNormalization(axis=chanDim)(x7)\n",
    "    x7= LeakyReLU(alpha=0.05)(x7)\n",
    "    \n",
    "    x7=Conv2D(filters=1,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x7)\n",
    "    x7= BatchNormalization(axis=chanDim)(x7)\n",
    "    x7= LeakyReLU(alpha=0.05)(x7)\n",
    "    \n",
    "    #x3 = Lambda(lambda t: t[:,:,:,0])(input)\n",
    "    #xu = MaxPooling2D(pool_size=(2,2))(inputs)\n",
    "    #xc = Lambda(sliceuse,output_shape=(40,40,1),arguments={'index':0})(xu)    \n",
    "     \n",
    "    #xu = MaxPooling2D(pool_size=(2,2))(inputs)\n",
    "    xc = Lambda(sliceuse,output_shape=(20,20,1),arguments={'index':num})(inputs)\n",
    "    xc = Reshape((20,20,1))(xc)  \n",
    "    \n",
    "    xr1 = Lambda(splitdata,output_shape=(10,10,1),arguments={'index':0,'inum':4})(xc)    \n",
    "    xr2 = Lambda(splitdata,output_shape=(10,10,1),arguments={'index':1,'inum':4})(xc)    \n",
    "    xr3 = Lambda(splitdata,output_shape=(10,10,1),arguments={'index':2,'inum':4})(xc)    \n",
    "    xr4 = Lambda(splitdata,output_shape=(10,10,1),arguments={'index':3,'inum':4})(xc)    \n",
    "    \n",
    "    #xr1,xr2,xr3,xr4 = Lambda(splitdata,arguments={'index':0,'inum':4})(xc)    \n",
    "    #xr = np.array(Lambda(splitdata,output_shape=(20,20,1),arguments={'index':0,'inum':4})(xc)) \n",
    "    #xr1,xr2,xr3,xr4 = Lambda(splitdata,output_shape=(20,20,1),arguments={'index':3,'inum':4})(xc)\n",
    "    xr = [xr1,xr2,xr3,xr4]\n",
    "    # ,output_shape=(20,20,1)\n",
    "    \n",
    "    x3 = xr\n",
    "    \n",
    "    for m in range(4):        \n",
    "        x3[m] = Reshape((10,10,1))(xr[m])\n",
    "        x3[m] = Flatten()(x3[m])   \n",
    "        x3[m] = Dense(500 ,kernel_regularizer=regularizers.l2(weight_decay))(x3[m]) \n",
    "    #activation=\"relu\",\n",
    "        x3[m]= LeakyReLU(alpha=0.05)(x3[m])\n",
    "        x3[m] = Dense(800 ,kernel_regularizer=regularizers.l2(weight_decay))(x3[m])\n",
    "        x3[m]= LeakyReLU(alpha=0.05)(x3[m])\n",
    "        x3[m] = Dense(1000 ,kernel_regularizer=regularizers.l2(weight_decay))(x3[m])\n",
    "        x3[m]= LeakyReLU(alpha=0.05)(x3[m])        \n",
    "        x3[m] = Dense(1200 ,kernel_regularizer=regularizers.l2(weight_decay))(x3[m])\n",
    "        x3[m]= LeakyReLU(alpha=0.05)(x3[m])\n",
    "        x3[m] = Dense(40*40 ,kernel_regularizer=regularizers.l2(weight_decay))(x3[m])\n",
    "        x3[m]= LeakyReLU(alpha=0.05)(x3[m])\n",
    "        x3[m] = Reshape((40,40,1))(x3[m])\n",
    "         \n",
    "    x3resu =concatenate([x3[0],x3[1],x3[2],x3[3]])\n",
    "    x3resu =Reshape((80,80,1))(x3resu)\n",
    "    \n",
    "    x10 = [xr1,xr2,xr3,xr4]\n",
    "    for m in range(4):\n",
    "        x10[m] = Reshape((10,10,1))(x10[m])\n",
    "        x10[m] = Flatten()(x10[m])   \n",
    "        x10[m] = Dense(400 ,kernel_regularizer=regularizers.l2(weight_decay))(x10[m]) \n",
    "        #activation=\"relu\",\n",
    "        x10[m]= LeakyReLU(alpha=0.05)(x10[m])\n",
    "        x10[m] = Dense(900 ,kernel_regularizer=regularizers.l2(weight_decay))(x10[m])\n",
    "        x10[m]= LeakyReLU(alpha=0.05)(x10[m])\n",
    "        x10[m] = Dense(1200 ,kernel_regularizer=regularizers.l2(weight_decay))(x10[m])\n",
    "        x10[m]= LeakyReLU(alpha=0.05)(x10[m])\n",
    "        x10[m] = Dense(40*40 ,kernel_regularizer=regularizers.l2(weight_decay))(x10[m])\n",
    "        x10[m]= LeakyReLU(alpha=0.05)(x10[m])\n",
    "        x10[m] = Reshape((40,40,1))(x10[m]) \n",
    "          \n",
    "    x10resu =concatenate([x10[0],x10[1],x10[2],x10[3]])\n",
    "    x10resu =Reshape((80,80,1))(x10resu)\n",
    "    \n",
    "    \n",
    "    x11 = x6\n",
    "    x11=Conv2D(filters=32,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x11)\n",
    "    x11= BatchNormalization(axis=chanDim)(x11)\n",
    "    x11= LeakyReLU(alpha=0.05)(x11)   \n",
    "    \n",
    "    x11= UpSampling2D()(x11)\n",
    "    \n",
    "    x11=Conv2D(filters=32,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x11)\n",
    "    x11= BatchNormalization(axis=chanDim)(x11)\n",
    "    x11= LeakyReLU(alpha=0.05)(x11)   \n",
    "    \n",
    "    x11= UpSampling2D()(x11)\n",
    "    \n",
    "    x11=Conv2D(filters=32,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x11)\n",
    "    x11= BatchNormalization(axis=chanDim)(x11)\n",
    "    x11= LeakyReLU(alpha=0.05)(x11)      \n",
    "    \n",
    "    x11=Conv2D(filters=1,kernel_size=(3,3),strides=1,padding=\"same\",activation=\"relu\",kernel_regularizer=regularizers.l2(weight_decay))(x11)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    x=  Add()([x3resu,x7,x10resu,x11])\n",
    "    #xrsu = Merge([ x,x2,x3],mode='concat')\n",
    "    model = Model(inputs=[inputs],outputs=x,name='vgggen5_12_Next2'+str(num))\n",
    "    return model\n",
    "\n",
    "def vgggen5_12_Next20_20(inputs,num):\n",
    "    weight_decay = 0.0005    \n",
    "       \n",
    "   \n",
    "    x6 = Lambda(sliceuse,output_shape=(20,20,1),arguments={'index':num})(inputs)\n",
    "    x6 = Reshape((20,20,1))(x6)\n",
    "    \n",
    "    x=Conv2D(filters=32,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x6)\n",
    "    x= BatchNormalization(axis=chanDim)(x)\n",
    "    x= LeakyReLU(alpha=0.05)(x)       \n",
    "  \n",
    "    \n",
    "    x=Conv2D(filters=32,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x)\n",
    "    x= BatchNormalization(axis=chanDim)(x)\n",
    "    x1= LeakyReLU(alpha=0.05)(x) \n",
    "    \n",
    "    x5=Conv2D(filters=64,kernel_size=(3,3),strides=2,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x1)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)\n",
    "    \n",
    "    x5=Conv2D(filters=64,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)\n",
    "    \n",
    "    x5=Conv2D(filters=64,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)\n",
    "    \n",
    "           \n",
    "    x5= UpSampling2D()(x5)\n",
    "        \n",
    "    \n",
    "    x5=Conv2D(filters=32,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)\n",
    "    \n",
    "    x5=Conv2D(filters=32,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)\n",
    "    \n",
    "\n",
    "    x5=Conv2D(filters=1,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)     \n",
    "    #20*20\n",
    "  \n",
    "    x7= UpSampling2D()(x5)  #40*40 \n",
    "    \n",
    "    x7=Conv2D(filters=32,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x7)\n",
    "    x7= BatchNormalization(axis=chanDim)(x7)\n",
    "    x7= LeakyReLU(alpha=0.05)(x7)\n",
    "    \n",
    "    x7=Conv2D(filters=32,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x7)\n",
    "    x7= BatchNormalization(axis=chanDim)(x7)\n",
    "    x7= LeakyReLU(alpha=0.05)(x7)\n",
    "    \n",
    "    #x7= UpSampling2D()(x7)  #80*80\n",
    "    \n",
    "    x7=Conv2D(filters=32,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x7)\n",
    "    x7= BatchNormalization(axis=chanDim)(x7)\n",
    "    x7= LeakyReLU(alpha=0.05)(x7)\n",
    "    \n",
    "    x7=Conv2D(filters=32,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x7)\n",
    "    x7= BatchNormalization(axis=chanDim)(x7)\n",
    "    x7= LeakyReLU(alpha=0.05)(x7)\n",
    "    \n",
    "    x7=Conv2D(filters=1,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x7)\n",
    "    x7= BatchNormalization(axis=chanDim)(x7)\n",
    "    x7= LeakyReLU(alpha=0.05)(x7)\n",
    "    \n",
    "    #x3 = Lambda(lambda t: t[:,:,:,0])(input)\n",
    "    #xu = MaxPooling2D(pool_size=(2,2))(inputs)\n",
    "    #xc = Lambda(sliceuse,output_shape=(40,40,1),arguments={'index':0})(xu)    \n",
    "     \n",
    "    #xu = MaxPooling2D(pool_size=(2,2))(inputs)\n",
    "    xc = Lambda(sliceuse,output_shape=(20,20,1),arguments={'index':num})(inputs)\n",
    "    xc = Reshape((20,20,1))(xc)  \n",
    "    \n",
    "    xr1 = Lambda(splitdata,output_shape=(10,10,1),arguments={'index':0,'inum':4})(xc)    \n",
    "    xr2 = Lambda(splitdata,output_shape=(10,10,1),arguments={'index':1,'inum':4})(xc)    \n",
    "    xr3 = Lambda(splitdata,output_shape=(10,10,1),arguments={'index':2,'inum':4})(xc)    \n",
    "    xr4 = Lambda(splitdata,output_shape=(10,10,1),arguments={'index':3,'inum':4})(xc)    \n",
    "    \n",
    "    #xr1,xr2,xr3,xr4 = Lambda(splitdata,arguments={'index':0,'inum':4})(xc)    \n",
    "    #xr = np.array(Lambda(splitdata,output_shape=(20,20,1),arguments={'index':0,'inum':4})(xc)) \n",
    "    #xr1,xr2,xr3,xr4 = Lambda(splitdata,output_shape=(20,20,1),arguments={'index':3,'inum':4})(xc)\n",
    "    xr = [xr1,xr2,xr3,xr4]\n",
    "    # ,output_shape=(20,20,1)\n",
    "    \n",
    "    x3 = xr\n",
    "    \n",
    "    for m in range(4):        \n",
    "        x3[m] = Reshape((10,10,1))(xr[m])\n",
    "        x3[m] = Flatten()(x3[m])   \n",
    "        x3[m] = Dense(500 ,kernel_regularizer=regularizers.l2(weight_decay))(x3[m]) \n",
    "    #activation=\"relu\",\n",
    "        x3[m]= LeakyReLU(alpha=0.05)(x3[m])\n",
    "        x3[m] = Dense(800 ,kernel_regularizer=regularizers.l2(weight_decay))(x3[m])\n",
    "        x3[m]= LeakyReLU(alpha=0.05)(x3[m])\n",
    "        x3[m] = Dense(1000 ,kernel_regularizer=regularizers.l2(weight_decay))(x3[m])\n",
    "        x3[m]= LeakyReLU(alpha=0.05)(x3[m])        \n",
    "        x3[m] = Dense(1200 ,kernel_regularizer=regularizers.l2(weight_decay))(x3[m])\n",
    "        x3[m]= LeakyReLU(alpha=0.05)(x3[m])\n",
    "        x3[m] = Dense(600 ,kernel_regularizer=regularizers.l2(weight_decay))(x3[m])\n",
    "        x3[m]= LeakyReLU(alpha=0.05)(x3[m])\n",
    "        x3[m] = Dense(1200 ,kernel_regularizer=regularizers.l2(weight_decay))(x3[m])\n",
    "        x3[m]= LeakyReLU(alpha=0.05)(x3[m])        \n",
    "        x3[m] = Dense(600 ,kernel_regularizer=regularizers.l2(weight_decay))(x3[m])        \n",
    "        x3[m]= LeakyReLU(alpha=0.05)(x3[m])\n",
    "        x3[m] = Dense(1200 ,kernel_regularizer=regularizers.l2(weight_decay))(x3[m])\n",
    "        x3[m]= LeakyReLU(alpha=0.05)(x3[m])        \n",
    "        x3[m] = Dense(600 ,kernel_regularizer=regularizers.l2(weight_decay))(x3[m])        \n",
    "        x3[m]= LeakyReLU(alpha=0.05)(x3[m])\n",
    "        x3[m] = Dense(20*20 ,kernel_regularizer=regularizers.l2(weight_decay))(x3[m])\n",
    "        x3[m]= LeakyReLU(alpha=0.05)(x3[m])\n",
    "        x3[m] = Reshape((20,20,1))(x3[m])\n",
    "         \n",
    "    x3resu =concatenate([x3[0],x3[1],x3[2],x3[3]])\n",
    "    x3resu =Reshape((40,40,1))(x3resu)\n",
    "    \n",
    "    x10 = [xr1,xr2,xr3,xr4]\n",
    "    for m in range(4):\n",
    "        x10[m] = Reshape((10,10,1))(x10[m])\n",
    "        x10[m] = Flatten()(x10[m])   \n",
    "        x10[m] = Dense(400 ,kernel_regularizer=regularizers.l2(weight_decay))(x10[m]) \n",
    "        #activation=\"relu\",\n",
    "        x10[m]= LeakyReLU(alpha=0.05)(x10[m])\n",
    "        x10[m] = Dense(900 ,kernel_regularizer=regularizers.l2(weight_decay))(x10[m])\n",
    "        x10[m]= LeakyReLU(alpha=0.05)(x10[m])\n",
    "        x10[m] = Dense(1200 ,kernel_regularizer=regularizers.l2(weight_decay))(x10[m])\n",
    "        x10[m]= LeakyReLU(alpha=0.05)(x10[m])\n",
    "        x3[m] = Dense(600 ,kernel_regularizer=regularizers.l2(weight_decay))(x3[m])\n",
    "        x3[m]= LeakyReLU(alpha=0.05)(x3[m])\n",
    "        x3[m] = Dense(1200 ,kernel_regularizer=regularizers.l2(weight_decay))(x3[m])\n",
    "        x3[m]= LeakyReLU(alpha=0.05)(x3[m])        \n",
    "        x3[m] = Dense(600 ,kernel_regularizer=regularizers.l2(weight_decay))(x3[m])        \n",
    "        x3[m]= LeakyReLU(alpha=0.05)(x3[m])\n",
    "        x10[m] = Dense(20*20 ,kernel_regularizer=regularizers.l2(weight_decay))(x10[m])\n",
    "        x10[m]= LeakyReLU(alpha=0.05)(x10[m])\n",
    "        x10[m] = Reshape((20,20,1))(x10[m]) \n",
    "          \n",
    "    x10resu =concatenate([x10[0],x10[1],x10[2],x10[3]])\n",
    "    x10resu =Reshape((40,40,1))(x10resu)\n",
    "    \n",
    "    \n",
    "    x11 = x6\n",
    "    x11=Conv2D(filters=32,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x11)\n",
    "    x11= BatchNormalization(axis=chanDim)(x11)\n",
    "    x11= LeakyReLU(alpha=0.05)(x11)   \n",
    "    \n",
    "    x11= UpSampling2D()(x11)\n",
    "    \n",
    "    x11=Conv2D(filters=32,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x11)\n",
    "    x11= BatchNormalization(axis=chanDim)(x11)\n",
    "    x11= LeakyReLU(alpha=0.05)(x11)   \n",
    "    \n",
    "    #x11= UpSampling2D()(x11)\n",
    "    \n",
    "    x11=Conv2D(filters=32,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x11)\n",
    "    x11= BatchNormalization(axis=chanDim)(x11)\n",
    "    x11= LeakyReLU(alpha=0.05)(x11)      \n",
    "    \n",
    "    x11=Conv2D(filters=1,kernel_size=(3,3),strides=1,padding=\"same\",activation=\"relu\",kernel_regularizer=regularizers.l2(weight_decay))(x11)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    x=  Add()([x3resu,x7,x10resu,x11])\n",
    "    #xrsu = Merge([ x,x2,x3],mode='concat')\n",
    "    model = Model(inputs=[inputs],outputs=x,name='vgggen5_12_Next20_20'+str(num))\n",
    "    return model\n",
    "\n",
    "\n",
    "def vgggen5_12_Next(inputs,num):\n",
    "    weight_decay = 0.0005    \n",
    "       \n",
    "   \n",
    "    x6 = Lambda(sliceuse,output_shape=(20,20,1),arguments={'index':num})(inputs)\n",
    "    x6 = Reshape((20,20,1))(x6)\n",
    "    \n",
    "    x=Conv2D(filters=32,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x6)\n",
    "    x= BatchNormalization(axis=chanDim)(x)\n",
    "    x= LeakyReLU(alpha=0.05)(x)       \n",
    "  \n",
    "    \n",
    "    x=Conv2D(filters=64,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x)\n",
    "    x= BatchNormalization(axis=chanDim)(x)\n",
    "    x1= LeakyReLU(alpha=0.05)(x) \n",
    "    \n",
    "    x5=Conv2D(filters=64,kernel_size=(3,3),strides=2,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x1)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5_1= LeakyReLU(alpha=0.05)(x5)\n",
    "    \n",
    "    x5=Conv2D(filters=64,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5_1)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)\n",
    "    \n",
    "    x5=Conv2D(filters=128,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)    \n",
    "    \n",
    "    x5=Conv2D(filters=64,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)    \n",
    "           \n",
    "    x5= UpSampling2D()(x5)\n",
    "    \n",
    "    x5=  Add()([x5,x1])\n",
    "    \n",
    "    x5=Conv2D(filters=64,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)\n",
    "    \n",
    "    x5=Conv2D(filters=128,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)\n",
    "    \n",
    "\n",
    "    x5=Conv2D(filters=64,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)     \n",
    "    #20*20\n",
    "  \n",
    "    x7= UpSampling2D()(x5)  #40*40 \n",
    "    \n",
    "    x7=Conv2D(filters=64,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x7)\n",
    "    x7= BatchNormalization(axis=chanDim)(x7)\n",
    "    x7= LeakyReLU(alpha=0.05)(x7)\n",
    "    \n",
    "    x7=Conv2D(filters=64,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x7)\n",
    "    x7= BatchNormalization(axis=chanDim)(x7)\n",
    "    x7= LeakyReLU(alpha=0.05)(x7)\n",
    "    \n",
    "    x7= UpSampling2D()(x7)  #80*80\n",
    "    \n",
    "    x7=Conv2D(filters=32,kernel_size=(5,5),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x7)\n",
    "    x7= BatchNormalization(axis=chanDim)(x7)\n",
    "    x7= LeakyReLU(alpha=0.05)(x7)\n",
    "    \n",
    "    x7=Conv2D(filters=32,kernel_size=(5,5),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x7)\n",
    "    x7= BatchNormalization(axis=chanDim)(x7)\n",
    "    x7= LeakyReLU(alpha=0.05)(x7)\n",
    "    \n",
    "    x7=Conv2D(filters=1,kernel_size=(5,5),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x7)\n",
    "    x7= BatchNormalization(axis=chanDim)(x7)\n",
    "    x7= LeakyReLU(alpha=0.05)(x7)\n",
    "    \n",
    "    #x3 = Lambda(lambda t: t[:,:,:,0])(input)\n",
    "    #xu = MaxPooling2D(pool_size=(2,2))(inputs)\n",
    "    #xc = Lambda(sliceuse,output_shape=(40,40,1),arguments={'index':0})(xu)    \n",
    "     \n",
    "    #xu = MaxPooling2D(pool_size=(2,2))(inputs)\n",
    "    xc = Lambda(sliceuse,output_shape=(20,20,1),arguments={'index':num})(inputs)\n",
    "    xc = Reshape((20,20,1))(xc)  \n",
    "    \n",
    "    xr1 = Lambda(splitdata,output_shape=(10,10,1),arguments={'index':0,'inum':4})(xc)    \n",
    "    xr2 = Lambda(splitdata,output_shape=(10,10,1),arguments={'index':1,'inum':4})(xc)    \n",
    "    xr3 = Lambda(splitdata,output_shape=(10,10,1),arguments={'index':2,'inum':4})(xc)    \n",
    "    xr4 = Lambda(splitdata,output_shape=(10,10,1),arguments={'index':3,'inum':4})(xc)    \n",
    "    \n",
    "    #xr1,xr2,xr3,xr4 = Lambda(splitdata,arguments={'index':0,'inum':4})(xc)    \n",
    "    #xr = np.array(Lambda(splitdata,output_shape=(20,20,1),arguments={'index':0,'inum':4})(xc)) \n",
    "    #xr1,xr2,xr3,xr4 = Lambda(splitdata,output_shape=(20,20,1),arguments={'index':3,'inum':4})(xc)\n",
    "    xr = [xr1,xr2,xr3,xr4]\n",
    "    # ,output_shape=(20,20,1)\n",
    "    \n",
    "    x3 = xr\n",
    "    x3_1 = xr\n",
    "    for m in range(4):        \n",
    "        x3[m] = Reshape((10,10,1))(xr[m])\n",
    "        x3[m] = Flatten()(x3[m])   \n",
    "        x3[m] = Dense(500 ,kernel_regularizer=regularizers.l2(weight_decay))(x3[m]) \n",
    "    #activation=\"relu\",\n",
    "        x3[m]= LeakyReLU(alpha=0.05)(x3[m])\n",
    "        x3[m] = Dense(800 ,kernel_regularizer=regularizers.l2(weight_decay))(x3[m])\n",
    "        x3[m]= LeakyReLU(alpha=0.05)(x3[m])\n",
    "        x3[m] = Dense(1000 ,kernel_regularizer=regularizers.l2(weight_decay))(x3[m])\n",
    "        x3[m]= LeakyReLU(alpha=0.05)(x3[m])        \n",
    "        x3[m] = Dense(600 ,kernel_regularizer=regularizers.l2(weight_decay))(x3[m])        \n",
    "        x3[m]= LeakyReLU(alpha=0.05)(x3[m])\n",
    "        x3[m] = Dense(1200 ,kernel_regularizer=regularizers.l2(weight_decay))(x3[m])\n",
    "        x3_1[m]= LeakyReLU(alpha=0.05)(x3[m])\n",
    "        x3[m] = Dense(600 ,kernel_regularizer=regularizers.l2(weight_decay))(x3_1[m])\n",
    "        x3[m]= LeakyReLU(alpha=0.05)(x3[m])\n",
    "        x3[m] = Dense(1000 ,kernel_regularizer=regularizers.l2(weight_decay))(x3[m])\n",
    "        x3[m]= LeakyReLU(alpha=0.05)(x3[m])        \n",
    "        x3[m] = Dense(600 ,kernel_regularizer=regularizers.l2(weight_decay))(x3[m])        \n",
    "        x3[m]= LeakyReLU(alpha=0.05)(x3[m])\n",
    "        x3[m] = Dense(1200 ,kernel_regularizer=regularizers.l2(weight_decay))(x3[m])\n",
    "        x3[m]= LeakyReLU(alpha=0.05)(x3[m])   \n",
    "        x3[m]=  Add()([x3[m],x3_1[m]])\n",
    "        x3[m] = Dense(900 ,kernel_regularizer=regularizers.l2(weight_decay))(x3[m])        \n",
    "        x3[m]= LeakyReLU(alpha=0.05)(x3[m])\n",
    "        x3[m] = Dense(40*40 ,kernel_regularizer=regularizers.l2(weight_decay))(x3[m])\n",
    "        x3[m]= LeakyReLU(alpha=0.05)(x3[m])\n",
    "        x3[m] = Reshape((40,40,1))(x3[m])\n",
    "         \n",
    "    x3resu =concatenate([x3[0],x3[1],x3[2],x3[3]])\n",
    "    x3resu =Reshape((80,80,1))(x3resu)\n",
    "    \n",
    "    x10 = [xr1,xr2,xr3,xr4]\n",
    "    for m in range(4):\n",
    "        x10[m] = Reshape((10,10,1))(x10[m])\n",
    "        x10[m] = Flatten()(x10[m])   \n",
    "        x10[m] = Dense(400 ,kernel_regularizer=regularizers.l2(weight_decay))(x10[m])         \n",
    "        x10[m]= LeakyReLU(alpha=0.05)(x10[m])\n",
    "        x10[m] = Dense(1200 ,kernel_regularizer=regularizers.l2(weight_decay))(x10[m])\n",
    "        x10[m]= LeakyReLU(alpha=0.05)(x10[m])\n",
    "        x10[m] = Dense(600 ,kernel_regularizer=regularizers.l2(weight_decay))(x10[m])\n",
    "        x10[m]= LeakyReLU(alpha=0.05)(x10[m])\n",
    "        x10[m] = Dense(1200 ,kernel_regularizer=regularizers.l2(weight_decay))(x10[m])\n",
    "        x10[m]= LeakyReLU(alpha=0.05)(x10[m])       \n",
    "        x10[m] = Dense(40*40 ,kernel_regularizer=regularizers.l2(weight_decay))(x10[m])\n",
    "        x10[m]= LeakyReLU(alpha=0.05)(x10[m])\n",
    "        x10[m] = Reshape((40,40,1))(x10[m]) \n",
    "          \n",
    "    x10resu =concatenate([x10[0],x10[1],x10[2],x10[3]])\n",
    "    x10resu =Reshape((80,80,1))(x10resu)\n",
    "    \n",
    "    \n",
    "    x11 = x6\n",
    "    x11=Conv2D(filters=64,kernel_size=(5,5),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x11)\n",
    "    x11= BatchNormalization(axis=chanDim)(x11)\n",
    "    x11= LeakyReLU(alpha=0.05)(x11)   \n",
    "    \n",
    "    x11= UpSampling2D()(x11)\n",
    "    \n",
    "    x11=Conv2D(filters=64,kernel_size=(5,5),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x11)\n",
    "    x11= BatchNormalization(axis=chanDim)(x11)\n",
    "    x11= LeakyReLU(alpha=0.05)(x11)   \n",
    "    \n",
    "    x11= UpSampling2D()(x11)\n",
    "    \n",
    "    x11=Conv2D(filters=32,kernel_size=(5,5),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x11)\n",
    "    x11= BatchNormalization(axis=chanDim)(x11)\n",
    "    x11= LeakyReLU(alpha=0.05)(x11)      \n",
    "    \n",
    "    x11_1=Conv2D(filters=32,kernel_size=(5,5),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x11)\n",
    "    x11_1= BatchNormalization(axis=chanDim)(x11_1)\n",
    "    x11_1= LeakyReLU(alpha=0.05)(x11_1)      \n",
    "    \n",
    "    x11=  Add()([x11,x11_1])\n",
    "    \n",
    "    x11=Conv2D(filters=1,kernel_size=(5,5),strides=1,padding=\"same\",activation=\"relu\",kernel_regularizer=regularizers.l2(weight_decay))(x11)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    x=  Add()([x3resu,x7,x10resu,x11])\n",
    "    #xrsu = Merge([ x,x2,x3],mode='concat')\n",
    "    model = Model(inputs=[inputs],outputs=x,name='vgggen5_12_Next'+str(num))\n",
    "    return model\n",
    "\n",
    "def vgggen5_12_Next40_80(inputs,num):\n",
    "    weight_decay = 0.0005    \n",
    "       \n",
    "   \n",
    "    x6 = Lambda(sliceuse,output_shape=(40,40,1),arguments={'index':num})(inputs)\n",
    "    x6 = Reshape((40,40,1))(x6)\n",
    "    \n",
    "    x=Conv2D(filters=32,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x6)\n",
    "    x= BatchNormalization(axis=chanDim)(x)\n",
    "    x= LeakyReLU(alpha=0.05)(x)       \n",
    "  \n",
    "    \n",
    "    x=Conv2D(filters=64,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x)\n",
    "    x= BatchNormalization(axis=chanDim)(x)\n",
    "    x1= LeakyReLU(alpha=0.05)(x) \n",
    "    \n",
    "    x5=Conv2D(filters=64,kernel_size=(3,3),strides=2,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x1)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)\n",
    "    \n",
    "    x5=Conv2D(filters=64,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)\n",
    "    \n",
    "    x5=Conv2D(filters=128,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)    \n",
    "    \n",
    "    x5=Conv2D(filters=64,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5_2= LeakyReLU(alpha=0.05)(x5)    \n",
    "    \n",
    "    \n",
    "    x5=Conv2D(filters=128,kernel_size=(3,3),strides=2,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5_2)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)\n",
    "    \n",
    "    x5=Conv2D(filters=256,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)\n",
    "    \n",
    "    x5=Conv2D(filters=128,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)    \n",
    "    \n",
    "    x5=Conv2D(filters=64,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)       \n",
    "           \n",
    "    x5= UpSampling2D()(x5)\n",
    "    \n",
    "    \n",
    "    x5=  Add()([x5,x5_2])\n",
    "    \n",
    "    x5=Conv2D(filters=64,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)\n",
    "    \n",
    "    x5=Conv2D(filters=128,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)    \n",
    "    \n",
    "    x5=Conv2D(filters=64,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)    \n",
    "    \n",
    "    x5= UpSampling2D()(x5)\n",
    "    \n",
    "    x5=  Add()([x5,x1])\n",
    "    \n",
    "    x5=Conv2D(filters=64,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)\n",
    "    \n",
    "    x5=Conv2D(filters=64,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)\n",
    "    \n",
    "\n",
    "    x5=Conv2D(filters=64,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)     \n",
    "       \n",
    "    x7= UpSampling2D()(x5)  #80*80\n",
    "    \n",
    "    x7=Conv2D(filters=32,kernel_size=(5,5),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x7)\n",
    "    x7= BatchNormalization(axis=chanDim)(x7)\n",
    "    x7= LeakyReLU(alpha=0.05)(x7)\n",
    "    \n",
    "    x7=Conv2D(filters=32,kernel_size=(5,5),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x7)\n",
    "    x7= BatchNormalization(axis=chanDim)(x7)\n",
    "    x7= LeakyReLU(alpha=0.05)(x7)\n",
    "    \n",
    "    x7=Conv2D(filters=1,kernel_size=(5,5),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x7)\n",
    "    x7= BatchNormalization(axis=chanDim)(x7)\n",
    "    x7= LeakyReLU(alpha=0.05)(x7)\n",
    "    \n",
    "    #x3 = Lambda(lambda t: t[:,:,:,0])(input)\n",
    "    #xu = MaxPooling2D(pool_size=(2,2))(inputs)\n",
    "    #xc = Lambda(sliceuse,output_shape=(40,40,1),arguments={'index':0})(xu)    \n",
    "     \n",
    "    #xu = MaxPooling2D(pool_size=(2,2))(inputs)\n",
    "    xc = Lambda(sliceuse,output_shape=(40,40,1),arguments={'index':num})(inputs)\n",
    "    xc = Reshape((40,40,1))(xc)  \n",
    "    \n",
    "    xr1 = Lambda(splitdata,output_shape=(20,20,1),arguments={'index':0,'inum':4})(xc)    \n",
    "    xr2 = Lambda(splitdata,output_shape=(20,20,1),arguments={'index':1,'inum':4})(xc)    \n",
    "    xr3 = Lambda(splitdata,output_shape=(20,20,1),arguments={'index':2,'inum':4})(xc)    \n",
    "    xr4 = Lambda(splitdata,output_shape=(20,20,1),arguments={'index':3,'inum':4})(xc)    \n",
    "    \n",
    "    #xr1,xr2,xr3,xr4 = Lambda(splitdata,arguments={'index':0,'inum':4})(xc)    \n",
    "    #xr = np.array(Lambda(splitdata,output_shape=(20,20,1),arguments={'index':0,'inum':4})(xc)) \n",
    "    #xr1,xr2,xr3,xr4 = Lambda(splitdata,output_shape=(20,20,1),arguments={'index':3,'inum':4})(xc)\n",
    "    xr = [xr1,xr2,xr3,xr4]\n",
    "    # ,output_shape=(20,20,1)\n",
    "    \n",
    "    x3 = xr\n",
    "    x3_1 = xr\n",
    "    for m in range(4):        \n",
    "        x3[m] = Reshape((20,20,1))(xr[m])\n",
    "        x3[m] = Flatten()(x3[m])   \n",
    "        x3[m] = Dense(500 ,kernel_regularizer=regularizers.l2(weight_decay))(x3[m]) \n",
    "    #activation=\"relu\",\n",
    "        x3[m]= LeakyReLU(alpha=0.05)(x3[m])\n",
    "        x3[m] = Dense(800 ,kernel_regularizer=regularizers.l2(weight_decay))(x3[m])\n",
    "        x3[m]= LeakyReLU(alpha=0.05)(x3[m])\n",
    "        x3[m] = Dense(1000 ,kernel_regularizer=regularizers.l2(weight_decay))(x3[m])\n",
    "        x3[m]= LeakyReLU(alpha=0.05)(x3[m])        \n",
    "        x3[m] = Dense(600 ,kernel_regularizer=regularizers.l2(weight_decay))(x3[m])        \n",
    "        x3[m]= LeakyReLU(alpha=0.05)(x3[m])\n",
    "        x3[m] = Dense(1200 ,kernel_regularizer=regularizers.l2(weight_decay))(x3[m])\n",
    "        x3_1[m]= LeakyReLU(alpha=0.05)(x3[m])\n",
    "        x3[m] = Dense(600 ,kernel_regularizer=regularizers.l2(weight_decay))(x3_1[m])\n",
    "        x3[m]= LeakyReLU(alpha=0.05)(x3[m])\n",
    "        #x3[m] = Dense(1000 ,kernel_regularizer=regularizers.l2(weight_decay))(x3[m])\n",
    "        #x3[m]= LeakyReLU(alpha=0.05)(x3[m])        \n",
    "        x3[m] = Dense(600 ,kernel_regularizer=regularizers.l2(weight_decay))(x3[m])        \n",
    "        x3[m]= LeakyReLU(alpha=0.05)(x3[m])\n",
    "        x3[m] = Dense(1200 ,kernel_regularizer=regularizers.l2(weight_decay))(x3[m])\n",
    "        x3[m]= LeakyReLU(alpha=0.05)(x3[m])   \n",
    "        x3[m]=  Add()([x3[m],x3_1[m]])\n",
    "        x3[m] = Dense(900 ,kernel_regularizer=regularizers.l2(weight_decay))(x3[m])        \n",
    "        x3[m]= LeakyReLU(alpha=0.05)(x3[m])\n",
    "        x3[m] = Dense(40*40 ,kernel_regularizer=regularizers.l2(weight_decay))(x3[m])\n",
    "        x3[m]= LeakyReLU(alpha=0.05)(x3[m])\n",
    "        x3[m] = Reshape((40,40,1))(x3[m])\n",
    "         \n",
    "    x3resu =concatenate([x3[0],x3[1],x3[2],x3[3]])\n",
    "    x3resu =Reshape((80,80,1))(x3resu)\n",
    "    \n",
    "    x10 = [xr1,xr2,xr3,xr4]\n",
    "    for m in range(4):\n",
    "        x10[m] = Reshape((20,20,1))(x10[m])\n",
    "        x10[m] = Flatten()(x10[m])   \n",
    "        x10[m] = Dense(400 ,kernel_regularizer=regularizers.l2(weight_decay))(x10[m])         \n",
    "        x10[m]= LeakyReLU(alpha=0.05)(x10[m])\n",
    "        #x10[m] = Dense(1200 ,kernel_regularizer=regularizers.l2(weight_decay))(x10[m])\n",
    "        #x10[m]= LeakyReLU(alpha=0.05)(x10[m])\n",
    "        x10[m] = Dense(600 ,kernel_regularizer=regularizers.l2(weight_decay))(x10[m])\n",
    "        x10[m]= LeakyReLU(alpha=0.05)(x10[m])\n",
    "        x10[m] = Dense(1200 ,kernel_regularizer=regularizers.l2(weight_decay))(x10[m])\n",
    "        x10[m]= LeakyReLU(alpha=0.05)(x10[m])       \n",
    "        x10[m] = Dense(40*40 ,kernel_regularizer=regularizers.l2(weight_decay))(x10[m])\n",
    "        x10[m]= LeakyReLU(alpha=0.05)(x10[m])\n",
    "        x10[m] = Reshape((40,40,1))(x10[m]) \n",
    "          \n",
    "    x10resu =concatenate([x10[0],x10[1],x10[2],x10[3]])\n",
    "    x10resu =Reshape((80,80,1))(x10resu)\n",
    "    \n",
    "    \n",
    "    x11 = x6\n",
    "    x11=Conv2D(filters=64,kernel_size=(5,5),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x11)\n",
    "    x11= BatchNormalization(axis=chanDim)(x11)\n",
    "    x11= LeakyReLU(alpha=0.05)(x11)   \n",
    "    \n",
    "    x11=Conv2D(filters=64,kernel_size=(5,5),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x11)\n",
    "    x11= BatchNormalization(axis=chanDim)(x11)\n",
    "    x11= LeakyReLU(alpha=0.05)(x11)   \n",
    "    \n",
    "    x11= UpSampling2D()(x11)   \n",
    "    \n",
    "    x11=Conv2D(filters=64,kernel_size=(5,5),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x11)\n",
    "    x11= BatchNormalization(axis=chanDim)(x11)\n",
    "    x11= LeakyReLU(alpha=0.05)(x11)      \n",
    "    \n",
    "    x11_1=Conv2D(filters=64,kernel_size=(5,5),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x11)\n",
    "    x11_1= BatchNormalization(axis=chanDim)(x11_1)\n",
    "    x11_1= LeakyReLU(alpha=0.05)(x11_1)      \n",
    "    \n",
    "    x11=  Add()([x11,x11_1])\n",
    "    \n",
    "    x11=Conv2D(filters=1,kernel_size=(5,5),strides=1,padding=\"same\",activation=\"relu\",kernel_regularizer=regularizers.l2(weight_decay))(x11)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    x=  Add()([x3resu,x7,x10resu,x11])\n",
    "    #xrsu = Merge([ x,x2,x3],mode='concat')\n",
    "    model = Model(inputs=[inputs],outputs=x,name='vgggen5_12_Next40_80'+str(num))\n",
    "    return model\n",
    "\n",
    "def vgggen5_12_Next40_80_2(inputs,num):\n",
    "    weight_decay = 0.0005    \n",
    "       \n",
    "   \n",
    "    x6 = Lambda(sliceuse,output_shape=(40,40,1),arguments={'index':num})(inputs)\n",
    "    x6 = Reshape((40,40,1))(x6)\n",
    "    \n",
    "    x=Conv2D(filters=32,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x6)\n",
    "    x= BatchNormalization(axis=chanDim)(x)\n",
    "    x= LeakyReLU(alpha=0.05)(x)       \n",
    "  \n",
    "    \n",
    "    x=Conv2D(filters=64,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x)\n",
    "    x= BatchNormalization(axis=chanDim)(x)\n",
    "    x1= LeakyReLU(alpha=0.05)(x) \n",
    "    \n",
    "    x5=Conv2D(filters=64,kernel_size=(3,3),strides=2,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x1)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)\n",
    "    \n",
    "    x5=Conv2D(filters=128,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)\n",
    "    \n",
    "    x5=Conv2D(filters=128,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)    \n",
    "    \n",
    "    x5=Conv2D(filters=128,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5_2= LeakyReLU(alpha=0.05)(x5)    \n",
    "    \n",
    "    \n",
    "    x5=Conv2D(filters=128,kernel_size=(3,3),strides=2,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5_2)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)\n",
    "    \n",
    "    x5=Conv2D(filters=256,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)\n",
    "    \n",
    "    x5=Conv2D(filters=128,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)    \n",
    "    \n",
    "    x5=Conv2D(filters=64,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5_3= LeakyReLU(alpha=0.05)(x5)       \n",
    "    \n",
    "    x5=Conv2D(filters=32,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5_3)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)\n",
    "    \n",
    "    x5 = Flatten()(x5)  \n",
    "    \n",
    "    x5 = Dense(1200 ,kernel_regularizer=regularizers.l2(weight_decay))(x5)         \n",
    "    x5= LeakyReLU(alpha=0.05)(x5)\n",
    "    \n",
    "    x5 = Dense(3200 ,kernel_regularizer=regularizers.l2(weight_decay))(x5)         \n",
    "    x5= LeakyReLU(alpha=0.05)(x5)\n",
    "    \n",
    "    x5 = Reshape((10,10,32))(x5)\n",
    "    \n",
    "    x5=Conv2D(filters=64,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)       \n",
    "    \n",
    "    x5=  Add()([x5,x5_3])\n",
    "    \n",
    "    x5=Conv2D(filters=128,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)    \n",
    "    \n",
    "    x5= UpSampling2D()(x5)    \n",
    "    \n",
    "    x5=  Add()([x5,x5_2])\n",
    "    \n",
    "    x5=Conv2D(filters=64,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)\n",
    "    \n",
    "    x5=Conv2D(filters=128,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)    \n",
    "    \n",
    "    x5=Conv2D(filters=64,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)    \n",
    "    \n",
    "    x5= UpSampling2D()(x5)\n",
    "    \n",
    "    x5=  Add()([x5,x1])\n",
    "    \n",
    "    x5=Conv2D(filters=64,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)\n",
    "    \n",
    "    x5=Conv2D(filters=64,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)\n",
    "    \n",
    "\n",
    "    x5=Conv2D(filters=64,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)     \n",
    "       \n",
    "    x7= UpSampling2D()(x5)  #80*80\n",
    "    \n",
    "    x7=Conv2D(filters=32,kernel_size=(5,5),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x7)\n",
    "    x7= BatchNormalization(axis=chanDim)(x7)\n",
    "    x7= LeakyReLU(alpha=0.05)(x7)\n",
    "    \n",
    "    x7=Conv2D(filters=32,kernel_size=(5,5),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x7)\n",
    "    x7= BatchNormalization(axis=chanDim)(x7)\n",
    "    x7= LeakyReLU(alpha=0.05)(x7)\n",
    "    \n",
    "    x7=Conv2D(filters=1,kernel_size=(5,5),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x7)\n",
    "    x7= BatchNormalization(axis=chanDim)(x7)\n",
    "    x7= LeakyReLU(alpha=0.05)(x7)\n",
    "    \n",
    "    #x3 = Lambda(lambda t: t[:,:,:,0])(input)\n",
    "    #xu = MaxPooling2D(pool_size=(2,2))(inputs)\n",
    "    #xc = Lambda(sliceuse,output_shape=(40,40,1),arguments={'index':0})(xu)    \n",
    "     \n",
    "    #xu = MaxPooling2D(pool_size=(2,2))(inputs)\n",
    "    xc = Lambda(sliceuse,output_shape=(40,40,1),arguments={'index':num})(inputs)\n",
    "    xc = Reshape((40,40,1))(xc)  \n",
    "    \n",
    "    xr1 = Lambda(splitdata,output_shape=(20,20,1),arguments={'index':0,'inum':4})(xc)    \n",
    "    xr2 = Lambda(splitdata,output_shape=(20,20,1),arguments={'index':1,'inum':4})(xc)    \n",
    "    xr3 = Lambda(splitdata,output_shape=(20,20,1),arguments={'index':2,'inum':4})(xc)    \n",
    "    xr4 = Lambda(splitdata,output_shape=(20,20,1),arguments={'index':3,'inum':4})(xc)    \n",
    "    \n",
    "    #xr1,xr2,xr3,xr4 = Lambda(splitdata,arguments={'index':0,'inum':4})(xc)    \n",
    "    #xr = np.array(Lambda(splitdata,output_shape=(20,20,1),arguments={'index':0,'inum':4})(xc)) \n",
    "    #xr1,xr2,xr3,xr4 = Lambda(splitdata,output_shape=(20,20,1),arguments={'index':3,'inum':4})(xc)\n",
    "    xr = [xr1,xr2,xr3,xr4]\n",
    "    # ,output_shape=(20,20,1)\n",
    "    \n",
    "    x3 = xr\n",
    "    x3_1 = xr\n",
    "    \"\"\"\n",
    "    for m in range(4):        \n",
    "        x3[m] = Reshape((20,20,1))(xr[m])\n",
    "        x3[m] = Flatten()(x3[m])   \n",
    "        x3[m] = Dense(500 ,kernel_regularizer=regularizers.l2(weight_decay))(x3[m]) \n",
    "    #activation=\"relu\",\n",
    "        x3[m]= LeakyReLU(alpha=0.05)(x3[m])\n",
    "        x3[m] = Dense(800 ,kernel_regularizer=regularizers.l2(weight_decay))(x3[m])\n",
    "        x3[m]= LeakyReLU(alpha=0.05)(x3[m])\n",
    "        x3[m] = Dense(1000 ,kernel_regularizer=regularizers.l2(weight_decay))(x3[m])\n",
    "        x3[m]= LeakyReLU(alpha=0.05)(x3[m])        \n",
    "        x3[m] = Dense(600 ,kernel_regularizer=regularizers.l2(weight_decay))(x3[m])        \n",
    "        x3[m]= LeakyReLU(alpha=0.05)(x3[m])\n",
    "        x3[m] = Dense(1200 ,kernel_regularizer=regularizers.l2(weight_decay))(x3[m])\n",
    "        x3_1[m]= LeakyReLU(alpha=0.05)(x3[m])\n",
    "        x3[m] = Dense(600 ,kernel_regularizer=regularizers.l2(weight_decay))(x3_1[m])\n",
    "        x3[m]= LeakyReLU(alpha=0.05)(x3[m])\n",
    "        #x3[m] = Dense(1000 ,kernel_regularizer=regularizers.l2(weight_decay))(x3[m])\n",
    "        #x3[m]= LeakyReLU(alpha=0.05)(x3[m])        \n",
    "        x3[m] = Dense(600 ,kernel_regularizer=regularizers.l2(weight_decay))(x3[m])        \n",
    "        x3[m]= LeakyReLU(alpha=0.05)(x3[m])\n",
    "        x3[m] = Dense(1200 ,kernel_regularizer=regularizers.l2(weight_decay))(x3[m])\n",
    "        x3[m]= LeakyReLU(alpha=0.05)(x3[m])   \n",
    "        x3[m]=  Add()([x3[m],x3_1[m]])\n",
    "        x3[m] = Dense(900 ,kernel_regularizer=regularizers.l2(weight_decay))(x3[m])        \n",
    "        x3[m]= LeakyReLU(alpha=0.05)(x3[m])\n",
    "        x3[m] = Dense(40*40 ,kernel_regularizer=regularizers.l2(weight_decay))(x3[m])\n",
    "        x3[m]= LeakyReLU(alpha=0.05)(x3[m])\n",
    "        x3[m] = Reshape((40,40,1))(x3[m])\n",
    "         \n",
    "    x3resu =concatenate([x3[0],x3[1],x3[2],x3[3]])\n",
    "    x3resu =Reshape((80,80,1))(x3resu)\n",
    "    \"\"\"\n",
    "    x10 = [xr1,xr2,xr3,xr4]\n",
    "    for m in range(4):\n",
    "        x10[m] = Reshape((20,20,1))(x10[m])\n",
    "        x10[m] = Flatten()(x10[m])   \n",
    "        x10[m] = Dense(600 ,kernel_regularizer=regularizers.l2(weight_decay))(x10[m])         \n",
    "        x10[m]= LeakyReLU(alpha=0.05)(x10[m])\n",
    "        x10[m] = Dense(1600 ,kernel_regularizer=regularizers.l2(weight_decay))(x10[m])\n",
    "        x10[m]= LeakyReLU(alpha=0.05)(x10[m])\n",
    "        x10[m] = Dense(600 ,kernel_regularizer=regularizers.l2(weight_decay))(x10[m])\n",
    "        x10[m]= LeakyReLU(alpha=0.05)(x10[m])\n",
    "        x10[m] = Dense(1200 ,kernel_regularizer=regularizers.l2(weight_decay))(x10[m])\n",
    "        x10[m]= LeakyReLU(alpha=0.05)(x10[m])       \n",
    "        x10[m] = Dense(800 ,kernel_regularizer=regularizers.l2(weight_decay))(x10[m])\n",
    "        x10[m]= LeakyReLU(alpha=0.05)(x10[m])        \n",
    "        x10[m] = Dense(40*40 ,kernel_regularizer=regularizers.l2(weight_decay))(x10[m])\n",
    "        x10[m]= LeakyReLU(alpha=0.05)(x10[m])\n",
    "        x10[m] = Reshape((40,40,1))(x10[m]) \n",
    "          \n",
    "    x10resu =concatenate([x10[0],x10[1],x10[2],x10[3]])\n",
    "    x10resu =Reshape((80,80,1))(x10resu)\n",
    "    \n",
    "    \n",
    "    x11 = x6\n",
    "    x11=Conv2D(filters=64,kernel_size=(5,5),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x11)\n",
    "    x11= BatchNormalization(axis=chanDim)(x11)\n",
    "    x11= LeakyReLU(alpha=0.05)(x11)   \n",
    "    \n",
    "    x11=Conv2D(filters=64,kernel_size=(5,5),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x11)\n",
    "    x11= BatchNormalization(axis=chanDim)(x11)\n",
    "    x11= LeakyReLU(alpha=0.05)(x11)   \n",
    "    \n",
    "    x11= UpSampling2D()(x11)   \n",
    "    \n",
    "    x11=Conv2D(filters=64,kernel_size=(5,5),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x11)\n",
    "    x11= BatchNormalization(axis=chanDim)(x11)\n",
    "    x11= LeakyReLU(alpha=0.05)(x11)      \n",
    "    \n",
    "    x11_1=Conv2D(filters=64,kernel_size=(5,5),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x11)\n",
    "    x11_1= BatchNormalization(axis=chanDim)(x11_1)\n",
    "    x11_1= LeakyReLU(alpha=0.05)(x11_1)      \n",
    "    \n",
    "    x11=  Add()([x11,x11_1])\n",
    "    \n",
    "    x11=Conv2D(filters=1,kernel_size=(5,5),strides=1,padding=\"same\",activation=\"relu\",kernel_regularizer=regularizers.l2(weight_decay))(x11)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    x=  Add()([x7,x10resu,x11])  #x3resu,\n",
    "    #xrsu = Merge([ x,x2,x3],mode='concat')\n",
    "    model = Model(inputs=[inputs],outputs=x,name='vgggen5_12_Next40_80_2'+str(num))\n",
    "    return model\n",
    "\n",
    "\n",
    "def vgggen5_12_Next40_80_3(inputs,num):\n",
    "    weight_decay = 0.0005    \n",
    "       \n",
    "   \n",
    "    x6 = Lambda(sliceuse,output_shape=(40,40,1),arguments={'index':num})(inputs)\n",
    "    x6 = Reshape((40,40,1))(x6)\n",
    "    \n",
    "    x=Conv2D(filters=32,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x6)\n",
    "    x= BatchNormalization(axis=chanDim)(x)\n",
    "    x= LeakyReLU(alpha=0.05)(x)       \n",
    "  \n",
    "    \n",
    "    x=Conv2D(filters=64,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x)\n",
    "    x= BatchNormalization(axis=chanDim)(x)\n",
    "    x1= LeakyReLU(alpha=0.05)(x) \n",
    "    \n",
    "    x5=Conv2D(filters=64,kernel_size=(3,3),strides=2,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x1)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)\n",
    "    \n",
    "    x5=Conv2D(filters=128,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)\n",
    "    \n",
    "    x5=Conv2D(filters=128,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)    \n",
    "    \n",
    "    x5=Conv2D(filters=128,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5_2= LeakyReLU(alpha=0.05)(x5)    \n",
    "    \n",
    "    \n",
    "    x5=Conv2D(filters=128,kernel_size=(3,3),strides=2,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5_2)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)\n",
    "    \n",
    "    x5=Conv2D(filters=256,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)\n",
    "    \n",
    "    x5=Conv2D(filters=128,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)    \n",
    "    \n",
    "    x5=Conv2D(filters=64,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5_3= LeakyReLU(alpha=0.05)(x5)       \n",
    "    \n",
    "    \n",
    "    x5=Conv2D(filters=32,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5_3)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)\n",
    "    \n",
    "    x5 = Flatten()(x5)  \n",
    "    \n",
    "    x5 = Dense(1200 ,kernel_regularizer=regularizers.l2(weight_decay))(x5)         \n",
    "    x5= LeakyReLU(alpha=0.05)(x5)\n",
    "    \n",
    "    x5 = Dense(3200 ,kernel_regularizer=regularizers.l2(weight_decay))(x5)         \n",
    "    x5= LeakyReLU(alpha=0.05)(x5)\n",
    "    \n",
    "    x5 = Reshape((10,10,32))(x5)\n",
    "    \n",
    "    x5=Conv2D(filters=64,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5_5= LeakyReLU(alpha=0.05)(x5)       \n",
    "    \n",
    "    \n",
    "    x5_6=Conv2D(filters=50,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5_3)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5_6)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)\n",
    "    \n",
    "    x5 = Flatten()(x5)  \n",
    "    \n",
    "    x5 = Dense(1200 ,kernel_regularizer=regularizers.l2(weight_decay))(x5)         \n",
    "    x5= LeakyReLU(alpha=0.05)(x5)\n",
    "    \n",
    "    x5 = Dense(5000 ,kernel_regularizer=regularizers.l2(weight_decay))(x5)         \n",
    "    x5= LeakyReLU(alpha=0.05)(x5)\n",
    "    \n",
    "    x5 = Reshape((10,10,50))(x5)\n",
    "    \n",
    "    x5=Conv2D(filters=64,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)       \n",
    "    \n",
    "    \n",
    "    x5=  Add()([x5_5,x5])\n",
    "    \n",
    "    \n",
    "    x5=  Add()([x5,x5_3])\n",
    "    \n",
    "    x5=Conv2D(filters=128,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)    \n",
    "    \n",
    "    x5= UpSampling2D()(x5)    \n",
    "    \n",
    "    x5=  Add()([x5,x5_2])\n",
    "    \n",
    "    x5=Conv2D(filters=64,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)\n",
    "    \n",
    "    x5=Conv2D(filters=128,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)    \n",
    "    \n",
    "    x5=Conv2D(filters=64,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)    \n",
    "    \n",
    "    x5= UpSampling2D()(x5)\n",
    "    \n",
    "    x5=  Add()([x5,x1])\n",
    "    \n",
    "    x5=Conv2D(filters=64,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)\n",
    "    \n",
    "    x5=Conv2D(filters=64,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)\n",
    "    \n",
    "\n",
    "    x5=Conv2D(filters=64,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)     \n",
    "       \n",
    "    x7= UpSampling2D()(x5)  #80*80\n",
    "    \n",
    "    x7=Conv2D(filters=32,kernel_size=(5,5),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x7)\n",
    "    x7= BatchNormalization(axis=chanDim)(x7)\n",
    "    x7= LeakyReLU(alpha=0.05)(x7)\n",
    "    \n",
    "    x7=Conv2D(filters=32,kernel_size=(5,5),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x7)\n",
    "    x7= BatchNormalization(axis=chanDim)(x7)\n",
    "    x7= LeakyReLU(alpha=0.05)(x7)\n",
    "    \n",
    "    x7=Conv2D(filters=1,kernel_size=(5,5),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x7)\n",
    "    x7= BatchNormalization(axis=chanDim)(x7)\n",
    "    x7= LeakyReLU(alpha=0.05)(x7)\n",
    "    \n",
    "    #x3 = Lambda(lambda t: t[:,:,:,0])(input)\n",
    "    #xu = MaxPooling2D(pool_size=(2,2))(inputs)\n",
    "    #xc = Lambda(sliceuse,output_shape=(40,40,1),arguments={'index':0})(xu)    \n",
    "     \n",
    "    #xu = MaxPooling2D(pool_size=(2,2))(inputs)\n",
    "    xc = Lambda(sliceuse,output_shape=(40,40,1),arguments={'index':num})(inputs)\n",
    "    xc = Reshape((40,40,1))(xc)  \n",
    "    \n",
    "    xr1 = Lambda(splitdata,output_shape=(20,20,1),arguments={'index':0,'inum':4})(xc)    \n",
    "    xr2 = Lambda(splitdata,output_shape=(20,20,1),arguments={'index':1,'inum':4})(xc)    \n",
    "    xr3 = Lambda(splitdata,output_shape=(20,20,1),arguments={'index':2,'inum':4})(xc)    \n",
    "    xr4 = Lambda(splitdata,output_shape=(20,20,1),arguments={'index':3,'inum':4})(xc)    \n",
    "    \n",
    "    #xr1,xr2,xr3,xr4 = Lambda(splitdata,arguments={'index':0,'inum':4})(xc)    \n",
    "    #xr = np.array(Lambda(splitdata,output_shape=(20,20,1),arguments={'index':0,'inum':4})(xc)) \n",
    "    #xr1,xr2,xr3,xr4 = Lambda(splitdata,output_shape=(20,20,1),arguments={'index':3,'inum':4})(xc)\n",
    "    xr = [xr1,xr2,xr3,xr4]\n",
    "    # ,output_shape=(20,20,1)\n",
    "    \n",
    "    x3 = xr\n",
    "    x3_1 = xr\n",
    "    \"\"\"\n",
    "    for m in range(4):        \n",
    "        x3[m] = Reshape((20,20,1))(xr[m])\n",
    "        x3[m] = Flatten()(x3[m])   \n",
    "        x3[m] = Dense(500 ,kernel_regularizer=regularizers.l2(weight_decay))(x3[m]) \n",
    "    #activation=\"relu\",\n",
    "        x3[m]= LeakyReLU(alpha=0.05)(x3[m])\n",
    "        x3[m] = Dense(800 ,kernel_regularizer=regularizers.l2(weight_decay))(x3[m])\n",
    "        x3[m]= LeakyReLU(alpha=0.05)(x3[m])\n",
    "        x3[m] = Dense(1000 ,kernel_regularizer=regularizers.l2(weight_decay))(x3[m])\n",
    "        x3[m]= LeakyReLU(alpha=0.05)(x3[m])        \n",
    "        x3[m] = Dense(600 ,kernel_regularizer=regularizers.l2(weight_decay))(x3[m])        \n",
    "        x3[m]= LeakyReLU(alpha=0.05)(x3[m])\n",
    "        x3[m] = Dense(1200 ,kernel_regularizer=regularizers.l2(weight_decay))(x3[m])\n",
    "        x3_1[m]= LeakyReLU(alpha=0.05)(x3[m])\n",
    "        x3[m] = Dense(600 ,kernel_regularizer=regularizers.l2(weight_decay))(x3_1[m])\n",
    "        x3[m]= LeakyReLU(alpha=0.05)(x3[m])\n",
    "        #x3[m] = Dense(1000 ,kernel_regularizer=regularizers.l2(weight_decay))(x3[m])\n",
    "        #x3[m]= LeakyReLU(alpha=0.05)(x3[m])        \n",
    "        x3[m] = Dense(600 ,kernel_regularizer=regularizers.l2(weight_decay))(x3[m])        \n",
    "        x3[m]= LeakyReLU(alpha=0.05)(x3[m])\n",
    "        x3[m] = Dense(1200 ,kernel_regularizer=regularizers.l2(weight_decay))(x3[m])\n",
    "        x3[m]= LeakyReLU(alpha=0.05)(x3[m])   \n",
    "        x3[m]=  Add()([x3[m],x3_1[m]])\n",
    "        x3[m] = Dense(900 ,kernel_regularizer=regularizers.l2(weight_decay))(x3[m])        \n",
    "        x3[m]= LeakyReLU(alpha=0.05)(x3[m])\n",
    "        x3[m] = Dense(40*40 ,kernel_regularizer=regularizers.l2(weight_decay))(x3[m])\n",
    "        x3[m]= LeakyReLU(alpha=0.05)(x3[m])\n",
    "        x3[m] = Reshape((40,40,1))(x3[m])\n",
    "         \n",
    "    x3resu =concatenate([x3[0],x3[1],x3[2],x3[3]])\n",
    "    x3resu =Reshape((80,80,1))(x3resu)\n",
    "    \"\"\"\n",
    "    x10 = [xr1,xr2,xr3,xr4]\n",
    "    for m in range(4):\n",
    "        x10[m] = Reshape((20,20,1))(x10[m])\n",
    "        x10[m] = Flatten()(x10[m])   \n",
    "        x10[m] = Dense(600 ,kernel_regularizer=regularizers.l2(weight_decay))(x10[m])         \n",
    "        x10[m]= LeakyReLU(alpha=0.05)(x10[m])\n",
    "        x10[m] = Dense(1600 ,kernel_regularizer=regularizers.l2(weight_decay))(x10[m])\n",
    "        x10[m]= LeakyReLU(alpha=0.05)(x10[m])\n",
    "        x10[m] = Dense(600 ,kernel_regularizer=regularizers.l2(weight_decay))(x10[m])\n",
    "        x10[m]= LeakyReLU(alpha=0.05)(x10[m])\n",
    "        x10[m] = Dense(1200 ,kernel_regularizer=regularizers.l2(weight_decay))(x10[m])\n",
    "        x10[m]= LeakyReLU(alpha=0.05)(x10[m])       \n",
    "        x10[m] = Dense(800 ,kernel_regularizer=regularizers.l2(weight_decay))(x10[m])\n",
    "        x10[m]= LeakyReLU(alpha=0.05)(x10[m])        \n",
    "        x10[m] = Dense(40*40 ,kernel_regularizer=regularizers.l2(weight_decay))(x10[m])\n",
    "        x10[m]= LeakyReLU(alpha=0.05)(x10[m])\n",
    "        x10[m] = Reshape((40,40,1))(x10[m]) \n",
    "          \n",
    "    x10resu =concatenate([x10[0],x10[1],x10[2],x10[3]])\n",
    "    x10resu =Reshape((80,80,1))(x10resu)\n",
    "    \n",
    "    \n",
    "    x11 = x6\n",
    "    x11=Conv2D(filters=64,kernel_size=(5,5),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x11)\n",
    "    x11= BatchNormalization(axis=chanDim)(x11)\n",
    "    x11= LeakyReLU(alpha=0.05)(x11)   \n",
    "    \n",
    "    x11=Conv2D(filters=64,kernel_size=(5,5),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x11)\n",
    "    x11= BatchNormalization(axis=chanDim)(x11)\n",
    "    x11= LeakyReLU(alpha=0.05)(x11)   \n",
    "    \n",
    "    x11= UpSampling2D()(x11)   \n",
    "    \n",
    "    x11=Conv2D(filters=64,kernel_size=(5,5),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x11)\n",
    "    x11= BatchNormalization(axis=chanDim)(x11)\n",
    "    x11= LeakyReLU(alpha=0.05)(x11)      \n",
    "    \n",
    "    x11_1=Conv2D(filters=64,kernel_size=(5,5),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x11)\n",
    "    x11_1= BatchNormalization(axis=chanDim)(x11_1)\n",
    "    x11_1= LeakyReLU(alpha=0.05)(x11_1)      \n",
    "    \n",
    "    x11=  Add()([x11,x11_1])\n",
    "    \n",
    "    x11=Conv2D(filters=1,kernel_size=(5,5),strides=1,padding=\"same\",activation=\"relu\",kernel_regularizer=regularizers.l2(weight_decay))(x11)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    x=  Add()([x7,x10resu,x11])  #x3resu,\n",
    "    #xrsu = Merge([ x,x2,x3],mode='concat')\n",
    "    model = Model(inputs=[inputs],outputs=x,name='vgggen5_12_Next40_80_3'+str(num))\n",
    "    return model\n",
    "\n",
    "\n",
    "def vgggen5_12_Next40_80_5prev(inputs):\n",
    "    weight_decay = 0.0005         \n",
    "   \n",
    "   \n",
    "    x6 = Reshape((40,40,3))(inputs)\n",
    "    \n",
    "    x=Conv2D(filters=32,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x6)\n",
    "    x= BatchNormalization(axis=chanDim)(x)\n",
    "    x= LeakyReLU(alpha=0.05)(x)       \n",
    "  \n",
    "    \n",
    "    x=Conv2D(filters=64,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x)\n",
    "    x= BatchNormalization(axis=chanDim)(x)\n",
    "    x1= LeakyReLU(alpha=0.05)(x) \n",
    "    \n",
    "    x5=Conv2D(filters=64,kernel_size=(3,3),strides=2,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x1)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)\n",
    "    \n",
    "    x5=Conv2D(filters=128,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)\n",
    "    \n",
    "    x5=Conv2D(filters=128,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)    \n",
    "    \n",
    "    x5=Conv2D(filters=128,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5_2= LeakyReLU(alpha=0.05)(x5)    \n",
    "    \n",
    "    \n",
    "    x5=Conv2D(filters=128,kernel_size=(3,3),strides=2,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5_2)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)\n",
    "    \n",
    "    x5=Conv2D(filters=256,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)\n",
    "    \n",
    "    x5=Conv2D(filters=128,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)    \n",
    "    \n",
    "    x5=Conv2D(filters=64,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5_3= LeakyReLU(alpha=0.05)(x5)       \n",
    "    \n",
    "    \n",
    "    x5=Conv2D(filters=32,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5_3)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)\n",
    "    \n",
    "    x5 = Flatten()(x5)  \n",
    "    \n",
    "    x5 = Dense(1600 ,kernel_regularizer=regularizers.l2(weight_decay))(x5)         \n",
    "    x5= LeakyReLU(alpha=0.05)(x5)\n",
    "    \n",
    "    x5 = Dense(3200 ,kernel_regularizer=regularizers.l2(weight_decay))(x5)         \n",
    "    x5= LeakyReLU(alpha=0.05)(x5)\n",
    "    \n",
    "    x5 = Reshape((10,10,32))(x5)\n",
    "    \n",
    "    x5=Conv2D(filters=64,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5_5= LeakyReLU(alpha=0.05)(x5)       \n",
    "    \n",
    "    \n",
    "    x5_6=Conv2D(filters=50,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5_3)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5_6)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)\n",
    "    \n",
    "    x5 = Flatten()(x5)  \n",
    "    \n",
    "    x5 = Dense(1200 ,kernel_regularizer=regularizers.l2(weight_decay))(x5)         \n",
    "    x5= LeakyReLU(alpha=0.05)(x5)\n",
    "    \n",
    "    x5 = Dense(5000 ,kernel_regularizer=regularizers.l2(weight_decay))(x5)         \n",
    "    x5= LeakyReLU(alpha=0.05)(x5)\n",
    "    \n",
    "    x5 = Reshape((10,10,50))(x5)\n",
    "    \n",
    "    x5=Conv2D(filters=64,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)       \n",
    "    \n",
    "    \n",
    "    x5=  Add()([x5_5,x5])\n",
    "    \n",
    "    \n",
    "    x5=  Add()([x5,x5_3])\n",
    "    \n",
    "    x5=Conv2D(filters=128,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)    \n",
    "    \n",
    "    x5= UpSampling2D()(x5)    \n",
    "    \n",
    "    x5=  Add()([x5,x5_2])\n",
    "    \n",
    "    x5=Conv2D(filters=64,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)\n",
    "    \n",
    "    x5=Conv2D(filters=128,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)    \n",
    "    \n",
    "    x5=Conv2D(filters=64,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)    \n",
    "    \n",
    "    x5= UpSampling2D()(x5)\n",
    "    \n",
    "    x5=  Add()([x5,x1])\n",
    "    \n",
    "    x5=Conv2D(filters=64,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)\n",
    "    \n",
    "    x5=Conv2D(filters=64,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)\n",
    "    \n",
    "\n",
    "    x5=Conv2D(filters=64,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)     \n",
    "       \n",
    "    x7= UpSampling2D()(x5)  #80*80\n",
    "    \n",
    "    x7=Conv2D(filters=60,kernel_size=(5,5),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x7)\n",
    "    x7= BatchNormalization(axis=chanDim)(x7)\n",
    "    x7= LeakyReLU(alpha=0.05)(x7)\n",
    "    \n",
    "    x7=Conv2D(filters=32,kernel_size=(5,5),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x7)\n",
    "    x7= BatchNormalization(axis=chanDim)(x7)\n",
    "    x7= LeakyReLU(alpha=0.05)(x7)\n",
    "    \n",
    "    x7=Conv2D(filters=3,kernel_size=(5,5),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x7)\n",
    "    x7= BatchNormalization(axis=chanDim)(x7)\n",
    "    x7= LeakyReLU(alpha=0.05)(x7)\n",
    "    \n",
    "    #x3 = Lambda(lambda t: t[:,:,:,0])(input)\n",
    "    #xu = MaxPooling2D(pool_size=(2,2))(inputs)\n",
    "    #xc = Lambda(sliceuse,output_shape=(40,40,1),arguments={'index':0})(xu)    \n",
    "     \n",
    "    #xu = MaxPooling2D(pool_size=(2,2))(inputs)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    x= x7 #Add()([x7,x10resu,x11])  #x3resu,\n",
    "    #xrsu = Merge([ x,x2,x3],mode='concat')\n",
    "    model = Model(inputs=[inputs],outputs=x,name='vgggen5_12_Next40_80_5prev')\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "vgggen5_15_Nextprev = vgggen5_12_Next40_80_5prev(model_inputconv2)\n",
    "\n",
    "\n",
    "def vgggen5_12_Next40_80_5prev2(inputs,picsize):\n",
    "    weight_decay = 0.0005         \n",
    "   \n",
    "   \n",
    "    x6 = Reshape((picsize,picsize,3))(inputs)\n",
    "    \n",
    "    x=Conv2D(filters=32,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x6)\n",
    "    x= BatchNormalization(axis=chanDim)(x)\n",
    "    x= LeakyReLU(alpha=0.05)(x)       \n",
    "  \n",
    "    \n",
    "    x=Conv2D(filters=64,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x)\n",
    "    x= BatchNormalization(axis=chanDim)(x)\n",
    "    x1= LeakyReLU(alpha=0.05)(x) \n",
    "    \n",
    "    x5=Conv2D(filters=64,kernel_size=(3,3),strides=2,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x1)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)\n",
    "    \n",
    "    x5=Conv2D(filters=128,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)\n",
    "    \n",
    "    x5=Conv2D(filters=64,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)    \n",
    "    \n",
    "    x5=Conv2D(filters=128,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5_2= LeakyReLU(alpha=0.05)(x5)    \n",
    "    \n",
    "    \n",
    "    x5=Conv2D(filters=128,kernel_size=(3,3),strides=2,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5_2)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)\n",
    "    \n",
    "    x5=Conv2D(filters=256,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)\n",
    "    \n",
    "    x5=Conv2D(filters=128,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)    \n",
    "    \n",
    "    x5=Conv2D(filters=64,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5_3= LeakyReLU(alpha=0.05)(x5)       \n",
    "    \n",
    "    \n",
    "    x5=Conv2D(filters=32,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5_3)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)\n",
    "    \n",
    "    x5 = Flatten()(x5)  \n",
    "    \n",
    "    x5 = Dense(1600 ,kernel_regularizer=regularizers.l2(weight_decay))(x5)         \n",
    "    x5= LeakyReLU(alpha=0.05)(x5)\n",
    "    \n",
    "    x5 = Dense(7200 ,kernel_regularizer=regularizers.l2(weight_decay))(x5)         \n",
    "    x5= LeakyReLU(alpha=0.05)(x5)\n",
    "    \n",
    "    x5 = Reshape((15,15,32))(x5)\n",
    "    \n",
    "    x5=Conv2D(filters=64,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)       \n",
    "    \n",
    "    \"\"\"\n",
    "    x5_6=Conv2D(filters=50,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5_3)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5_6)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)\n",
    "    \n",
    "    x5 = Flatten()(x5)  \n",
    "    \n",
    "    x5 = Dense(1200 ,kernel_regularizer=regularizers.l2(weight_decay))(x5)         \n",
    "    x5= LeakyReLU(alpha=0.05)(x5)\n",
    "    \n",
    "    x5 = Dense(11250 ,kernel_regularizer=regularizers.l2(weight_decay))(x5)         \n",
    "    x5= LeakyReLU(alpha=0.05)(x5)\n",
    "    \n",
    "    x5 = Reshape((15,15,50))(x5)\n",
    "    \n",
    "    x5=Conv2D(filters=64,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)       \n",
    "    \n",
    "    \n",
    "    x5=  Add()([x5_5,x5])\n",
    "    \"\"\"\n",
    "    \n",
    "    x5=  Add()([x5,x5_3])\n",
    "    \n",
    "    x5=Conv2D(filters=128,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)    \n",
    "    \n",
    "    x5= UpSampling2D()(x5)    \n",
    "    \n",
    "    x5=  Add()([x5,x5_2])\n",
    "    \n",
    "    x5=Conv2D(filters=64,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)\n",
    "    \n",
    "    x5=Conv2D(filters=128,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)    \n",
    "    \n",
    "    x5=Conv2D(filters=64,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)    \n",
    "    \n",
    "    x5= UpSampling2D()(x5)\n",
    "    \n",
    "    x5=  Add()([x5,x1])\n",
    "    \n",
    "    x5=Conv2D(filters=32,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)\n",
    "    \n",
    "    x5=Conv2D(filters=64,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)\n",
    "    \n",
    "\n",
    "    x5=Conv2D(filters=64,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)     \n",
    "       \n",
    "    x7= UpSampling2D()(x5)  #80*80\n",
    "    \n",
    "    x7=Conv2D(filters=60,kernel_size=(5,5),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x7)\n",
    "    x7= BatchNormalization(axis=chanDim)(x7)\n",
    "    x7= LeakyReLU(alpha=0.05)(x7)\n",
    "    \n",
    "    x7=Conv2D(filters=32,kernel_size=(5,5),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x7)\n",
    "    x7= BatchNormalization(axis=chanDim)(x7)\n",
    "    x7= LeakyReLU(alpha=0.05)(x7)\n",
    "    \n",
    "    x7=Conv2D(filters=3,kernel_size=(5,5),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x7)\n",
    "    x7= BatchNormalization(axis=chanDim)(x7)\n",
    "    x7= LeakyReLU(alpha=0.05)(x7)\n",
    "    \n",
    "    #x3 = Lambda(lambda t: t[:,:,:,0])(input)\n",
    "    #xu = MaxPooling2D(pool_size=(2,2))(inputs)\n",
    "    #xc = Lambda(sliceuse,output_shape=(40,40,1),arguments={'index':0})(xu)    \n",
    "     \n",
    "    #xu = MaxPooling2D(pool_size=(2,2))(inputs)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    x= x7 #Add()([x7,x10resu,x11])  #x3resu,\n",
    "    #xrsu = Merge([ x,x2,x3],mode='concat')\n",
    "    model = Model(inputs=[inputs],outputs=x,name='vgggen5_12_Next40_80_5prev2')\n",
    "    return model\n",
    "\n",
    "model_inputconv6 = Input(shape=(60,60,3))\n",
    "\n",
    "vgggen5_15_Nextprev2 = vgggen5_12_Next40_80_5prev2(model_inputconv6,60)\n",
    "\n",
    "\n",
    "def vgggen5_12_Next40_80_5prev3(inputs,picsize):\n",
    "    weight_decay = 0.0005         \n",
    "   \n",
    "   \n",
    "    x6 = Reshape((picsize,picsize,3))(inputs)\n",
    "    \n",
    "    x=Conv2D(filters=32,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x6)\n",
    "    x= BatchNormalization(axis=chanDim)(x)\n",
    "    x= LeakyReLU(alpha=0.05)(x)       \n",
    "  \n",
    "    \n",
    "    x=Conv2D(filters=64,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x)\n",
    "    x= BatchNormalization(axis=chanDim)(x)\n",
    "    x1= LeakyReLU(alpha=0.05)(x) \n",
    "    \n",
    "    x5=Conv2D(filters=64,kernel_size=(3,3),strides=2,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x1)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)\n",
    "    \n",
    "    x5=Conv2D(filters=128,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)\n",
    "    \n",
    "    x5=Conv2D(filters=64,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)    \n",
    "    \n",
    "    x5=Conv2D(filters=128,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5_2= LeakyReLU(alpha=0.05)(x5)    \n",
    "    \n",
    "    \n",
    "    x5=Conv2D(filters=128,kernel_size=(3,3),strides=2,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5_2)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)\n",
    "    \n",
    "    x5=Conv2D(filters=256,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)\n",
    "    \n",
    "    x5=Conv2D(filters=128,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)    \n",
    "    \n",
    "    x5=Conv2D(filters=64,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5_3= LeakyReLU(alpha=0.05)(x5)       \n",
    "    \n",
    "    \n",
    "    x5=Conv2D(filters=128,kernel_size=(3,3),strides=2,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5_3)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)\n",
    "    \n",
    "    x5=Conv2D(filters=256,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)\n",
    "    \n",
    "    x5=Conv2D(filters=256,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)    \n",
    "    \n",
    "    x5=Conv2D(filters=128,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5_6= LeakyReLU(alpha=0.05)(x5)       \n",
    "    \n",
    "        \n",
    "    x5=Conv2D(filters=64,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5_6)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)\n",
    "    \n",
    "    x5 = Flatten()(x5)  \n",
    "    \n",
    "    x5 = Dense(1600 ,kernel_regularizer=regularizers.l2(weight_decay))(x5)         \n",
    "    x5= LeakyReLU(alpha=0.05)(x5)\n",
    "    \n",
    "    x5 = Dense(6000 ,kernel_regularizer=regularizers.l2(weight_decay))(x5)         \n",
    "    x5= LeakyReLU(alpha=0.05)(x5)\n",
    "    \n",
    "    x5 = Reshape((10,10,60))(x5)\n",
    "    \n",
    "    x5=Conv2D(filters=128,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)       \n",
    "    \n",
    "    \"\"\"\n",
    "    x5_6=Conv2D(filters=50,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5_3)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5_6)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)\n",
    "    \n",
    "    x5 = Flatten()(x5)  \n",
    "    \n",
    "    x5 = Dense(1200 ,kernel_regularizer=regularizers.l2(weight_decay))(x5)         \n",
    "    x5= LeakyReLU(alpha=0.05)(x5)\n",
    "    \n",
    "    x5 = Dense(11250 ,kernel_regularizer=regularizers.l2(weight_decay))(x5)         \n",
    "    x5= LeakyReLU(alpha=0.05)(x5)\n",
    "    \n",
    "    x5 = Reshape((15,15,50))(x5)\n",
    "    \n",
    "    x5=Conv2D(filters=64,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)       \n",
    "    \n",
    "    \n",
    "    x5=  Add()([x5_5,x5])\n",
    "    \"\"\"\n",
    "    x5=  Add()([x5,x5_6])\n",
    "    \n",
    "    x5=Conv2D(filters=64,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)    \n",
    "    \n",
    "    x5= UpSampling2D()(x5)    \n",
    "    \n",
    "    \n",
    "    x5=  Add()([x5,x5_3])\n",
    "    \n",
    "    x5=Conv2D(filters=128,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)    \n",
    "    \n",
    "    x5= UpSampling2D()(x5)    \n",
    "    \n",
    "    x5=  Add()([x5,x5_2])\n",
    "    \n",
    "    x5=Conv2D(filters=64,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)\n",
    "    \n",
    "    x5=Conv2D(filters=128,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)    \n",
    "    \n",
    "    x5=Conv2D(filters=64,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)    \n",
    "    \n",
    "    x5= UpSampling2D()(x5)\n",
    "    \n",
    "    x5=  Add()([x5,x1])\n",
    "    \n",
    "    x5=Conv2D(filters=32,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)\n",
    "    \n",
    "    x5=Conv2D(filters=64,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)\n",
    "    \n",
    "\n",
    "    x5=Conv2D(filters=64,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)     \n",
    "       \n",
    "    x7= UpSampling2D()(x5)  #80*80\n",
    "    \n",
    "    x7=Conv2D(filters=60,kernel_size=(5,5),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x7)\n",
    "    x7= BatchNormalization(axis=chanDim)(x7)\n",
    "    x7= LeakyReLU(alpha=0.05)(x7)\n",
    "    \n",
    "    x7=Conv2D(filters=32,kernel_size=(5,5),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x7)\n",
    "    x7= BatchNormalization(axis=chanDim)(x7)\n",
    "    x7= LeakyReLU(alpha=0.05)(x7)\n",
    "    \n",
    "    x7=Conv2D(filters=3,kernel_size=(5,5),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x7)\n",
    "    x7= BatchNormalization(axis=chanDim)(x7)\n",
    "    x7= LeakyReLU(alpha=0.05)(x7)\n",
    "    \n",
    "    #x3 = Lambda(lambda t: t[:,:,:,0])(input)\n",
    "    #xu = MaxPooling2D(pool_size=(2,2))(inputs)\n",
    "    #xc = Lambda(sliceuse,output_shape=(40,40,1),arguments={'index':0})(xu)    \n",
    "     \n",
    "    #xu = MaxPooling2D(pool_size=(2,2))(inputs)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    x= x7 #Add()([x7,x10resu,x11])  #x3resu,\n",
    "    #xrsu = Merge([ x,x2,x3],mode='concat')\n",
    "    model = Model(inputs=[inputs],outputs=x,name='vgggen5_12_Next40_80_5prev3')\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "vgggen5_15_Nextprev3 = vgggen5_12_Next40_80_5prev3(model_inputconv,80)\n",
    "\n",
    "def vgggen5_12_Next40_80_5(inputs,num):\n",
    "    weight_decay = 0.0005    \n",
    "       \n",
    "   \n",
    "    x6 = Reshape((40,40,3))(inputs)\n",
    "    \n",
    "    #x3 = Lambda(lambda t: t[:,:,:,0])(input)\n",
    "    #xu = MaxPooling2D(pool_size=(2,2))(inputs)\n",
    "    #xc = Lambda(sliceuse,output_shape=(40,40,1),arguments={'index':0})(xu)    \n",
    "     \n",
    "    #xu = MaxPooling2D(pool_size=(2,2))(inputs)\n",
    "    xc = Lambda(sliceuse,output_shape=(40,40,1),arguments={'index':num})(inputs)\n",
    "    xc = Reshape((40,40,1))(xc)  \n",
    "    \n",
    "    xr1 = Lambda(splitdata,output_shape=(20,20,1),arguments={'index':0,'inum':4})(xc)    \n",
    "    xr2 = Lambda(splitdata,output_shape=(20,20,1),arguments={'index':1,'inum':4})(xc)    \n",
    "    xr3 = Lambda(splitdata,output_shape=(20,20,1),arguments={'index':2,'inum':4})(xc)    \n",
    "    xr4 = Lambda(splitdata,output_shape=(20,20,1),arguments={'index':3,'inum':4})(xc)    \n",
    "    \n",
    "    #xr1,xr2,xr3,xr4 = Lambda(splitdata,arguments={'index':0,'inum':4})(xc)    \n",
    "    #xr = np.array(Lambda(splitdata,output_shape=(20,20,1),arguments={'index':0,'inum':4})(xc)) \n",
    "    #xr1,xr2,xr3,xr4 = Lambda(splitdata,output_shape=(20,20,1),arguments={'index':3,'inum':4})(xc)\n",
    "    xr = [xr1,xr2,xr3,xr4]\n",
    "    # ,output_shape=(20,20,1)\n",
    "    \n",
    "    x3 = xr\n",
    "    x3_1 = xr\n",
    "    \"\"\"\n",
    "    for m in range(4):        \n",
    "        x3[m] = Reshape((20,20,1))(xr[m])\n",
    "        x3[m] = Flatten()(x3[m])   \n",
    "        x3[m] = Dense(500 ,kernel_regularizer=regularizers.l2(weight_decay))(x3[m]) \n",
    "    #activation=\"relu\",\n",
    "        x3[m]= LeakyReLU(alpha=0.05)(x3[m])\n",
    "        x3[m] = Dense(800 ,kernel_regularizer=regularizers.l2(weight_decay))(x3[m])\n",
    "        x3[m]= LeakyReLU(alpha=0.05)(x3[m])\n",
    "        x3[m] = Dense(1000 ,kernel_regularizer=regularizers.l2(weight_decay))(x3[m])\n",
    "        x3[m]= LeakyReLU(alpha=0.05)(x3[m])        \n",
    "        x3[m] = Dense(600 ,kernel_regularizer=regularizers.l2(weight_decay))(x3[m])        \n",
    "        x3[m]= LeakyReLU(alpha=0.05)(x3[m])\n",
    "        x3[m] = Dense(1200 ,kernel_regularizer=regularizers.l2(weight_decay))(x3[m])\n",
    "        x3_1[m]= LeakyReLU(alpha=0.05)(x3[m])\n",
    "        x3[m] = Dense(600 ,kernel_regularizer=regularizers.l2(weight_decay))(x3_1[m])\n",
    "        x3[m]= LeakyReLU(alpha=0.05)(x3[m])\n",
    "        #x3[m] = Dense(1000 ,kernel_regularizer=regularizers.l2(weight_decay))(x3[m])\n",
    "        #x3[m]= LeakyReLU(alpha=0.05)(x3[m])        \n",
    "        x3[m] = Dense(600 ,kernel_regularizer=regularizers.l2(weight_decay))(x3[m])        \n",
    "        x3[m]= LeakyReLU(alpha=0.05)(x3[m])\n",
    "        x3[m] = Dense(1200 ,kernel_regularizer=regularizers.l2(weight_decay))(x3[m])\n",
    "        x3[m]= LeakyReLU(alpha=0.05)(x3[m])   \n",
    "        x3[m]=  Add()([x3[m],x3_1[m]])\n",
    "        x3[m] = Dense(900 ,kernel_regularizer=regularizers.l2(weight_decay))(x3[m])        \n",
    "        x3[m]= LeakyReLU(alpha=0.05)(x3[m])\n",
    "        x3[m] = Dense(40*40 ,kernel_regularizer=regularizers.l2(weight_decay))(x3[m])\n",
    "        x3[m]= LeakyReLU(alpha=0.05)(x3[m])\n",
    "        x3[m] = Reshape((40,40,1))(x3[m])\n",
    "         \n",
    "    x3resu =concatenate([x3[0],x3[1],x3[2],x3[3]])\n",
    "    x3resu =Reshape((80,80,1))(x3resu)\n",
    "    \"\"\"\n",
    "    x10 = [xr1,xr2,xr3,xr4]\n",
    "    for m in range(4):\n",
    "        x10[m] = Reshape((20,20,1))(x10[m])\n",
    "        x10[m] = Flatten()(x10[m])   \n",
    "        x10[m] = Dense(600 ,kernel_regularizer=regularizers.l2(weight_decay))(x10[m])         \n",
    "        x10[m]= LeakyReLU(alpha=0.05)(x10[m])\n",
    "        x10[m] = Dense(1600 ,kernel_regularizer=regularizers.l2(weight_decay))(x10[m])\n",
    "        x10[m]= LeakyReLU(alpha=0.05)(x10[m])\n",
    "        x10[m] = Dense(600 ,kernel_regularizer=regularizers.l2(weight_decay))(x10[m])\n",
    "        x10[m]= LeakyReLU(alpha=0.05)(x10[m])\n",
    "        x10[m] = Dense(1200 ,kernel_regularizer=regularizers.l2(weight_decay))(x10[m])\n",
    "        x10[m]= LeakyReLU(alpha=0.05)(x10[m])       \n",
    "        x10[m] = Dense(800 ,kernel_regularizer=regularizers.l2(weight_decay))(x10[m])\n",
    "        x10[m]= LeakyReLU(alpha=0.05)(x10[m])        \n",
    "        x10[m] = Dense(40*40 ,kernel_regularizer=regularizers.l2(weight_decay))(x10[m])\n",
    "        x10[m]= LeakyReLU(alpha=0.05)(x10[m])\n",
    "        x10[m] = Reshape((40,40,1))(x10[m]) \n",
    "          \n",
    "    x10resu =concatenate([x10[0],x10[1],x10[2],x10[3]])\n",
    "    x10resu =Reshape((80,80,1))(x10resu)\n",
    "    \n",
    "    \n",
    "    x11 = x6\n",
    "    x11=Conv2D(filters=64,kernel_size=(5,5),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x11)\n",
    "    x11= BatchNormalization(axis=chanDim)(x11)\n",
    "    x11= LeakyReLU(alpha=0.05)(x11)   \n",
    "    \n",
    "    x11=Conv2D(filters=64,kernel_size=(5,5),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x11)\n",
    "    x11= BatchNormalization(axis=chanDim)(x11)\n",
    "    x11= LeakyReLU(alpha=0.05)(x11)   \n",
    "    \n",
    "    x11= UpSampling2D()(x11)   \n",
    "    \n",
    "    x11=Conv2D(filters=64,kernel_size=(5,5),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x11)\n",
    "    x11= BatchNormalization(axis=chanDim)(x11)\n",
    "    x11= LeakyReLU(alpha=0.05)(x11)      \n",
    "    \n",
    "    x11_1=Conv2D(filters=64,kernel_size=(5,5),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x11)\n",
    "    x11_1= BatchNormalization(axis=chanDim)(x11_1)\n",
    "    x11_1= LeakyReLU(alpha=0.05)(x11_1)      \n",
    "    \n",
    "    x11=  Add()([x11,x11_1])\n",
    "    \n",
    "    x11=Conv2D(filters=1,kernel_size=(5,5),strides=1,padding=\"same\",activation=\"relu\",kernel_regularizer=regularizers.l2(weight_decay))(x11)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    x=  Add()([x10resu,x11])  #x3resu, x7,\n",
    "    #xrsu = Merge([ x,x2,x3],mode='concat')\n",
    "    model = Model(inputs=[inputs],outputs=x,name='vgggen5_12_Next40_80_5'+str(num))\n",
    "    return model\n",
    "\n",
    "pichalf = 30\n",
    "def vgggen5_12_Next40_80_6(inputs,num,picsize):\n",
    "    global pichalf\n",
    "    weight_decay = 0.0005    \n",
    "       \n",
    "    pichalf = (int)(picsize/2)\n",
    "    x6 = Reshape((picsize,picsize,3))(inputs)\n",
    "    \n",
    "    #x3 = Lambda(lambda t: t[:,:,:,0])(input)\n",
    "    #xu = MaxPooling2D(pool_size=(2,2))(inputs)\n",
    "    #xc = Lambda(sliceuse,output_shape=(40,40,1),arguments={'index':0})(xu)    \n",
    "     \n",
    "    #xu = MaxPooling2D(pool_size=(2,2))(inputs)\n",
    "    xc = Lambda(sliceuse,output_shape=(picsize,picsize,1),arguments={'index':num})(inputs)\n",
    "    xc = Reshape((picsize,picsize,1))(xc)  \n",
    "    \n",
    "    #pichalf = (int)(picsize/2)\n",
    "    \n",
    "    xr1 = Lambda(splitdata,output_shape=(pichalf,pichalf,1),arguments={'index':0,'inum':4})(xc)    \n",
    "    xr2 = Lambda(splitdata,output_shape=(pichalf,pichalf,1),arguments={'index':1,'inum':4})(xc)    \n",
    "    xr3 = Lambda(splitdata,output_shape=(pichalf,pichalf,1),arguments={'index':2,'inum':4})(xc)    \n",
    "    xr4 = Lambda(splitdata,output_shape=(pichalf,pichalf,1),arguments={'index':3,'inum':4})(xc)    \n",
    "    \n",
    "    #xr1,xr2,xr3,xr4 = Lambda(splitdata,arguments={'index':0,'inum':4})(xc)    \n",
    "    #xr = np.array(Lambda(splitdata,output_shape=(20,20,1),arguments={'index':0,'inum':4})(xc)) \n",
    "    #xr1,xr2,xr3,xr4 = Lambda(splitdata,output_shape=(20,20,1),arguments={'index':3,'inum':4})(xc)\n",
    "    xr = [xr1,xr2,xr3,xr4]\n",
    "    # ,output_shape=(20,20,1)\n",
    "    \n",
    "    x3 = xr\n",
    "    x3_1 = xr\n",
    "    \"\"\"\n",
    "    for m in range(4):        \n",
    "        x3[m] = Reshape((20,20,1))(xr[m])\n",
    "        x3[m] = Flatten()(x3[m])   \n",
    "        x3[m] = Dense(500 ,kernel_regularizer=regularizers.l2(weight_decay))(x3[m]) \n",
    "    #activation=\"relu\",\n",
    "        x3[m]= LeakyReLU(alpha=0.05)(x3[m])\n",
    "        x3[m] = Dense(800 ,kernel_regularizer=regularizers.l2(weight_decay))(x3[m])\n",
    "        x3[m]= LeakyReLU(alpha=0.05)(x3[m])\n",
    "        x3[m] = Dense(1000 ,kernel_regularizer=regularizers.l2(weight_decay))(x3[m])\n",
    "        x3[m]= LeakyReLU(alpha=0.05)(x3[m])        \n",
    "        x3[m] = Dense(600 ,kernel_regularizer=regularizers.l2(weight_decay))(x3[m])        \n",
    "        x3[m]= LeakyReLU(alpha=0.05)(x3[m])\n",
    "        x3[m] = Dense(1200 ,kernel_regularizer=regularizers.l2(weight_decay))(x3[m])\n",
    "        x3_1[m]= LeakyReLU(alpha=0.05)(x3[m])\n",
    "        x3[m] = Dense(600 ,kernel_regularizer=regularizers.l2(weight_decay))(x3_1[m])\n",
    "        x3[m]= LeakyReLU(alpha=0.05)(x3[m])\n",
    "        #x3[m] = Dense(1000 ,kernel_regularizer=regularizers.l2(weight_decay))(x3[m])\n",
    "        #x3[m]= LeakyReLU(alpha=0.05)(x3[m])        \n",
    "        x3[m] = Dense(600 ,kernel_regularizer=regularizers.l2(weight_decay))(x3[m])        \n",
    "        x3[m]= LeakyReLU(alpha=0.05)(x3[m])\n",
    "        x3[m] = Dense(1200 ,kernel_regularizer=regularizers.l2(weight_decay))(x3[m])\n",
    "        x3[m]= LeakyReLU(alpha=0.05)(x3[m])   \n",
    "        x3[m]=  Add()([x3[m],x3_1[m]])\n",
    "        x3[m] = Dense(900 ,kernel_regularizer=regularizers.l2(weight_decay))(x3[m])        \n",
    "        x3[m]= LeakyReLU(alpha=0.05)(x3[m])\n",
    "        x3[m] = Dense(40*40 ,kernel_regularizer=regularizers.l2(weight_decay))(x3[m])\n",
    "        x3[m]= LeakyReLU(alpha=0.05)(x3[m])\n",
    "        x3[m] = Reshape((40,40,1))(x3[m])\n",
    "         \n",
    "    x3resu =concatenate([x3[0],x3[1],x3[2],x3[3]])\n",
    "    x3resu =Reshape((80,80,1))(x3resu)\n",
    "    \"\"\"\n",
    "    firstsize = pichalf*pichalf\n",
    "    x10 = [xr1,xr2,xr3,xr4]\n",
    "    for m in range(4):\n",
    "        x10[m] = Reshape((pichalf,pichalf,1))(x10[m])\n",
    "        x10[m] = Flatten()(x10[m])   \n",
    "        x10[m] = Dense(1600 ,kernel_regularizer=regularizers.l2(weight_decay))(x10[m])         \n",
    "        x10[m]= LeakyReLU(alpha=0.05)(x10[m])       \n",
    "        x10[m] = Dense(900 ,kernel_regularizer=regularizers.l2(weight_decay))(x10[m])\n",
    "        x10[m]= LeakyReLU(alpha=0.05)(x10[m])        \n",
    "        x10[m] = Dense(firstsize ,kernel_regularizer=regularizers.l2(weight_decay))(x10[m])\n",
    "        x10[m]= LeakyReLU(alpha=0.05)(x10[m])\n",
    "        x10[m] = Dense(1200 ,kernel_regularizer=regularizers.l2(weight_decay))(x10[m])\n",
    "        x10[m]= LeakyReLU(alpha=0.05)(x10[m])       \n",
    "        x10[m] = Dense(900 ,kernel_regularizer=regularizers.l2(weight_decay))(x10[m])\n",
    "        x10[m]= LeakyReLU(alpha=0.05)(x10[m])        \n",
    "        x10[m] = Dense(picsize*picsize ,kernel_regularizer=regularizers.l2(weight_decay))(x10[m])\n",
    "        x10[m]= LeakyReLU(alpha=0.05)(x10[m])\n",
    "        x10[m] = Reshape((picsize,picsize,1))(x10[m]) \n",
    "          \n",
    "    x10resu =concatenate([x10[0],x10[1],x10[2],x10[3]])\n",
    "    x10resu =Reshape((picsize*2,picsize*2,1))(x10resu)\n",
    "    \n",
    "    \n",
    "    x11 = x6\n",
    "    x11=Conv2D(filters=64,kernel_size=(5,5),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x11)\n",
    "    x11= BatchNormalization(axis=chanDim)(x11)\n",
    "    x11= LeakyReLU(alpha=0.05)(x11)   \n",
    "    \n",
    "    x11=Conv2D(filters=64,kernel_size=(5,5),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x11)\n",
    "    x11= BatchNormalization(axis=chanDim)(x11)\n",
    "    x11= LeakyReLU(alpha=0.05)(x11)   \n",
    "    \n",
    "    x11= UpSampling2D()(x11)   \n",
    "    \n",
    "    x11=Conv2D(filters=64,kernel_size=(5,5),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x11)\n",
    "    x11= BatchNormalization(axis=chanDim)(x11)\n",
    "    x11= LeakyReLU(alpha=0.05)(x11)      \n",
    "    \n",
    "    x11_1=Conv2D(filters=64,kernel_size=(5,5),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x11)\n",
    "    x11_1= BatchNormalization(axis=chanDim)(x11_1)\n",
    "    x11_1= LeakyReLU(alpha=0.05)(x11_1)      \n",
    "    \n",
    "    x11=  Add()([x11,x11_1])\n",
    "    \n",
    "    x11=Conv2D(filters=1,kernel_size=(5,5),strides=1,padding=\"same\",activation=\"relu\",kernel_regularizer=regularizers.l2(weight_decay))(x11)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    x=  Add()([x10resu,x11])  #x3resu, x7,\n",
    "    #xrsu = Merge([ x,x2,x3],mode='concat')\n",
    "    model = Model(inputs=[inputs],outputs=x,name='vgggen5_12_Next40_80_6'+str(num))\n",
    "    return model\n",
    "\n",
    "\n",
    "def vgggen5_12_Next40_80_7(inputs,num,picsize):\n",
    "    global pichalf\n",
    "    weight_decay = 0.0005    \n",
    "       \n",
    "    pichalf = (int)(picsize/2)\n",
    "    x6 = Reshape((picsize,picsize,3))(inputs)\n",
    "    \n",
    "    #x3 = Lambda(lambda t: t[:,:,:,0])(input)\n",
    "    #xu = MaxPooling2D(pool_size=(2,2))(inputs)\n",
    "    #xc = Lambda(sliceuse,output_shape=(40,40,1),arguments={'index':0})(xu)    \n",
    "     \n",
    "    #xu = MaxPooling2D(pool_size=(2,2))(inputs)\n",
    "    xc = Lambda(sliceuse,output_shape=(picsize,picsize,1),arguments={'index':num})(inputs)\n",
    "    xc = Reshape((picsize,picsize,1))(xc)  \n",
    "    \n",
    "    #pichalf = (int)(picsize/2)\n",
    "    \n",
    "    xr1 = Lambda(splitdata,output_shape=(pichalf,pichalf,1),arguments={'index':0,'inum':4})(xc)    \n",
    "    xr2 = Lambda(splitdata,output_shape=(pichalf,pichalf,1),arguments={'index':1,'inum':4})(xc)    \n",
    "    xr3 = Lambda(splitdata,output_shape=(pichalf,pichalf,1),arguments={'index':2,'inum':4})(xc)    \n",
    "    xr4 = Lambda(splitdata,output_shape=(pichalf,pichalf,1),arguments={'index':3,'inum':4})(xc)    \n",
    "    \n",
    "    #xr1,xr2,xr3,xr4 = Lambda(splitdata,arguments={'index':0,'inum':4})(xc)    \n",
    "    #xr = np.array(Lambda(splitdata,output_shape=(20,20,1),arguments={'index':0,'inum':4})(xc)) \n",
    "    #xr1,xr2,xr3,xr4 = Lambda(splitdata,output_shape=(20,20,1),arguments={'index':3,'inum':4})(xc)\n",
    "    xr = [xr1,xr2,xr3,xr4]\n",
    "    # ,output_shape=(20,20,1)\n",
    "    \n",
    "    x3 = xr\n",
    "    x3_1 = xr\n",
    "    \"\"\"\n",
    "    for m in range(4):        \n",
    "        x3[m] = Reshape((20,20,1))(xr[m])\n",
    "        x3[m] = Flatten()(x3[m])   \n",
    "        x3[m] = Dense(500 ,kernel_regularizer=regularizers.l2(weight_decay))(x3[m]) \n",
    "    #activation=\"relu\",\n",
    "        x3[m]= LeakyReLU(alpha=0.05)(x3[m])\n",
    "        x3[m] = Dense(800 ,kernel_regularizer=regularizers.l2(weight_decay))(x3[m])\n",
    "        x3[m]= LeakyReLU(alpha=0.05)(x3[m])\n",
    "        x3[m] = Dense(1000 ,kernel_regularizer=regularizers.l2(weight_decay))(x3[m])\n",
    "        x3[m]= LeakyReLU(alpha=0.05)(x3[m])        \n",
    "        x3[m] = Dense(600 ,kernel_regularizer=regularizers.l2(weight_decay))(x3[m])        \n",
    "        x3[m]= LeakyReLU(alpha=0.05)(x3[m])\n",
    "        x3[m] = Dense(1200 ,kernel_regularizer=regularizers.l2(weight_decay))(x3[m])\n",
    "        x3_1[m]= LeakyReLU(alpha=0.05)(x3[m])\n",
    "        x3[m] = Dense(600 ,kernel_regularizer=regularizers.l2(weight_decay))(x3_1[m])\n",
    "        x3[m]= LeakyReLU(alpha=0.05)(x3[m])\n",
    "        #x3[m] = Dense(1000 ,kernel_regularizer=regularizers.l2(weight_decay))(x3[m])\n",
    "        #x3[m]= LeakyReLU(alpha=0.05)(x3[m])        \n",
    "        x3[m] = Dense(600 ,kernel_regularizer=regularizers.l2(weight_decay))(x3[m])        \n",
    "        x3[m]= LeakyReLU(alpha=0.05)(x3[m])\n",
    "        x3[m] = Dense(1200 ,kernel_regularizer=regularizers.l2(weight_decay))(x3[m])\n",
    "        x3[m]= LeakyReLU(alpha=0.05)(x3[m])   \n",
    "        x3[m]=  Add()([x3[m],x3_1[m]])\n",
    "        x3[m] = Dense(900 ,kernel_regularizer=regularizers.l2(weight_decay))(x3[m])        \n",
    "        x3[m]= LeakyReLU(alpha=0.05)(x3[m])\n",
    "        x3[m] = Dense(40*40 ,kernel_regularizer=regularizers.l2(weight_decay))(x3[m])\n",
    "        x3[m]= LeakyReLU(alpha=0.05)(x3[m])\n",
    "        x3[m] = Reshape((40,40,1))(x3[m])\n",
    "         \n",
    "    x3resu =concatenate([x3[0],x3[1],x3[2],x3[3]])\n",
    "    x3resu =Reshape((80,80,1))(x3resu)\n",
    "    \"\"\"\n",
    "    firstsize = pichalf*pichalf\n",
    "    x10 = [xr1,xr2,xr3,xr4]\n",
    "    for m in range(4):\n",
    "        x10[m] = Reshape((pichalf,pichalf,1))(x10[m])\n",
    "        x10[m] = Flatten()(x10[m])   \n",
    "        x10[m] = Dense(800 ,kernel_regularizer=regularizers.l2(weight_decay))(x10[m])         \n",
    "        x10[m]= LeakyReLU(alpha=0.05)(x10[m])       \n",
    "        x10[m] = Dense(800 ,kernel_regularizer=regularizers.l2(weight_decay))(x10[m])\n",
    "        x10[m]= LeakyReLU(alpha=0.05)(x10[m])        \n",
    "        x10[m] = Dense(firstsize ,kernel_regularizer=regularizers.l2(weight_decay))(x10[m])\n",
    "        x10[m]= LeakyReLU(alpha=0.05)(x10[m])\n",
    "        x10[m] = Dense(800 ,kernel_regularizer=regularizers.l2(weight_decay))(x10[m])\n",
    "        x10[m]= LeakyReLU(alpha=0.05)(x10[m])       \n",
    "        x10[m] = Dense(500 ,kernel_regularizer=regularizers.l2(weight_decay))(x10[m])\n",
    "        x10[m]= LeakyReLU(alpha=0.05)(x10[m])        \n",
    "        x10[m] = Dense(picsize*picsize ,kernel_regularizer=regularizers.l2(weight_decay))(x10[m])\n",
    "        x10[m]= LeakyReLU(alpha=0.05)(x10[m])\n",
    "        x10[m] = Reshape((picsize,picsize,1))(x10[m]) \n",
    "          \n",
    "    x10resu =concatenate([x10[0],x10[1],x10[2],x10[3]])\n",
    "    x10resu =Reshape((picsize*2,picsize*2,1))(x10resu)\n",
    "    \n",
    "    \n",
    "    x11 = x6\n",
    "    x11=Conv2D(filters=64,kernel_size=(5,5),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x11)\n",
    "    x11= BatchNormalization(axis=chanDim)(x11)\n",
    "    x11= LeakyReLU(alpha=0.05)(x11)   \n",
    "    \n",
    "    x11=Conv2D(filters=64,kernel_size=(5,5),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x11)\n",
    "    x11= BatchNormalization(axis=chanDim)(x11)\n",
    "    x11= LeakyReLU(alpha=0.05)(x11)   \n",
    "    \n",
    "    x11= UpSampling2D()(x11)   \n",
    "    \n",
    "    x11=Conv2D(filters=64,kernel_size=(5,5),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x11)\n",
    "    x11= BatchNormalization(axis=chanDim)(x11)\n",
    "    x11= LeakyReLU(alpha=0.05)(x11)      \n",
    "    \n",
    "    x11_1=Conv2D(filters=64,kernel_size=(5,5),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x11)\n",
    "    x11_1= BatchNormalization(axis=chanDim)(x11_1)\n",
    "    x11_1= LeakyReLU(alpha=0.05)(x11_1)      \n",
    "    \n",
    "    x11=  Add()([x11,x11_1])\n",
    "    \n",
    "    x11=Conv2D(filters=1,kernel_size=(5,5),strides=1,padding=\"same\",activation=\"relu\",kernel_regularizer=regularizers.l2(weight_decay))(x11)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    x=  Add()([x10resu,x11])  #x3resu, x7,\n",
    "    #xrsu = Merge([ x,x2,x3],mode='concat')\n",
    "    model = Model(inputs=[inputs],outputs=x,name='vgggen5_12_Next40_80_7'+str(num))\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def vgggen5_16_Next(inputs,num):\n",
    "    weight_decay = 0.0005 \n",
    "   \n",
    "    \"\"\"\n",
    "    red_x = x[:,:,:,0]\n",
    "    blue_x = x[:,:,:,2]\n",
    "    green_x = x[:,:,:,1]\n",
    "    \"\"\"\n",
    "    #x =  MaxPooling2D(pool_size=(2,2))(inputs)\n",
    "    #inputs = Lambda(sliceuse,output_shape=(16,16,1),arguments={'index':0})(inputs)\n",
    "    x6 = Lambda(sliceuse,output_shape=(40,40,1),arguments={'index':num})(inputs)\n",
    "    x6 = Reshape((40,40,1))(x6)\n",
    "    \n",
    "    x=Conv2D(filters=32,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x6)\n",
    "    x= BatchNormalization(axis=chanDim)(x)\n",
    "    x= LeakyReLU(alpha=0.05)(x)       \n",
    "    \n",
    "    \n",
    "    x=Conv2D(filters=32,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x)\n",
    "    x= BatchNormalization(axis=chanDim)(x)\n",
    "    x1= LeakyReLU(alpha=0.05)(x) \n",
    "    \n",
    "    x5=Conv2D(filters=64,kernel_size=(3,3),strides=2,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x1)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)\n",
    "    \n",
    "    x5=Conv2D(filters=64,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)\n",
    "    \n",
    "    x5=Conv2D(filters=64,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)\n",
    "    \n",
    "    x9=Conv2D(filters=64,kernel_size=(3,3),strides=2,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x9= BatchNormalization(axis=chanDim)(x9)\n",
    "    x9= LeakyReLU(alpha=0.05)(x9)\n",
    "    \n",
    "    x9=Conv2D(filters=128,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x9)\n",
    "    x9= BatchNormalization(axis=chanDim)(x9)\n",
    "    x9= LeakyReLU(alpha=0.05)(x9)\n",
    "    \n",
    "    x9=Conv2D(filters=128,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x9)\n",
    "    x9= BatchNormalization(axis=chanDim)(x9)\n",
    "    x9= LeakyReLU(alpha=0.05)(x9)\n",
    "    \n",
    "    x10= UpSampling2D()(x9)\n",
    "    \n",
    "    x10=Conv2D(filters=64,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x10)\n",
    "    x10= BatchNormalization(axis=chanDim)(x10)\n",
    "    x10= LeakyReLU(alpha=0.05)(x10)\n",
    "    \n",
    "    x10=Conv2D(filters=64,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x10)\n",
    "    x10= BatchNormalization(axis=chanDim)(x10)\n",
    "    x10= LeakyReLU(alpha=0.05)(x10)  \n",
    "    \n",
    "    \n",
    "    x5=  Add()([x5,x10])\n",
    "    x5= UpSampling2D()(x5)\n",
    "        \n",
    "    \n",
    "    x5=Conv2D(filters=64,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)    \n",
    "   \n",
    "    \n",
    "    x5=Conv2D(filters=32,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)\n",
    "    \n",
    "    x5=  Add()([x5,x1])\n",
    "    x5= UpSampling2D()(x5)\n",
    "    \n",
    "    x5=Conv2D(filters=32,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)\n",
    "    \n",
    "    x5=Conv2D(filters=32,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)    \n",
    "   \n",
    "    \n",
    "    x5=Conv2D(filters=1,kernel_size=(3,3),strides=1,padding=\"same\",activation=\"relu\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)\n",
    "    \n",
    "   \n",
    "    \n",
    "    xu = inputs\n",
    "    xc = Lambda(sliceuse,output_shape=(40,40,1),arguments={'index':num})(xu)\n",
    "    xc = Reshape((40,40,1))(xc)  \n",
    "    \n",
    "    xr1 = Lambda(splitdata,output_shape=(20,20,1),arguments={'index':0,'inum':4})(xc)    \n",
    "    xr2 = Lambda(splitdata,output_shape=(20,20,1),arguments={'index':1,'inum':4})(xc)    \n",
    "    xr3 = Lambda(splitdata,output_shape=(20,20,1),arguments={'index':2,'inum':4})(xc)    \n",
    "    xr4 = Lambda(splitdata,output_shape=(20,20,1),arguments={'index':3,'inum':4})(xc)    \n",
    "    \n",
    "    #xr1,xr2,xr3,xr4 = Lambda(splitdata,arguments={'index':0,'inum':4})(xc)    \n",
    "    #xr = np.array(Lambda(splitdata,output_shape=(20,20,1),arguments={'index':0,'inum':4})(xc)) \n",
    "    #xr1,xr2,xr3,xr4 = Lambda(splitdata,output_shape=(20,20,1),arguments={'index':3,'inum':4})(xc)\n",
    "    xr = [xr1,xr2,xr3,xr4]\n",
    "    # ,output_shape=(20,20,1)\n",
    "    \n",
    "    x3 = xr\n",
    "    for m in range(4):        \n",
    "        x3[m] = Reshape((20,20,1))(xr[m])\n",
    "        x3[m] = Flatten()(x3[m])   \n",
    "        x3[m] = Dense(600 ,kernel_regularizer=regularizers.l2(weight_decay))(x3[m]) \n",
    "    #activation=\"relu\",\n",
    "        x3[m]= LeakyReLU(alpha=0.05)(x3[m])\n",
    "        x3[m] = Dense(800 ,kernel_regularizer=regularizers.l2(weight_decay))(x3[m])\n",
    "        x3[m]= LeakyReLU(alpha=0.05)(x3[m])\n",
    "        x3[m] = Dense(1000 ,kernel_regularizer=regularizers.l2(weight_decay))(x3[m])\n",
    "        x3[m]= LeakyReLU(alpha=0.05)(x3[m])\n",
    "        x3[m] = Dense(40*40 ,kernel_regularizer=regularizers.l2(weight_decay))(x3[m])\n",
    "        x3[m]= LeakyReLU(alpha=0.05)(x3[m])\n",
    "        x3[m] = Reshape((40,40,1))(x3[m])\n",
    "         \n",
    "    x3resu =concatenate([x3[0],x3[1],x3[2],x3[3]])\n",
    "    x3resu =Reshape((80,80,1))(x3resu)\n",
    "    \n",
    "    x10 = [xr1,xr2,xr3,xr4]\n",
    "    for m in range(4):\n",
    "        x10[m] = Reshape((20,20,1))(x10[m])\n",
    "        x10[m] = Flatten()(x10[m])   \n",
    "        x10[m] = Dense(600 ,kernel_regularizer=regularizers.l2(weight_decay))(x10[m]) \n",
    "        #activation=\"relu\",\n",
    "        x10[m]= LeakyReLU(alpha=0.05)(x10[m])\n",
    "        x10[m] = Dense(1000 ,kernel_regularizer=regularizers.l2(weight_decay))(x10[m])\n",
    "        x10[m]= LeakyReLU(alpha=0.05)(x10[m])\n",
    "        x10[m] = Dense(40*40 ,kernel_regularizer=regularizers.l2(weight_decay))(x10[m])\n",
    "        x10[m]= LeakyReLU(alpha=0.05)(x10[m])\n",
    "        x10[m] = Reshape((40,40,1))(x10[m]) \n",
    "          \n",
    "    x10resu =concatenate([x10[0],x10[1],x10[2],x10[3]])\n",
    "    x10resu =Reshape((80,80,1))(x10resu)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    x= UpSampling2D()(x1)      \n",
    "   \n",
    "    x=Conv2D(filters=64,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x)\n",
    "    x= BatchNormalization(axis=chanDim)(x)\n",
    "    \n",
    "    x=Conv2D(filters=64,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x)\n",
    "    x= BatchNormalization(axis=chanDim)(x)\n",
    "    \n",
    "    \n",
    "    x=Conv2D(filters=32,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x)\n",
    "    x= BatchNormalization(axis=chanDim)(x)\n",
    "    x= LeakyReLU(alpha=0.05)(x)       \n",
    "    \n",
    "    x13 = Conv2D(filters=32,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x)\n",
    "    x13= BatchNormalization(axis=chanDim)(x13)\n",
    "    x=  Add()([x,x13]) \n",
    "    \n",
    "    \n",
    "    x=Conv2D(filters=1,kernel_size=(3,3),strides=1,padding=\"same\",activation=\"tanh\",kernel_regularizer=regularizers.l2(weight_decay))(x)\n",
    "     \n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    x11 = UpSampling2D()(x6)\n",
    "    x11=Conv2D(filters=32,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x11)\n",
    "    x11= BatchNormalization(axis=chanDim)(x11)\n",
    "    x11= LeakyReLU(alpha=0.05)(x11)   \n",
    "    \n",
    "    x11=Conv2D(filters=1,kernel_size=(3,3),strides=1,padding=\"same\",activation=\"tanh\",kernel_regularizer=regularizers.l2(weight_decay))(x11)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    x=  Add()([x3resu,x5,x,x10resu,x11])\n",
    "    #xrsu = Merge([ x,x2,x3],mode='concat')\n",
    "    model = Model(inputs=[inputs],outputs=x,name='vgggen5_16_Next'+str(num))\n",
    "    return model\n",
    "\n",
    "def vgggen15mod(inputs,num,size,mode):\n",
    "    weight_decay = 0.0005    \n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    #x =  MaxPooling2D(pool_size=(2,2))(inputs)\n",
    "    #inputs = Lambda(sliceuse,output_shape=(16,16,1),arguments={'index':0})(inputs)\n",
    "    \"\"\"\n",
    "    x6 = Lambda(sliceuse,output_shape=(size,size,1),arguments={'index':num})(inputs)\n",
    "    x6 = Reshape((size,size,1))(x6)\n",
    "    \n",
    "    x=Conv2D(filters=32,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x6)\n",
    "    x= BatchNormalization(axis=chanDim)(x)\n",
    "    x2= LeakyReLU(alpha=0.05)(x)       \n",
    "  \n",
    "    \n",
    "    x=Conv2D(filters=32,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x2)\n",
    "    x= BatchNormalization(axis=chanDim)(x)\n",
    "    x1= LeakyReLU(alpha=0.05)(x) \n",
    "    \n",
    "    x5=Conv2D(filters=32,kernel_size=(3,3),strides=2,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x1)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5_1= LeakyReLU(alpha=0.05)(x5)\n",
    "    \n",
    "    x5=Conv2D(filters=64,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5_1)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)\n",
    "    \n",
    "    x5=Conv2D(filters=64,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5_2= LeakyReLU(alpha=0.05)(x5)\n",
    "    \n",
    "    \n",
    "    x5=Conv2D(filters=64,kernel_size=(3,3),strides=2,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5_2)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)\n",
    "    \n",
    "    x5=Conv2D(filters=128,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)\n",
    "    \n",
    "    x5=Conv2D(filters=128,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)\n",
    "    \n",
    "    x5=Conv2D(filters=64,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)\n",
    "       \n",
    "    x5= UpSampling2D()(x5)\n",
    "    \n",
    "    x5=  Add()([x5,x5_2])\n",
    "    x5=Conv2D(filters=64,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)\n",
    "    \n",
    "    x5=Conv2D(filters=64,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)\n",
    "    \n",
    "    x5=Conv2D(filters=32,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)\n",
    "    \n",
    "    x5= UpSampling2D()(x5)\n",
    "    x5=  Add()([x5,x1])    \n",
    "    \n",
    "    x5=Conv2D(filters=32,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)\n",
    "    \n",
    "    x5=Conv2D(filters=32,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    x5= BatchNormalization(axis=chanDim)(x5)\n",
    "    x5= LeakyReLU(alpha=0.05)(x5)\n",
    "    \n",
    "\n",
    "    #x5=Conv2D(filters=1,kernel_size=(3,3),strides=1,padding=\"same\",activation=\"sigmoid\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "    if mode ==0:\n",
    "        x5=Conv2D(filters=1,kernel_size=(3,3),strides=1,padding=\"same\",activation=\"tanh\",kernel_regularizer=regularizers.l2(weight_decay))(x5)        \n",
    "        model = Model(inputs=[inputs],outputs=x5,name='vgggen15modn'+str(num))\n",
    "    if mode ==1:\n",
    "        x5=Conv2D(filters=1,kernel_size=(3,3),strides=1,padding=\"same\",activation=\"sigmoid\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "        model = Model(inputs=[inputs],outputs=x5,name='vgggen15modm'+str(num))    \n",
    "    if mode ==2:\n",
    "        x5=Conv2D(filters=1,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x5)\n",
    "        x5= LeakyReLU(alpha=0.05)(x5)\n",
    "        model = Model(inputs=[inputs],outputs=x5,name='vgggen15modr'+str(num))  \n",
    "    return model\n",
    "vgggen15mod1 = vgggen15mod(model_inputconv,0,80,2)\n",
    "vgggen15mod2 = vgggen15mod(model_inputconv,1,80,2)\n",
    "vgggen15mod3 = vgggen15mod(model_inputconv,2,80,2)\n",
    "\n",
    "def vgggen5_15_MNext(inputs,num,size):\n",
    "    weight_decay = 0.0005    \n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    #x =  MaxPooling2D(pool_size=(2,2))(inputs)\n",
    "    #inputs = Lambda(sliceuse,output_shape=(16,16,1),arguments={'index':0})(inputs)\n",
    "    \"\"\"\n",
    "    x6 = Lambda(sliceuse,output_shape=(size,size,1),arguments={'index':num})(inputs)\n",
    "    x6 = Reshape((size,size,1))(x6)\n",
    "    \n",
    "    if num==0:\n",
    "        x5 = vgggen15mod1(inputs)   \n",
    "    if num==1:\n",
    "        x5 = vgggen15mod2(inputs)   \n",
    "    if num==2:\n",
    "        x5 = vgggen15mod3(inputs)   \n",
    "\n",
    "    \n",
    "    x11 = x6\n",
    "    x11=Conv2D(filters=32,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x11)\n",
    "    x11= BatchNormalization(axis=chanDim)(x11)\n",
    "    x11= LeakyReLU(alpha=0.05)(x11)   \n",
    "    \n",
    "    x13 = Conv2D(filters=32,kernel_size=(3,3),strides=1,padding=\"same\",kernel_regularizer=regularizers.l2(weight_decay))(x11)\n",
    "    x13= BatchNormalization(axis=chanDim)(x13)\n",
    "    x11=  Add()([x11,x13]) \n",
    "    \n",
    "    x11=Conv2D(filters=1,kernel_size=(3,3),strides=1,padding=\"same\",activation=\"sigmoid\",kernel_regularizer=regularizers.l2(weight_decay))(x11)\n",
    "    #\n",
    "    x11= LeakyReLU(alpha=0.05)(x11)\n",
    "       \n",
    "    \n",
    "    x=  Add()([x5,x11])\n",
    "    #xrsu = Merge([ x,x2,x3],mode='concat')\n",
    "    model = Model(inputs=[inputs],outputs=x,name='vgggen5_15_MNext'+str(num))\n",
    "    return model\n",
    "\n",
    "\n",
    "vgggen5_15_MNext1 = vgggen5_15_MNext(model_inputconv,0,80)\n",
    "vgggen5_15_MNext2 = vgggen5_15_MNext(model_inputconv,1,80)\n",
    "vgggen5_15_MNext3 = vgggen5_15_MNext(model_inputconv,2,80)\n",
    "\n",
    "def modevgg16_gen_20_7(inputs):      \n",
    "    \n",
    "    vgggen5_15_MNext1.trainable = True    \n",
    "    vgggen5_15_MNext2.trainable = True    \n",
    "    vgggen5_15_MNext3.trainable = True    \n",
    "    x =  inputs\n",
    "    \n",
    "    x2 = vgggen5_15_MNext1(x)\n",
    "    x3 = vgggen5_15_MNext2(x)\n",
    "    x5 = vgggen5_15_MNext3(x)\n",
    "    xrsu = concatenate([x2,x3,x5])\n",
    "    layer_model = Model(inputs=inputs,outputs=xrsu)\n",
    "    return layer_model\n",
    "\n",
    "\n",
    "model_inputconv5 = Input(shape=(20,20,128))\n",
    "\n",
    "\n",
    "\n",
    "model_inputconv3 = Input(shape=(20,20,3))\n",
    "\n",
    "vgggen5_12_Next1 =vgggen5_12_Next(model_inputconv3,0)\n",
    "vgggen5_12_Next2 =vgggen5_12_Next(model_inputconv3,1)\n",
    "vgggen5_12_Next3 =vgggen5_12_Next(model_inputconv3,2)\n",
    "\n",
    "def modevgg16_gen_19(inputs):      \n",
    "    \n",
    "    vgggen5_12_Next1.trainable = True    \n",
    "    vgggen5_12_Next2.trainable = True    \n",
    "    vgggen5_12_Next3.trainable = True    \n",
    "    x =  inputs\n",
    "    x = AveragePooling2D((2, 2))(x)\n",
    "    x = AveragePooling2D((2, 2))(x)\n",
    "    x2 = vgggen5_12_Next1(x)\n",
    "    x3 = vgggen5_12_Next2(x)\n",
    "    x5 = vgggen5_12_Next3(x)\n",
    "    xrsu = concatenate([x2,x3,x5])\n",
    "    layer_model = Model(inputs=inputs,outputs=xrsu)\n",
    "    return layer_model\n",
    "\n",
    "\n",
    "vgggen5_15_Next1 =vgggen5_12_Next40_80_5(model_inputconv2,0)\n",
    "vgggen5_15_Next2 =vgggen5_12_Next40_80_5(model_inputconv2,1)\n",
    "vgggen5_15_Next3 =vgggen5_12_Next40_80_5(model_inputconv2,2)\n",
    "\n",
    "\n",
    "def modevgg16_gen_20(inputs):      \n",
    "    \n",
    "    vgggen5_12_Next1.trainable = True    \n",
    "    vgggen5_12_Next2.trainable = True    \n",
    "    vgggen5_12_Next3.trainable = True    \n",
    "    x =  inputs\n",
    "    x = AveragePooling2D((2, 2))(x)\n",
    "    x = AveragePooling2D((2, 2))(x)\n",
    "    x2 = vgggen5_12_Next1(x)\n",
    "    x3 = vgggen5_12_Next2(x)\n",
    "    x5 = vgggen5_12_Next3(x)\n",
    "    xrsu = concatenate([x2,x3,x5])\n",
    "    layer_model = Model(inputs=inputs,outputs=xrsu)\n",
    "    return layer_model\n",
    "\n",
    "def modevgg16_gen_20_2(inputs):      \n",
    "    \n",
    "    vgggen5_15_Next1.trainable = True    \n",
    "    vgggen5_15_Next2.trainable = True    \n",
    "    vgggen5_15_Next3.trainable = True    \n",
    "    x =  inputs\n",
    "    x = AveragePooling2D((2, 2))(x)\n",
    "    #x = AveragePooling2D((2, 2))(x)\n",
    "    x1 = vgggen5_15_Nextprev(x)\n",
    "    x2 = vgggen5_15_Next1(x)\n",
    "    x3 = vgggen5_15_Next2(x)\n",
    "    x5 = vgggen5_15_Next3(x)\n",
    "    xrsu = concatenate([x2,x3,x5])\n",
    "    xrsu=  Add()([x1,xrsu])\n",
    "    layer_model = Model(inputs=inputs,outputs=xrsu)\n",
    "    return layer_model\n",
    "\n",
    "\n",
    "                     \n",
    "vgggen5_19_Next1 =vgggen5_12_Next40_80_6(model_inputconv6,0,60)\n",
    "vgggen5_19_Next2 =vgggen5_12_Next40_80_6(model_inputconv6,1,60)\n",
    "vgggen5_19_Next3 =vgggen5_12_Next40_80_6(model_inputconv6,2,60)\n",
    "            \n",
    "\n",
    "def modevgg16_gen_20_3(inputs):      \n",
    "    \n",
    "    vgggen5_19_Next1.trainable = True    \n",
    "    vgggen5_19_Next2.trainable = True    \n",
    "    vgggen5_19_Next3.trainable = True    \n",
    "    x =  inputs\n",
    "    x = AveragePooling2D((2, 2))(x)\n",
    "    #x = AveragePooling2D((2, 2))(x)\n",
    "    x1 = vgggen5_15_Nextprev2(x)\n",
    "    x2 = vgggen5_19_Next1(x)\n",
    "    x3 = vgggen5_19_Next2(x)\n",
    "    x5 = vgggen5_19_Next3(x)\n",
    "    xrsu = concatenate([x2,x3,x5])\n",
    "    xrsu=  Add()([x1,xrsu])\n",
    "    layer_model = Model(inputs=inputs,outputs=xrsu)\n",
    "    return layer_model\n",
    "                        \n",
    "\n",
    "\n",
    "vgggen5_20_Next1 =vgggen5_12_Next40_80_7(model_inputconv,0,80)\n",
    "vgggen5_20_Next2 =vgggen5_12_Next40_80_7(model_inputconv,1,80)\n",
    "vgggen5_20_Next3 =vgggen5_12_Next40_80_7(model_inputconv,2,80)\n",
    "    \n",
    "    \n",
    "def modevgg16_gen_20_5(inputs):      \n",
    "    \n",
    "    vgggen5_20_Next1.trainable = True    \n",
    "    vgggen5_20_Next2.trainable = True    \n",
    "    vgggen5_20_Next3.trainable = True    \n",
    "    x =  inputs\n",
    "    x = AveragePooling2D((2, 2))(x)\n",
    "    #x = AveragePooling2D((2, 2))(x)\n",
    "    x1 = vgggen5_15_Nextprev3(x)\n",
    "    x2 = vgggen5_20_Next1(x)\n",
    "    x3 = vgggen5_20_Next2(x)\n",
    "    x5 = vgggen5_20_Next3(x)\n",
    "    xrsu = concatenate([x2,x3,x5])\n",
    "    xrsu=  Add()([x1,xrsu])\n",
    "    layer_model = Model(inputs=inputs,outputs=xrsu)\n",
    "    return layer_model\n",
    "                         \n",
    "vgggen5_16_Next1 = vgggen5_16_Next(model_inputconv2,0)\n",
    "vgggen5_16_Next2 = vgggen5_16_Next(model_inputconv2,1)\n",
    "vgggen5_16_Next3 = vgggen5_16_Next(model_inputconv2,2)\n",
    "\n",
    "def modevgg16_gen_21(inputs):      \n",
    "    \n",
    "    vgggen5_16_Next1.trainable = True    \n",
    "    vgggen5_16_Next2.trainable = True    \n",
    "    vgggen5_16_Next3.trainable = True    \n",
    "    x =  MaxPooling2D(pool_size=(2,2))(inputs)\n",
    "    \n",
    "    x2 = vgggen5_16_Next1(x)\n",
    "    x3 = vgggen5_16_Next2(x)\n",
    "    x5 = vgggen5_16_Next3(x)\n",
    "    xrsu = concatenate([x2,x3,x5])\n",
    "    layer_model = Model(inputs=inputs,outputs=xrsu)\n",
    "    return layer_model\n",
    "\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "bload = True\n",
    "\n",
    "\n",
    "modevgg16_gen_19= modevgg16_gen_19(model_inputconv)\n",
    "\n",
    "modevgg16_gen_21= modevgg16_gen_21(model_inputconv)\n",
    "\n",
    "modevgg16_gen_20_7= modevgg16_gen_20_7(model_inputconv)\n",
    "\n",
    "modevgg16_gen_20= modevgg16_gen_20(model_inputconv)\n",
    "\n",
    "modevgg16_gen_20_2 = modevgg16_gen_20_2(model_inputconv)\n",
    "                         \n",
    "modevgg16_gen_20_3 = modevgg16_gen_20_3(model_inputconv9)\n",
    "\n",
    "modevgg16_gen_20_5 = modevgg16_gen_20_5(model_inputconv10)\n",
    "\n",
    "modevgg16_gen_19.summary()\n",
    "\n",
    "modevgg16_gen_21.summary()\n",
    "\n",
    "modevgg16_gen_20_7.summary()\n",
    "\n",
    "modevgg16_gen_20.summary()\n",
    "\n",
    "modevgg16_gen_20_2.summary()\n",
    "                         \n",
    "modevgg16_gen_20_3.summary()\n",
    "\n",
    "modevgg16_gen_20_5.summary() \n",
    "\n",
    "\"\"\"\n",
    "def gencompile1():    \n",
    "    modevgg16_gen_19.compile(optimizer = 'adadelta', loss = 'binary_crossentropy',  metrics = ['acc'])\n",
    "    modevgg16_gen_21.compile(optimizer = 'adadelta', loss = 'binary_crossentropy',  metrics = ['acc'])\n",
    "    modevgg16_gen_20_7.compile(optimizer = 'adadelta', loss = 'binary_crossentropy',  metrics = ['acc'])\n",
    "    \n",
    "def gencompile2():    \n",
    "    modevgg16_gen_19.compile(optimizer = optimizer, loss = msesum,  metrics = ['acc', lr_metric])\n",
    "    modevgg16_gen_21.compile(optimizer = optimizer, loss = msesum,  metrics = ['acc', lr_metric])\n",
    "    modevgg16_gen_20_7.compile(optimizer = 'adadelta', loss = 'binary_crossentropy',  metrics = ['acc'])\n",
    "\"\"\"\n",
    "\n",
    "def gencompile1():    \n",
    "    modevgg16_gen_19.compile(optimizer = 'adadelta', loss = msesum,  metrics = ['acc'])\n",
    "    modevgg16_gen_21.compile(optimizer = 'adadelta', loss = msesum,  metrics = ['acc'])\n",
    "    modevgg16_gen_20.compile(optimizer = 'adadelta', loss = msesum,  metrics = ['acc'])\n",
    "    modevgg16_gen_20_7.compile(optimizer = 'adadelta', loss = msesum,  metrics = ['acc'])\n",
    "    modevgg16_gen_20_2.compile(optimizer = 'adadelta', loss = msesum,  metrics = ['acc'])\n",
    "    modevgg16_gen_20_3.compile(optimizer = 'adadelta', loss = msesum,  metrics = ['acc'])\n",
    "    modevgg16_gen_20_5.compile(optimizer = 'adadelta', loss = msesum,  metrics = ['acc'])\n",
    "    \n",
    "def gencompile2():    \n",
    "    #modevgg16_gen_19.compile(optimizer = 'adadelta', loss = msesum,  metrics = ['acc', lr_metric])\n",
    "    #modevgg16_gen_21.compile(optimizer = 'adadelta', loss = msesum,  metrics = ['acc', lr_metric])\n",
    "    modevgg16_gen_19.compile(optimizer = 'adadelta', loss = msesum,  metrics = ['acc'])\n",
    "    modevgg16_gen_21.compile(optimizer = 'adadelta', loss = msesum,  metrics = ['acc'])\n",
    "    modevgg16_gen_20.compile(optimizer = 'adadelta', loss = msesum,  metrics = ['acc'])\n",
    "    modevgg16_gen_20_7.compile(optimizer = 'adadelta', loss = msesum,  metrics = ['acc'])\n",
    "    modevgg16_gen_20_2.compile(optimizer = 'adadelta', loss = msesum,  metrics = ['acc'])\n",
    "    modevgg16_gen_20_3.compile(optimizer = 'adadelta', loss = msesum,  metrics = ['acc'])\n",
    "    modevgg16_gen_20_5.compile(optimizer = 'adadelta', loss = msesum,  metrics = ['acc'])\n",
    "                         \n",
    "#20 -> 80 or 40 -> 80 or 80-80\n",
    "def trainvgg2(model,bloadmodel,num,printparr,chang,runmode,resusize):\n",
    "    #(modevgg16_gen_20,running,33,20,False,0)  \n",
    "    global traindata,traindataok,traincount,trainprev\n",
    "    global testdata,testdataok,testcount\n",
    "    if bloadmodel:\n",
    "        gencompile2()\n",
    "    else:\n",
    "        gencompile1()\n",
    "    print('traindata shape:', traindata.shape)\n",
    "    \n",
    "    #model.compile(loss=msesum,optimizer=sgd)\n",
    "  \n",
    "    epoch_num = 3\n",
    "    #learning_rate = np.linspace(0.03,0.01,epoch_num)\n",
    "    #change_lr = LearningRateScheduler(lambda epoch:float(learning_rate[epoch]))\n",
    "    early_stop = EarlyStopping(monitor='val_loss',patience=20,verbose=1,mode='auto' )\n",
    "    check_point = ModelCheckpoint('face_CNN_model_finalvgg_val_loss{val_loss:.2f}'+str(num)+'.h5',monitor='val_loss',verbose= 0,save_best_only= True,\n",
    "                                 save_weights_only=True,mode='auto',period=1)\n",
    "    \n",
    "    check_point2 = ModelCheckpoint('face_CNN_model_finalvgg_val_acc{val_acc:.2f}'+str(num)+'.h5',monitor='val_acc',verbose= 0,save_best_only= True,\n",
    "                                 save_weights_only=True,mode='auto',period=1)\n",
    "    \n",
    "    callbacks_list= [check_point,check_point2,early_stop]  \n",
    "    if bloadmodel:\n",
    "        model.load_weights('./face_CNN_model_finalvgg'+str(num))\n",
    "        \"\"\"\n",
    "        printGen22Resu(model,printparr,runmode,resusize)\n",
    "        printGen22Resu(model,printparr,runmode,resusize)\n",
    "        printGen22Resu(model,printparr,runmode,resusize)\n",
    "        \"\"\"\n",
    "        printGen22Resu(model,printparr,0,resusize)\n",
    "        printGen22Resu(model,printparr,0,resusize)\n",
    "        printGen22Resu(model,printparr,0,resusize)\n",
    "        printGen22Resu(model,printparr,0,resusize)\n",
    "        printGen22Resu(model,printparr,0,resusize)\n",
    "        printGen22Resu(model,printparr,0,resusize)\n",
    "        printGen22Resu(model,printparr,0,resusize)\n",
    "        printGen22Resu(model,printparr,0,resusize)\n",
    "        printGen22Resu(model,printparr,0,resusize)\n",
    "        print('-----------------------------------------------add noise-----------------------------------------------')\n",
    "        printGen22Resu(model,printparr,1,resusize)\n",
    "        printGen22Resu(model,printparr,1,resusize)\n",
    "        printGen22Resu(model,printparr,1,resusize)\n",
    "        printGen22Resu(model,printparr,1,resusize)\n",
    "        printGen22Resu(model,printparr,1,resusize)\n",
    "        printGen22Resu(model,printparr,1,resusize)\n",
    "        printGen22Resu(model,printparr,1,resusize)\n",
    "        printGen22Resu(model,printparr,1,resusize)\n",
    "        printGen22Resu(model,printparr,1,resusize)\n",
    "   \n",
    "    \"\"\"\n",
    "    train_generator = datagen.flow_from_directory(  \n",
    "    './words',\n",
    "    target_size=(30, 30),\n",
    "    color_mode='grayscale',\n",
    "    batch_size=64)\n",
    "\n",
    "    model.fit_generator(train_generator, steps_per_epoch=500, epochs=50)\n",
    "    \"\"\"\n",
    "    \n",
    "    #,change_lr\n",
    "    #print('modevgg16_gen_18 train run:')\n",
    "    #model.load_weights('face_CNN_model_finalvgg18_2.h5')\n",
    "    \n",
    "    for i in range(1,36):\n",
    "        trainprev = traindataok\n",
    "        print('run times:',i)\n",
    "        if i>1:\n",
    "            model.load_weights('./face_CNN_model_finalvgg'+str(num))\n",
    "        #or (bloadmodel and i==1)\n",
    "        \"\"\"\n",
    "        if (inum>0):\n",
    "            if (i%3==2 ):\n",
    "                datagen = ImageDataGenerator(\n",
    "    featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "    samplewise_center=False,  # set each sample mean to 0\n",
    "    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "    samplewise_std_normalization=False,  # divide each input by its std\n",
    "    zca_whitening=False,  # apply ZCA whitening\n",
    "    rotation_range=45,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)\n",
    "    height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)\n",
    "    horizontal_flip=True,  # randomly flip images\n",
    "    vertical_flip=False)  # randomly flip images            \n",
    "                datagen.fit(trainprev)        \n",
    "        \"\"\"    \n",
    "        if chang:        \n",
    "            traindata = data_chnagenoisy(trainprev,traincount)\n",
    "            traindata = np.array(traindata)\n",
    "            testdata = data_chnagenoisy(testdataok,testcount)\n",
    "            testdata = np.array(testdata)\n",
    "                       \n",
    "                \n",
    "        #print('begin proc image:')\n",
    "        if runmode==0:\n",
    "            model.fit(trainprev,trainprev,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epoch_num,\n",
    "              verbose=1,\n",
    "              validation_data=(testdataok,testdataok),\n",
    "              shuffle=True,\n",
    "              callbacks=callbacks_list)\n",
    "        else:\n",
    "            model.fit(traindata,trainprev,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epoch_num,\n",
    "              verbose=1,\n",
    "              validation_data=(testdata,testdataok),\n",
    "              shuffle=True,\n",
    "              callbacks=callbacks_list)\n",
    "        model.save_weights('./face_CNN_model_finalvgg'+str(num))\n",
    "        #model.fit_generator(traindata,traindataok,callbacks=[check_point,early_stop,change_lr],samples_per_epoch=int(train_samples// batch_size),\n",
    "        #                epochs =epoch_num,validation_steps =int(test_samples//batch_size),validation_data=(testdata,testdataok))\n",
    "        if runmode==0:\n",
    "            model.evaluate(testdataok[0:20],testdataok[0:20],steps=10)\n",
    "            model.evaluate(testdataok[30:50],testdataok[30:50],steps=10)       \n",
    "        else:\n",
    "            model.evaluate(testdata[0:20],testdataok[0:20],steps=10)\n",
    "            model.evaluate(testdata[30:50],testdataok[30:50],steps=10)  \n",
    "        \"\"\"\n",
    "        printGen22Resu(model,printparr,runmode,resusize)\n",
    "        printGen22Resu(model,printparr,runmode,resusize)\n",
    "        printGen22Resu(model,printparr,runmode,resusize)\n",
    "        \"\"\"\n",
    "        printGen22Resu(model,printparr,0,resusize)\n",
    "        printGen22Resu(model,printparr,0,resusize)\n",
    "        printGen22Resu(model,printparr,0,resusize)\n",
    "        printGen22Resu(model,printparr,0,resusize)\n",
    "        printGen22Resu(model,printparr,0,resusize)\n",
    "        printGen22Resu(model,printparr,0,resusize)\n",
    "        printGen22Resu(model,printparr,0,resusize)\n",
    "        printGen22Resu(model,printparr,0,resusize)\n",
    "        printGen22Resu(model,printparr,0,resusize)\n",
    "        print('-----------------------------------------------add noise-----------------------------------------------')\n",
    "        printGen22Resu(model,printparr,1,resusize)\n",
    "        printGen22Resu(model,printparr,1,resusize)\n",
    "        printGen22Resu(model,printparr,1,resusize)\n",
    "        printGen22Resu(model,printparr,1,resusize)\n",
    "        printGen22Resu(model,printparr,1,resusize)\n",
    "        printGen22Resu(model,printparr,1,resusize)\n",
    "        printGen22Resu(model,printparr,1,resusize)\n",
    "        printGen22Resu(model,printparr,1,resusize)\n",
    "        printGen22Resu(model,printparr,1,resusize)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def testgen19(bload,running):\n",
    "    global traindata,traindataok,traincount,traindata2\n",
    "    global testdata,testdataok,testcount,testdata2\n",
    "    if bload:    \n",
    "        print('data begin load')\n",
    "        traindata,traindataok,traincount = data_labelnoisy(trainpath2)\n",
    "        testdata,testdataok,testcount = data_labelnoisy(testpath2)\n",
    "        print('data all loaded!')\n",
    "    \n",
    "        traindata = np.array(traindata)\n",
    "        traindataok= np.array(traindataok)\n",
    "        testdata = np.array(testdata)\n",
    "        testdataok = np.array(testdataok)\n",
    "    if running:        \n",
    "        modevgg16_gen_19.load_weights('./face_CNN_model_finalvgg'+str(31))\n",
    "        printGen22Resu(model,printparr,runmode)\n",
    "        printGen22Resu(model,printparr,runmode)\n",
    "        printGen22Resu(model,printparr,runmode)\n",
    "    trainvgg2(modevgg16_gen_19,running,31,20,False,0)  \n",
    "\n",
    "def testgen21(bload):\n",
    "    global traindata,traindataok,traincount,traindata2\n",
    "    global testdata,testdataok,testcount,testdata2\n",
    "    if bload:    \n",
    "        print('data begin load')\n",
    "        traindata,traindataok,traincount = data_labelnoisy(trainpath2)\n",
    "        testdata,testdataok,testcount = data_labelnoisy(testpath2)\n",
    "        print('data all loaded!')\n",
    "    \n",
    "        traindata = np.array(traindata)\n",
    "        traindataok= np.array(traindataok)\n",
    "        testdata = np.array(testdata)\n",
    "        testdataok = np.array(testdataok)\n",
    "        \n",
    "   \n",
    "\n",
    "    trainvgg2(modevgg16_gen_21,True,32,40,False,0)\n",
    "    \n",
    "def trainvgg22(model,bloadmodel):\n",
    "    #20*20 --> 80*80    \n",
    "    trainvgg2(model,bloadmodel,22,20,False,0)\n",
    "    \n",
    "def trangen22():\n",
    "    global traindata,traindataok,traincount,traindata2\n",
    "    global testdata,testdataok,testcount,testdata2\n",
    "    if True:    \n",
    "        print('data begin load')\n",
    "        traindata,traindataok,traincount = data_labelnoisy(trainpath2)\n",
    "        testdata,testdataok,testcount = data_labelnoisy(testpath2)\n",
    "        print('data all loaded!')\n",
    "    \n",
    "        traindata = np.array(traindata)\n",
    "        traindataok= np.array(traindataok)\n",
    "        testdata = np.array(testdata)\n",
    "        testdataok = np.array(testdataok)\n",
    "    modevgg16_gen_22.load_weights('./face_CNN_model_finalvgg22')\n",
    "    printGen22Resu(modevgg16_gen_22,20,0)      \n",
    "    printGen22Resu(modevgg16_gen_22,20,0)\n",
    "    printGen22Resu(modevgg16_gen_22,20,0)\n",
    "    trainvgg22(modevgg16_gen_22,True)\n",
    "\n",
    "def testgen21(bload,running):\n",
    "    global traindata,traindataok,traincount,traindata2\n",
    "    global testdata,testdataok,testcount,testdata2\n",
    "    if bload:    \n",
    "        print('data begin load')\n",
    "        traindata,traindataok,traincount = data_labelnoisy(trainpath2)\n",
    "        testdata,testdataok,testcount = data_labelnoisy(testpath2)\n",
    "        print('data all loaded!')\n",
    "    \n",
    "        traindata = np.array(traindata)\n",
    "        traindataok= np.array(traindataok)\n",
    "        testdata = np.array(testdata)\n",
    "        testdataok = np.array(testdataok)      \n",
    "    \n",
    "\n",
    "    trainvgg2(modevgg16_gen_21,running,32,40,False,0)\n",
    "    \n",
    "def traingen20_7(bload,running):    \n",
    "    global traindata,traindataok,traincount,traindata2\n",
    "    global testdata,testdataok,testcount,testdata2\n",
    "    if bload:    \n",
    "        print('data begin load')\n",
    "        traindata,traindataok,traincount = data_labelnoisy(trainpath2)\n",
    "        testdata,testdataok,testcount = data_labelnoisy(testpath2)\n",
    "        print('data all loaded!')\n",
    "    \n",
    "        traindata = np.array(traindata)\n",
    "        traindataok= np.array(traindataok)\n",
    "        testdata = np.array(testdata)\n",
    "        testdataok = np.array(testdataok)\n",
    "    trainvgg2(modevgg16_gen_20_7,running,56,80,True,1)\n",
    "    \n",
    "def printgen19resu(model,printparr,runmode,num,loaddata):\n",
    "    global traindata,traindataok,traincount,traindata2\n",
    "    global testdata,testdataok,testcount,testdata2\n",
    "    if loaddata:    \n",
    "        print('data begin load')\n",
    "        traindata,traindataok,traincount = data_labelnoisy(trainpath2)\n",
    "        testdata,testdataok,testcount = data_labelnoisy(testpath2)\n",
    "        print('data all loaded!')\n",
    "    \n",
    "        traindata = np.array(traindata)\n",
    "        traindataok= np.array(traindataok)\n",
    "        testdata = np.array(testdata)\n",
    "        testdataok = np.array(testdataok)\n",
    "    model.load_weights('./face_CNN_model_finalvgg'+str(num)+'.h5')\n",
    "    for i in range(1,10):\n",
    "        printGen22Resu(model,printparr,runmode)\n",
    "    \n",
    "    \n",
    "\"\"\"  \n",
    "print('20*20-->80*80')\n",
    "printgen19resu(modevgg16_gen_19,20,0,31,True)    #训练完成后执行\n",
    "\n",
    "print('----------------------------------------------------------------------------------------')\n",
    "\n",
    "print('40*40-->80*80')\n",
    "printgen19resu(modevgg16_gen_21,40,0,32,False)     #训练完成后执行\n",
    "\n",
    "print('----------------------------------------------------------------------------------------')\n",
    "\n",
    "print('80*80去噪')\n",
    "printgen19resu(modevgg16_gen_20_7,80,1,56,False)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "def testgen19_1(bload,running):\n",
    "    global traindata,traindataok,traincount,traindata2\n",
    "    global testdata,testdataok,testcount,testdata2\n",
    "    if bload:    \n",
    "        print('data begin load')\n",
    "        traindata,traindataok,traincount = data_labelnoisy(trainpath2,80)\n",
    "        testdata = traindata[27000:]\n",
    "        testdataok = traindataok[27000:]\n",
    "        traindata = traindata[:27000]\n",
    "        traindataok = traindataok[:27000]\n",
    "       \n",
    "        traincount = 27000\n",
    "        \n",
    "        #testdata,testdataok,testcount = data_labelnoisy(testpath2)\n",
    "        print('data all loaded!')\n",
    "    \n",
    "        traindata = np.array(traindata)\n",
    "        traindataok= np.array(traindataok)\n",
    "        testdata = np.array(testdata)\n",
    "        testdataok = np.array(testdataok)\n",
    "        \n",
    "        print('traindata shape:', traindata.shape)\n",
    "        print('traindataok shape:', traindataok.shape)\n",
    "        print('testdata shape:', testdata.shape)\n",
    "        print('testdataok shape:', testdataok.shape)\n",
    "    if running:        \n",
    "        modevgg16_gen_19.load_weights('./face_CNN_model_finalvgg'+str(32))        \n",
    "    trainvgg2(modevgg16_gen_19,running,32,20,False,0)  \n",
    "    \n",
    "\n",
    "\n",
    "#testgen19_1(True,False)\n",
    "\n",
    "def testgen19_2(bload,running):\n",
    "    global traindata,traindataok,traincount,traindata2\n",
    "    global testdata,testdataok,testcount,testdata2\n",
    "    if bload:    \n",
    "        print('data begin load')\n",
    "        traindata,traindataok,traincount = data_labelnoisy(trainpath2,80)\n",
    "        testdata = traindata[27000:]\n",
    "        testdataok = traindataok[27000:]\n",
    "        traindata = traindata[:27000]\n",
    "        traindataok = traindataok[:27000]\n",
    "       \n",
    "        traincount = 27000\n",
    "        \n",
    "        #testdata,testdataok,testcount = data_labelnoisy(testpath2)\n",
    "        print('data all loaded!')\n",
    "    \n",
    "        traindata = np.array(traindata)\n",
    "        traindataok= np.array(traindataok)\n",
    "        testdata = np.array(testdata)\n",
    "        testdataok = np.array(testdataok)\n",
    "        \n",
    "        print('traindata shape:', traindata.shape)\n",
    "        print('traindataok shape:', traindataok.shape)\n",
    "        print('testdata shape:', testdata.shape)\n",
    "        print('testdataok shape:', testdataok.shape)\n",
    "    if running:        \n",
    "        modevgg16_gen_20.load_weights('./face_CNN_model_finalvgg'+str(50))        \n",
    "    trainvgg2(modevgg16_gen_20,running,50,20,False,0,80)  \n",
    "\n",
    "def testgen19_3(bload,running,datapath,datasize):\n",
    "    global traindata,traindataok,traincount,traindata2\n",
    "    global testdata,testdataok,testcount,testdata2\n",
    "    if bload:    \n",
    "        print('data begin load')\n",
    "        traindata,traindataok,traincount = data_labelnoisy(datapath,datasize)\n",
    "        testdata = traindata[27000:]\n",
    "        testdataok = traindataok[27000:]\n",
    "        traindata = traindata[:27000]\n",
    "        traindataok = traindataok[:27000]\n",
    "       \n",
    "        traincount = 27000\n",
    "        \n",
    "        #testdata,testdataok,testcount = data_labelnoisy(testpath2)\n",
    "        print('data all loaded!')\n",
    "    \n",
    "        traindata = np.array(traindata)\n",
    "        traindataok= np.array(traindataok)\n",
    "        testdata = np.array(testdata)\n",
    "        testdataok = np.array(testdataok)\n",
    "        \n",
    "        print('traindata shape:', traindata.shape)\n",
    "        print('traindataok shape:', traindataok.shape)\n",
    "        print('testdata shape:', testdata.shape)\n",
    "        print('testdataok shape:', testdataok.shape)\n",
    "    if running:        \n",
    "        modevgg16_gen_20_5.load_weights('./face_CNN_model_finalvgg'+str(59)) \n",
    "    halfsize = (int)(datasize/2)      \n",
    "    trainvgg2(modevgg16_gen_20_5,running,59,halfsize,False,0,datasize)      \n",
    "    \n",
    "#testgen19_3(True,False,trainpath6,160)\n",
    "#testgen19_2(True,True)\n",
    "#testgen19(True,False)\n",
    "#第二次运行改为 testgen19(True,True)\n",
    "#testgen21(True,False)\n",
    "#第二次运行改为 testgen21(True,True)\n",
    "            \n",
    "#print('begin proc image')\n",
    "#img_custconv(trainpath5,120)\n",
    "#print('train images complete')\n",
    "\n",
    "print('begin proc image')\n",
    "img_custconv(trainpath6,160)\n",
    "print('train images complete')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ee8ac0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e909f8c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
